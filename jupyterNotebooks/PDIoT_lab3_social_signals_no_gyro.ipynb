{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luisewoehlke/Honours-Project/blob/master/jupyterNotebooks/PDIoT_lab3_social_signals_no_gyro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzd9Z9OZxNvd"
      },
      "source": [
        "# **Lab 3 - Activity Recognition with Machine Learning**\n",
        "\n",
        "This notebook implements a machine learning workflow to recognize different physical activities from Respeck sensor data. The dataset includes multiple 30-second recordings of various physical activities (e.g., ascending stairs, shuffle walking, sitting-standing) stored in separate CSV files for each activity.\n",
        "\n",
        "You will then use the model you develop here and deploy it inside your Android app for live classification.\n",
        "\n",
        "In this week, you will not have access to the full dataset as of yet. However, you can complete this lab by combining the data that you and your group mates have collected in Coursework 1 as proof-of-concept first for when you eventually receive the full dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXyHZD1A0X7J"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZXLb6aseWnhg"
      },
      "outputs": [],
      "source": [
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s2B8Hymdj1Sg"
      },
      "outputs": [],
      "source": [
        "# Importing libraries that will be used\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icbrBf1Kl6vp"
      },
      "source": [
        "# Reading Files\n",
        "Reading files from your dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "57NMFLVSZxUk",
        "outputId": "81e429a3-f77b-443b-9b48-d8f02401af9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pTsJd33Kl44J"
      },
      "outputs": [],
      "source": [
        "# Put in the path of your dataset here\n",
        "your_dataset_path = \"C:/Users/luise/OneDrive - University of Edinburgh/uni/pdiot/cw3 data/Respeck/Respiratory/\"\n",
        "your_dataset_path = \"C:/Users/luise/OneDrive - University of Edinburgh/uni/pdiot/cw3 data/Respeck all/Respiratory/\"\n",
        "your_dataset_path = \"/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOTe3o9Il4ST"
      },
      "source": [
        "This line uses the glob module to find all file paths that match a specified pattern. The 'glob.glob()' function returns a list of file paths that match the given pattern. `your_dataset_path` should be the directory where your dataset files are located.\n",
        "\n",
        "The `*` is a wildcard character that matches any string of characters,  so this pattern retrieves all folders in the 'your_dataset_path' directory.\n",
        "\n",
        "Below is just an example of what your dataset folder can look like. You should refer to the Coursework 3 instructions on what classes your model(s) are expected to be able to classify. Within your dataset directory, there should be subfolders, each representing a class of activity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4izGxKkllz6",
        "outputId": "af9675e8-34df-4835-fb37-6d6d53141a04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory/breathingNormally',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory/hyperventilation',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory/other',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory/coughing']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "glob.glob(your_dataset_path + \"*\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3zJiRjym7LU"
      },
      "source": [
        "To see the files in each subfolder you can similarly do:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCS4lQgwnO9X",
        "outputId": "63570b2a-f977-4e60-d37d-ded09512d1bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s77_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s77_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s77_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s77_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s77_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s77_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s77_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s77_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s77_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s77_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s77_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s79_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s7_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s80_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s81_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s82_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s83_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s84_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s85_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s86_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s87_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s88_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s91_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s91_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s91_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s8_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s91_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s91_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s91_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s91_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s91_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s91_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s91_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s91_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s91_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s91_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s91_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s91_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s91_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s92_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s93_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s94_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s95_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s96_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s97_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s98_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_lyingBack_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_lyingBack_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_lyingBack_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_lyingLeft_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_lyingLeft_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s99_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_sitting_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_standing_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_lyingLeft_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_standing_eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_lyingRight_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_lyingRight_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_sitting_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_sitting_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_lyingStomach_singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_standing_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_lyingRight_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_lyingStomach_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_standing_laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_sitting_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/s9_respeck_lyingStomach_talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/00_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/02_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/03_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/04_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/04_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/04_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/04_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/04_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/04_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/04_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/04_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/04_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/04_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/04_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/05_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/05_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/05_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/07_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/07_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/07_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/08_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/09_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/10_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/11_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/12_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/13_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/14_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/16_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/17_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/17_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/18_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/19_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/19_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/19_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/20_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/20_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/20_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/21_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/21_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/22_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/25_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/27_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/27_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/27_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/27_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/27_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/27_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/27_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/27_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/27_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/29_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/30_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/31_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/33_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/34_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/35_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/36_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/37_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/37_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/37_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/37_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/37_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/37_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/37_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/37_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/37_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/37_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/37_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/37_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/37_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/37_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/37_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/37_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/37_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/37_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/37_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/38_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/39_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/43_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Lying down right_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/44_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/46_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/46_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/46_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/46_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/46_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/47_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/47_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/46_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/46_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/46_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/47_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/47_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/46_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/46_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/46_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/46_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/46_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/46_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/47_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/47_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/46_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/46_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/47_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/47_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/46_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/46_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/47_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/46_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/47_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/48_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/48_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/48_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/48_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/48_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/48_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Lying down on left_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Lying down right_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Lying down right_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Lying down on stomach_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Sitting_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Lying down on left_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Lying down back_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Standing_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Standing_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Sitting_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Lying down back_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Sitting_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Standing_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Standing_Eating.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Lying down on stomach_Talking.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Lying down back_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Sitting_Singing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Lying down on left_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Lying down on stomach_Laughing.csv',\n",
              " '/content/drive/My Drive/Colab Notebooks/cw3 data/Respeck all/Respiratory//other/49_Respeck_Lying down right_Singing.csv',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "activity_folder = \"other\"\n",
        "glob.glob(your_dataset_path + \"/\"+activity_folder+\"/*\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7eNuiHKmBuT"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zdg12YooOJF"
      },
      "source": [
        "## Load list of files in an activity folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b_ZtuAb64ZsD"
      },
      "outputs": [],
      "source": [
        "def load_files_from_folder(folder_path):\n",
        "    \"\"\"\n",
        "    Load all CSV files from a folder and return a list of file paths.\n",
        "\n",
        "    Parameters:\n",
        "    folder_path (str): The path to the folder containing CSV files.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of file paths for all CSV files in the folder.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize an empty list to store the full file paths of the CSV files\n",
        "    file_paths = []\n",
        "\n",
        "    # Loop through all the files in the given folder\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        # Check if the file has a .csv extension (ignores other files)\n",
        "        if file_name.endswith('.csv'):\n",
        "            # Construct the full file path by joining the folder path and the file name\n",
        "            full_file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "            # Append the full file path to the file_paths list\n",
        "            file_paths.append(full_file_path)\n",
        "\n",
        "    # Return the complete list of CSV file paths\n",
        "    return file_paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAUGBeBBn_L8"
      },
      "source": [
        "## Train and test set split from list of files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2SzHoQz2NH3v"
      },
      "outputs": [],
      "source": [
        "def split_files(file_list, test_size=0.2):\n",
        "    \"\"\"\n",
        "    Split the list of files into training and test sets.\n",
        "\n",
        "    Parameters:\n",
        "    file_list (list): List of file paths to be split into train and test sets.\n",
        "    test_size (float): The proportion of files to allocate to the test set.\n",
        "                       Default is 0.2, meaning 20% of the files will be used for testing.\n",
        "\n",
        "    Returns:\n",
        "    tuple:\n",
        "        - train_files (list): List of file paths for the training set.\n",
        "        - test_files (list): List of file paths for the test set.\n",
        "    \"\"\"\n",
        "\n",
        "    # Split the file list into training and test sets using train_test_split from scikit-learn\n",
        "    # test_size defines the proportion of the data to use as the test set (default is 20%)\n",
        "    # shuffle=True ensures that the files are shuffled randomly before splitting\n",
        "    train_files, test_files = train_test_split(file_list, test_size=test_size, shuffle=True)\n",
        "\n",
        "    # Return the train and test file lists\n",
        "    return train_files, test_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J7-zQgZzP19"
      },
      "source": [
        "## Sliding Window\n",
        "\n",
        "In time series Activity Recognition, a sliding window is a commonly used technique to segment continuous sensor data (such as accelerometer readings) into smaller, fixed-length overlapping or non-overlapping time intervals, or windows. Each window contains a sequence of sensor measurements that represent a short period of time, and this segmented data is used to extract features or make predictions about the activity happening within that window.\n",
        "\n",
        "### Key Concepts of a Sliding Window\n",
        "1.   **Window Size:** This refers to the length of each segment or window, typically defined in terms of the number of time steps or the duration (e.g., 2 seconds). The window size should be chosen carefully to capture enough information about the activity without making the window too large.\n",
        "2.   **Step Size:** The step size determines how far the window moves forward after each step. If the step size is smaller than the window size, the windows will overlap. For example, if the window size is 5 seconds and the step size is 2 seconds, there will be a 3-second overlap between consecutive windows. Overlapping windows provide more data for analysis and can help smooth out predictions by capturing transitional activities.\n",
        "3.   **Non-Overlapping Windows:** If the step size is equal to the window size, the windows do not overlap. This method provides distinct segments of data but may miss transitional phases between activities.\n",
        "\n",
        "### Why Sliding Windows for Activity Recognition?\n",
        "\n",
        "* Segmentation of Continuous Data: Activity recognition systems work with continuous streams of sensor data, and the sliding window helps segment these into manageable pieces to classify activities within specific intervals.\n",
        "\n",
        "* Context Capturing: Human activities are often complex and spread across time. By using a sliding window, you can capture context across a short duration, which may include transitions or small fluctuations in the activity (e.g., a person moving from sitting to standing).\n",
        "\n",
        "* Feature Extraction: Within each window, features such as mean, variance, frequency domain features, etc., can be extracted to help classify the activity.\n",
        "\n",
        "* Real-Time Recognition: In real-time systems, the sliding window allows for continuous monitoring and updating of predictions as new data arrives.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u3SuHww6MpEx"
      },
      "outputs": [],
      "source": [
        "def load_and_apply_sliding_windows(file_paths, window_size, step_size, label):\n",
        "    \"\"\"\n",
        "    Load the data from each file, apply sliding windows, and return the windows and labels.\n",
        "\n",
        "    Parameters:\n",
        "    file_paths (list): List of file paths to CSV files. Each file contains sensor data (e.g., accelerometer, gyroscope).\n",
        "    window_size (int): The size of each sliding window (number of time steps).\n",
        "    step_size (int): The step size (stride) between consecutive windows.\n",
        "    label (int or str): The label for the activity corresponding to the folder.\n",
        "                        This label will be assigned to each sliding window extracted from the data.\n",
        "\n",
        "    Returns:\n",
        "    tuple:\n",
        "        - windows (numpy.ndarray): A 3D array of sliding windows, where each window has the shape\n",
        "                                   (num_windows, window_size, num_features).\n",
        "        - labels (numpy.ndarray): A 1D array of labels, where each label corresponds to a sliding window.\n",
        "    \"\"\"\n",
        "    # Initialize lists to store sliding windows and their corresponding labels\n",
        "    windows = []\n",
        "    labels = []\n",
        "\n",
        "    # Loop through each file in the provided file paths\n",
        "    for file_path in file_paths:\n",
        "        # Load the CSV file into a pandas DataFrame\n",
        "        data = pd.read_csv(file_path)\n",
        "\n",
        "        # Select the columns containing the necessary sensor data (acceleration and gyroscope readings)\n",
        "        # These columns might vary depending on your dataset's structure\n",
        "        data = data[['accel_x', 'accel_y', 'accel_z']]\n",
        "\n",
        "        # Convert the DataFrame into a numpy array for faster processing in the sliding window operation\n",
        "        data = data.to_numpy()\n",
        "\n",
        "        # Get the number of samples (rows) and features (columns) in the data\n",
        "        num_samples, num_features = data.shape\n",
        "\n",
        "        # Apply sliding windows to the data\n",
        "        # The range function defines the start of each window, moving step_size increments at a time\n",
        "        for i in range(0, num_samples - window_size + 1, step_size):\n",
        "            # Extract a window of size 'window_size' from the current position 'i'\n",
        "            window = data[i:i + window_size, :]\n",
        "\n",
        "            # Append the window to the windows list\n",
        "            windows.append(window)\n",
        "\n",
        "            # Assign the activity label to the window and append it to the labels list\n",
        "            labels.append(label)\n",
        "\n",
        "    # Convert the lists of windows and labels into numpy arrays for efficient numerical operations\n",
        "    return np.array(windows), np.array(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-Ku5P4Lm8QA"
      },
      "source": [
        "## Load and Split Train Test for Each Activity Folder\n",
        "\n",
        "This function processes the sensor data for a specific activity, such as 'walking' or 'running', stored in its respective folder. It splits the data into training and testing sets, applies sliding windows, and labels the windows with the corresponding activity. This function can be used repeatedly for each activity to process and prepare data for training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zBVvTBi7N_fh"
      },
      "outputs": [],
      "source": [
        "def process_activity(activity, label, dataset_path, window_size=50, step_size=50, test_size=0.2):\n",
        "    \"\"\"\n",
        "    Processes an activity folder by loading the file list, splitting them into\n",
        "    train and test sets, and applying sliding windows to the files.\n",
        "\n",
        "    Args:\n",
        "        activity (str): Name of the activity (folder name). This refers to the specific physical activity\n",
        "                        like 'walking', 'running', etc.\n",
        "        label (int): Numeric label corresponding to the activity, used for classification.\n",
        "        dataset_path (str): Base path where the activity folders are located.\n",
        "        window_size (int): Size of the sliding window, i.e., the number of time steps included in each window.\n",
        "                           Default is 50.\n",
        "        step_size (int): Step size for the sliding window, i.e., how far the window moves along the data.\n",
        "                         Default is 50 (no overlap between windows).\n",
        "        test_size (float): Proportion of files to use for testing. Default is 0.2, meaning 20% of files will\n",
        "                           be allocated to the test set.\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - train_windows (numpy.ndarray): Sliding windows from the training files.\n",
        "            - train_labels (numpy.ndarray): Corresponding labels for the training windows.\n",
        "            - test_windows (numpy.ndarray): Sliding windows from the test files.\n",
        "            - test_labels (numpy.ndarray): Corresponding labels for the test windows.\n",
        "    \"\"\"\n",
        "    # Construct the full folder path where the activity files are stored\n",
        "    folder_path = os.path.join(dataset_path, activity)\n",
        "\n",
        "    # Load all CSV file paths for the given activity from the folder\n",
        "    file_list = load_files_from_folder(folder_path)\n",
        "\n",
        "    # Split the file list into training and testing sets\n",
        "    # train_files: files used for training\n",
        "    # test_files: files used for testing\n",
        "    train_files, test_files = split_files(file_list, test_size=test_size)\n",
        "\n",
        "    # Apply sliding windows to the training files\n",
        "    # The function 'load_and_apply_sliding_windows' returns the sliding windows (segments) and their corresponding labels\n",
        "    train_windows, train_labels = load_and_apply_sliding_windows(train_files, window_size, step_size, label)\n",
        "\n",
        "    # Apply sliding windows to the testing files\n",
        "    test_windows, test_labels = load_and_apply_sliding_windows(test_files, window_size, step_size, label)\n",
        "\n",
        "    # Return the sliding windows and their labels for both training and testing sets\n",
        "    return train_windows, train_labels, test_windows, test_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv2TUL_Tnnxu"
      },
      "source": [
        "## Combine Data\n",
        "The function combines the sliding window data and their corresponding labels from multiple activities (e.g., walking, running, etc.) into single arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "au6dRWtmmig7"
      },
      "outputs": [],
      "source": [
        "def combine_data(train_test_data, data_type):\n",
        "    \"\"\"\n",
        "    Combines the sliding windows and labels from all activities into a single\n",
        "    array for either training or testing.\n",
        "\n",
        "    Args:\n",
        "        train_test_data (dict): Dictionary containing the sliding window data for all activities.\n",
        "                                Each key in the dictionary corresponds to an activity, and the value is another\n",
        "                                dictionary with the keys 'train_windows', 'train_labels', 'test_windows', 'test_labels'.\n",
        "        data_type (str): Either 'train' or 'test' to specify which data to combine (e.g., 'train_windows' or 'test_windows').\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - windows (numpy.ndarray): Concatenated windows from all activities for either training or testing.\n",
        "            - labels (numpy.ndarray): Concatenated labels corresponding to the windows from all activities.\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract the list of sliding windows for the specified data type (either 'train' or 'test') from each activity\n",
        "    # For example, if data_type is 'train', it extracts 'train_windows' for all activities\n",
        "    windows_list = [train_test_data[activity][f'{data_type}_windows'] for activity in train_test_data]\n",
        "\n",
        "    # Similarly, extract the list of labels corresponding to the windows for each activity\n",
        "    labels_list = [train_test_data[activity][f'{data_type}_labels'] for activity in train_test_data]\n",
        "\n",
        "    # Concatenate all the sliding windows into a single numpy array along the first axis (rows)\n",
        "    # This creates one large array of windows from all the activities combined\n",
        "    concatenated_windows = np.concatenate(windows_list, axis=0)\n",
        "\n",
        "    # Concatenate all the labels into a single numpy array along the first axis (rows)\n",
        "    # The labels are now aligned with the concatenated windows\n",
        "    concatenated_labels = np.concatenate(labels_list, axis=0)\n",
        "\n",
        "    # Return the concatenated windows and labels as a tuple\n",
        "    return concatenated_windows, concatenated_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wv1PuOLgUV8"
      },
      "source": [
        "## 1D CNN Model\n",
        "\n",
        "This function, `build_1d_cnn_model`, creates and compiles a 1D Convolutional Neural Network (CNN) for multi-class classification tasks.\n",
        "\n",
        "### Function Overview\n",
        "\n",
        "Input Parameters\n",
        "* `input_shape`: Specifies the shape of the input data. It represents (timesteps, features), where timesteps refer to the length of the time series (e.g., 50 windows), and features represent the number of measurements in each time step (e.g., accelerometer readings).\n",
        "* `num_classes`: The number of output classes for the classification problem. For example, if you're classifying six different activities, num_classes would be 6.\n",
        "\n",
        "Returns\n",
        "* The function returns a compiled 1D CNN model that is ready to be trained on your data.\n",
        "\n",
        "<hr>\n",
        "\n",
        "### Function Breakdown\n",
        "1.   Model Initialization:\n",
        "    * `model = Sequential()`: Initializes a Sequential model, which means layers will be stacked on top of each other in a linear fashion.\n",
        "2.   First Convolutional Layer\n",
        "    * `Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape)`\n",
        "        * This is the first 1D convolutional layer\n",
        "        * `filters=64`: The layer applies 64 filters (or kernels) over the input data.\n",
        "        * `kernel_size=3`: Each filter will cover 3 timesteps at a time (a window of 3).\n",
        "        * `activation='relu'`: The Rectified Linear Unit (ReLU) activation function introduces non-linearity and helps the model learn complex patterns.\n",
        "        * `input_shape=input_shape`: Specifies the shape of the input data.\n",
        "    * `MaxPooling1D(pool_size=2)`: This pooling layer reduces the dimensionality of the data by taking the maximum value from each 2-timestep window (`pool_size=2`). This helps reduce computational complexity and captures the most important features.\n",
        "3. Second Convolutional Layer:\n",
        "    * `Conv1D(filters=128, kernel_size=3, activation='relu')`\n",
        "        * This is the second convolutional layer, similar to the first, but with 128 filters, which allow the network to learn more complex features from the data.\n",
        "        * `kernel_size=3` and activation='relu' function in the same way as the first Conv1D layer.\n",
        "    * `MaxPooling1D(pool_size=2)`: Another pooling layer to downsample the output, further reducing the datas dimensionality.\n",
        "4. Flattening Layer:\n",
        "    * `Flattening`: Converts the 2D output of the convolutional and pooling layers into a 1D vector. This is necessary because the next layer is fully connected, and it requires a 1D input.\n",
        "5. Fully Connected Layer:\n",
        "    * `Dense(128, activation='relu')`: This is a fully connected layer with 128 units/neurons. Each neuron is connected to every input from the flattened output. The ReLU activation function is used again to introduce non-linearity and help the model learn complex relationships.\n",
        "6. Dropout Layer:\n",
        "    * `Dropout(0.5)`: This layer randomly sets 50% of the neurons to zero during training to prevent overfitting. It helps the model generalize better to unseen data.\n",
        "7. Output Layer:\n",
        "    * `Dense(num_classes, activation='softmax')`: This is the output layer with num_classes neurons, one for each class in the classification problem. The softmax activation function ensures the output values represent probabilities that sum to 1, useful for multi-class classification.\n",
        "8. Compiling the model\n",
        "    * model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']):\n",
        "        * Optimizer: 'adam': Adam is an optimization algorithm that adjusts the learning rate during training to improve performance.\n",
        "        * Loss: 'categorical_crossentropy': This loss function is used for multi-class classification problems where the target variable is one-hot encoded (i.e., represented as a vector of 0s and 1s).\n",
        "        * Metrics: ['accuracy']: The accuracy metric is used to evaluate the models performance during training and testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sCOkh99EOg8t"
      },
      "outputs": [],
      "source": [
        "def build_1d_cnn_model(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Builds and compiles a 1D CNN model for multi-class classification.\n",
        "\n",
        "    Args:\n",
        "        input_shape (tuple): The shape of the input data (timesteps, features).\n",
        "        num_classes (int): The number of output classes.\n",
        "\n",
        "    Returns:\n",
        "        model (Sequential): Compiled 1D CNN model.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    # First Conv1D layer\n",
        "    # You can try experimenting with different filters, kernel_size values and activiation functions\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "    # Second Conv1D layer\n",
        "    # You can try experimenting with different filters, kernel_size values and activiation functions\n",
        "    model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "    # Flatten the output from the convolutional layers\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Fully connected layer\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "\n",
        "    # Dropout layer for regularization\n",
        "    # You can try experimenting with different dropout rates\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # Output layer with softmax for multi-class classification\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    #  Prints a detailed summary of the model, showing the layers, their output shapes, and the number of trainable parameters\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HurfE6lmOjQT"
      },
      "source": [
        "# Classification Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLs1eacYoa_S"
      },
      "source": [
        "## Step 1: Prepare and Preprocess the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QTzHon1EoiEK"
      },
      "outputs": [],
      "source": [
        "# Define activity folders and corresponding labels\n",
        "# Each key is the name of the physical activity, and the corresponding value is the numeric label\n",
        "# These labels will be used as the target variable for classification.\n",
        "activities = {\n",
        "    'breathingNormally': 0,\n",
        "    'coughing': 1,\n",
        "    'hyperventilation': 2,\n",
        "    'other': 3\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2FqqaaX2o1YW"
      },
      "outputs": [],
      "source": [
        "# Dictionary to store sliding windows and labels for both train and test sets for each activity\n",
        "# This will hold the training and test data after processing each activity.\n",
        "train_test_data = {}\n",
        "\n",
        "# Loop through each activity folder and process the data\n",
        "# Note, if you have large amounts of data, this step may take a while\n",
        "for activity, label in activities.items():\n",
        "    # Initialize an empty dictionary for each activity to store train and test windows and labels\n",
        "    train_test_data[activity] = {}\n",
        "\n",
        "    # Call process_activity() to process the data for the current activity folder\n",
        "    # It loads the data, applies sliding windows, splits it into train and test sets,\n",
        "    # and returns the respective sliding windows and labels for both sets.\n",
        "    (train_test_data[activity]['train_windows'], train_test_data[activity]['train_labels'],\n",
        "     train_test_data[activity]['test_windows'], train_test_data[activity]['test_labels']) = process_activity(\n",
        "        activity, label, your_dataset_path, window_size=50, step_size=50)\n",
        "\n",
        "# Explanation:\n",
        "    # - 'train_windows' and 'train_labels' store the windows and labels from the training files.\n",
        "    # - 'test_windows' and 'test_labels' store the windows and labels from the test files.\n",
        "    # - `your_dataset_path` should be replaced with the actual path to your dataset.\n",
        "    # - `process_activity` handles all the steps of loading data, splitting it, and applying sliding windows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdGR352hph4X"
      },
      "source": [
        "Now that each activity has been processed and stored in train_test_data, we need to combine the sliding windows and labels from all activities into unified arrays (one for training and one for testing) for model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OtpVBr4Fpq_8"
      },
      "outputs": [],
      "source": [
        "# Combine the sliding windows and labels for the training data from all activities\n",
        "# The combine_data() function concatenates the windows and labels across activities\n",
        "X_train, y_train = combine_data(train_test_data, 'train')\n",
        "\n",
        "# Combine the sliding windows and labels for the test data from all activities\n",
        "X_test, y_test = combine_data(train_test_data, 'test')\n",
        "\n",
        "# Explanation:\n",
        "# - `combine_data()` takes in the `train_test_data` dictionary and the data type ('train' or 'test') to specify\n",
        "#   whether we are combining training or testing data.\n",
        "# - It retrieves and concatenates the windows and labels from all activities into single arrays\n",
        "#   (`X_train` and `y_train` for training, `X_test` and `y_test` for testing).\n",
        "# - `X_train` and `X_test` are 3D arrays of sliding windows (shape: num_windows, window_size, num_features).\n",
        "# - `y_train` and `y_test` are 1D arrays containing the activity labels corresponding to each window."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yQGU1vwIQdz"
      },
      "source": [
        "### One-Hot Encode Labels (for multi-class classification)\n",
        "If you have more than two classes, you'll need to one-hot encode the labels, especially if your model will use categorical cross-entropy loss.\n",
        "\n",
        "One-Hot Encoding converts categorical labels into binary vectors (one-hot encoded format). Each class label is represented as a binary vector with 1 for the correct class and 0 for others. This is necessary for training models that use categorical_crossentropy as the loss function, such as a neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9b2J1EVdHj0U"
      },
      "outputs": [],
      "source": [
        "# Initialize the OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Reshape y_train to a 2D array to meet the input format requirements of OneHotEncoder\n",
        "# - y_train is originally a 1D array of labels (shape: [num_samples]), but OneHotEncoder expects a 2D array of shape (num_samples, 1).\n",
        "# - reshape(-1, 1): The -1 means 'infer the correct size based on the other dimensions' (i.e., it adapts based on the length of y_train).\n",
        "# OneHotEncoder will then create a binary vector for each label.\n",
        "y_train_one_hot = encoder.fit_transform(y_train.reshape(-1, 1))\n",
        "\n",
        "# Apply the same transformation to the test labels (y_test)\n",
        "# - Since the encoder is already fitted on the training data, we use transform() for the test set.\n",
        "# - Reshape y_test to (num_samples, 1) for compatibility with the encoder.\n",
        "y_test_one_hot = encoder.transform(y_test.reshape(-1, 1))\n",
        "\n",
        "# Explanation:\n",
        "# - y_train_one_hot and y_test_one_hot are now 2D arrays where each row is a one-hot encoded binary vector corresponding to a class label.\n",
        "# - The number of columns in the one-hot encoded labels equals the number of unique classes (activities).\n",
        "# For example, if there are 6 unique activities, the encoded vector will have 6 elements, with a '1' indicating the correct class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlnbOVr0rDbV",
        "outputId": "1df67fd4-d9f5-4366-d3af-a361a7333c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (57230, 50, 3), y_train shape: (57230,)\n",
            "X_test shape: (14337, 50, 3), y_test shape: (14337,)\n",
            "y_train_one_hot shape: (57230, 4), y_test_one_hot shape: (14337, 4)\n"
          ]
        }
      ],
      "source": [
        "# Print the shapes of the training and test arrays to verify that everything has been combined correctly\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
        "# Print the shapes of the one-hot encoded labels to verify that the transformation was successful\n",
        "print(f\"y_train_one_hot shape: {y_train_one_hot.shape}, y_test_one_hot shape: {y_test_one_hot.shape}\")\n",
        "\n",
        "# Explanation of shapes:\n",
        "# - The shape of y_train_one_hot will be (num_samples, num_classes), where:\n",
        "#     - num_samples is the number of training windows.\n",
        "#     - num_classes is the number of unique activities (the length of the one-hot vectors).\n",
        "# - Similarly, y_test_one_hot will have the same number of columns (num_classes) as y_train_one_hot but will have fewer rows (corresponding to the number of test windows)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEhUxZzzJzzI"
      },
      "source": [
        "## Step 2: Build the 1D-CNN Model\n",
        "Call our `build_1d_cnn_model` functionto build our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "4sDZWZH_KKBD",
        "outputId": "ffc5b584-b162-4016-ab31-4d16e93335cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv1d_16 (\u001b[38;5;33mConv1D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)                           \u001b[38;5;34m640\u001b[0m \n",
              "\n",
              " max_pooling1d_16 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)                             \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv1d_17 (\u001b[38;5;33mConv1D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)                       \u001b[38;5;34m24,704\u001b[0m \n",
              "\n",
              " max_pooling1d_17 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " flatten_8 (\u001b[38;5;33mFlatten\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)                               \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_16 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                          \u001b[38;5;34m180,352\u001b[0m \n",
              "\n",
              " dropout_22 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_17 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                                \u001b[38;5;34m516\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " conv1d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> \n",
              "\n",
              " max_pooling1d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv1d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> \n",
              "\n",
              " max_pooling1d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">180,352</span> \n",
              "\n",
              " dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m206,212\u001b[0m (805.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">206,212</span> (805.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m206,212\u001b[0m (805.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">206,212</span> (805.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Determine the input shape for the model\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "\n",
        "# Determine the number of output classes (num_classes)\n",
        "num_classes = y_train_one_hot.shape[1]\n",
        "\n",
        "# Build and compile the model\n",
        "# The function will return a compiled model ready for training\n",
        "model = build_1d_cnn_model(input_shape, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1-SHEmtKM0D"
      },
      "source": [
        "## Step 3: Train the CNN Model\n",
        "\n",
        "Train the 1D CNN model using the training data and validate on the test data. The model will learn to map input sliding windows to their corresponding activity labels.\n",
        "\n",
        "`model.fit()` is used to train the neural network model. It takes several parameters:\n",
        "* `X_train`: The input training data (sliding windows), with shape (num_samples, window_size, num_features).\n",
        "* `y_train_one_hot`: The corresponding one-hot encoded labels for the training data, with shape (num_samples, num_classes).\n",
        "* `epochs`: Number of times the entire training dataset is passed through the model. You can try adjusting the number of epochs and compare the difference in model performance. In this case, we are training for 20 epochs, meaning the model will see the entire training set 20 times.\n",
        "* `batch_size`: Number of samples processed before the model's weights are updated. Here, the batch size is set to 32, meaning the model will process 32 samples at a time before updating its parameters.\n",
        "* `validation_data`: This parameter allows us to evaluate the model's performance on the test data after each epoch.\n",
        "*`(X_test, y_test_one_hot)`: These are the input test data and corresponding one-hot encoded test labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VYQ4XGsWnhn"
      },
      "source": [
        "# Luise's accuracy improvement trials:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "Gc5f9TkdbH0t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ZtYgN-89Wnhn",
        "outputId": "d0c3b048-9d06-4bf4-f730-cd864c52ceca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.5226 - loss: 1.1957 - val_accuracy: 0.5899 - val_loss: 0.9636 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5561 - loss: 0.9992 - val_accuracy: 0.5825 - val_loss: 0.9419 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5641 - loss: 0.9549 - val_accuracy: 0.5892 - val_loss: 0.9153 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5713 - loss: 0.9247 - val_accuracy: 0.5985 - val_loss: 0.8884 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5886 - loss: 0.8891 - val_accuracy: 0.6133 - val_loss: 0.8617 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6052 - loss: 0.8575 - val_accuracy: 0.6295 - val_loss: 0.8096 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6189 - loss: 0.8323 - val_accuracy: 0.5982 - val_loss: 0.8700 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6336 - loss: 0.8098 - val_accuracy: 0.6493 - val_loss: 0.7950 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6442 - loss: 0.7902 - val_accuracy: 0.6342 - val_loss: 0.8144 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6464 - loss: 0.7855 - val_accuracy: 0.6363 - val_loss: 0.8058 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6533 - loss: 0.7772 - val_accuracy: 0.6406 - val_loss: 0.8123 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6714 - loss: 0.7398 - val_accuracy: 0.6566 - val_loss: 0.7912 - learning_rate: 5.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6851 - loss: 0.7238 - val_accuracy: 0.6559 - val_loss: 0.8044 - learning_rate: 5.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6868 - loss: 0.7177 - val_accuracy: 0.6670 - val_loss: 0.7962 - learning_rate: 5.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6933 - loss: 0.7028 - val_accuracy: 0.6718 - val_loss: 0.7912 - learning_rate: 5.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6981 - loss: 0.6970 - val_accuracy: 0.6605 - val_loss: 0.7996 - learning_rate: 5.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7005 - loss: 0.6877 - val_accuracy: 0.6531 - val_loss: 0.8303 - learning_rate: 5.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7010 - loss: 0.6849 - val_accuracy: 0.6755 - val_loss: 0.8078 - learning_rate: 5.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7050 - loss: 0.6843 - val_accuracy: 0.6732 - val_loss: 0.7976 - learning_rate: 5.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7092 - loss: 0.6711 - val_accuracy: 0.6641 - val_loss: 0.8146 - learning_rate: 5.0000e-04\n"
          ]
        }
      ],
      "source": [
        "# 1. ReduceLROnPlateau // reduce learning rate when val_accuracy stops improving\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',   # Track validation accuracy for learning rate adjustments\n",
        "    factor=0.5,               # Reduce learning rate by half when triggered\n",
        "    patience=3,               # Wait for 3 epochs of no improvement before reducing\n",
        "    min_lr=1e-5               # Set a minimum learning rate to prevent it from going too low\n",
        ")\n",
        "history = model.fit(X_train, y_train_one_hot,\n",
        "                    epochs=20,         # Train the model for 20 epochs\n",
        "                    batch_size=32,     # Use a batch size of 32\n",
        "                    validation_data=(X_test, y_test_one_hot),   # Validate on the test set after each epoch\n",
        "                    callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test"
      ],
      "metadata": {
        "id": "nMDhgymatZky"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "def test(model, X_test, y_test_one_hot):\n",
        "  # Get predicted probabilities for the test set\n",
        "  y_pred_probs = model.predict(X_test)\n",
        "\n",
        "  # Convert the predicted probabilities to class labels (taking the argmax of the probabilities)\n",
        "  y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "  # Convert the true test labels from one-hot encoding back to class labels\n",
        "  y_true_classes = np.argmax(y_test_one_hot, axis=1)\n",
        "\n",
        "  # Generate the classification report\n",
        "  report = classification_report(y_true_classes, y_pred_classes, digits=4)\n",
        "\n",
        "  # Print the classification report\n",
        "  print(report)\n",
        "\n",
        "  # Calculate and print per-class recall\n",
        "  classes = np.unique(y_true_classes)\n",
        "\n",
        "  print(\"Per-class Recall:\")\n",
        "  for cls in classes:\n",
        "      # Calculate recall for the current class\n",
        "      recall = recall_score(y_true_classes, y_pred_classes, labels=[cls], average=None)[0]\n",
        "      print(f\"Class {cls}: {recall:.4f}\")\n",
        "\n",
        "  # Calculate accuracy for each class\n",
        "  for cls in classes:\n",
        "      # Get indices for the current class\n",
        "      cls_indices = (y_true_classes == cls)\n",
        "\n",
        "      # Include both true positives (correctly predicted for this class) and true negatives (correctly not predicted as this class)\n",
        "      cls_accuracy = np.mean((y_pred_classes == cls) == (y_true_classes == cls))\n",
        "\n",
        "      # Store the accuracy in the dictionary\n",
        "      per_class_accuracy[cls] = cls_accuracy\n",
        "\n",
        "  # Print the per-class accuracy\n",
        "  print(\"Per-class Accuracy:\")\n",
        "  for cls, acc in per_class_accuracy.items():\n",
        "      print(f\"Class {cls}: {acc:.4f}\")\n",
        "\n",
        "test(model,X_test,y_test_one_hot)"
      ],
      "metadata": {
        "id": "szdIRsFTtQvI",
        "outputId": "f53f1fa3-b45c-4692-f9fd-0c0691d287fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m449/449\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7070    0.5276    0.6042      2794\n",
            "           1     0.7234    0.6579    0.6891      2163\n",
            "           2     0.6370    0.2483    0.3573      2163\n",
            "           3     0.6447    0.8434    0.7308      7217\n",
            "\n",
            "    accuracy                         0.6641     14337\n",
            "   macro avg     0.6780    0.5693    0.5953     14337\n",
            "weighted avg     0.6675    0.6641    0.6435     14337\n",
            "\n",
            "Per-class Recall:\n",
            "Class 0: 0.5276\n",
            "Class 1: 0.6579\n",
            "Class 2: 0.2483\n",
            "Class 3: 0.8434\n",
            "Per-class Accuracy:\n",
            "Class 0: 0.8653\n",
            "Class 1: 0.9104\n",
            "Class 2: 0.8652\n",
            "Class 3: 0.6872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34ozkk6SWnhn"
      },
      "source": [
        "## 2. automatic hyperparameter tuner:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PzB5Pk13Wnhn",
        "outputId": "7390cff1-7c87-4954-d308-48fe82eb73f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.13.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hM5B3rgaWnhn"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, LSTM\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "okhINpxmWnhn"
      },
      "outputs": [],
      "source": [
        "def build_tuning_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    # First Conv1D Layer\n",
        "    model.add(Conv1D(\n",
        "        filters=hp.Choice('filters_1', values=[64, 128, 256]),\n",
        "        kernel_size=hp.Choice('kernel_size_1', values=[3, 5, 7]),\n",
        "        activation='relu',\n",
        "        input_shape=input_shape\n",
        "    ))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Dropout(rate=hp.Choice('dropout_1', values=[0.3, 0.5, 0.6])))\n",
        "\n",
        "    # Second Conv1D Layer\n",
        "    model.add(Conv1D(\n",
        "        filters=hp.Choice('filters_2', values=[64, 128, 256]),\n",
        "        kernel_size=hp.Choice('kernel_size_2', values=[3, 5, 7]),\n",
        "        activation='relu',\n",
        "        kernel_regularizer=l2(hp.Choice('l2_regularization', values=[1e-4, 1e-3]))\n",
        "    ))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Dropout(rate=hp.Choice('dropout_2', values=[0.3, 0.5, 0.6])))\n",
        "\n",
        "    # Optional LSTM Layer\n",
        "    if hp.Boolean(\"use_lstm\"):\n",
        "        model.add(LSTM(units=hp.Choice('lstm_units', values=[32, 64, 128]), return_sequences=False))\n",
        "\n",
        "    # Dense Layers\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(128, activation='relu')) #gpt suggested 64 but original model has 128\n",
        "\n",
        "    model.add(Dropout(rate=hp.Choice('dropout_3', values=[0.3, 0.5, 0.6])))\n",
        "\n",
        "    model.add(Dense(num_classes, activation='softmax'))  # Assuming 4 classes for respiratory activities\n",
        "\n",
        "    # Compile Model\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTydgS71Wnhn",
        "outputId": "2dc0b892-04f0-4fa5-af18-7d9f042a5784",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 20 Complete [00h 02m 25s]\n",
            "val_accuracy: 0.5933031141757965\n",
            "\n",
            "Best val_accuracy So Far: 0.6573770344257355\n",
            "Total elapsed time: 01h 20m 36s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv1d (\u001b[38;5;33mConv1D\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m256\u001b[0m)                        \u001b[38;5;34m2,560\u001b[0m \n",
              "\n",
              " batch_normalization                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m256\u001b[0m)                        \u001b[38;5;34m1,024\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
              "\n",
              " max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)          (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout (\u001b[38;5;33mDropout\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)                      \u001b[38;5;34m163,968\u001b[0m \n",
              "\n",
              " batch_normalization_1                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)                          \u001b[38;5;34m512\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
              "\n",
              " max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " lstm (\u001b[38;5;33mLSTM\u001b[0m)                           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                            \u001b[38;5;34m49,408\u001b[0m \n",
              "\n",
              " flatten (\u001b[38;5;33mFlatten\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                                 \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense (\u001b[38;5;33mDense\u001b[0m)                         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            \u001b[38;5;34m8,320\u001b[0m \n",
              "\n",
              " dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_1 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                                \u001b[38;5;34m516\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> \n",
              "\n",
              " batch_normalization                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
              "\n",
              " max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)          (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> \n",
              "\n",
              " batch_normalization_1                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
              "\n",
              " max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> \n",
              "\n",
              " flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> \n",
              "\n",
              " dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m226,308\u001b[0m (884.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">226,308</span> (884.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m225,540\u001b[0m (881.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,540</span> (881.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:576: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 32 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m448/448\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6717 - loss: 0.8577\n",
            "Results summary\n",
            "Results in my_tuning_dir/respiratory_activity_classification_no_gyro\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_accuracy\", direction=\"max\")\n",
            "\n",
            "Trial 16 summary\n",
            "Hyperparameters:\n",
            "filters_1: 256\n",
            "kernel_size_1: 3\n",
            "dropout_1: 0.3\n",
            "filters_2: 128\n",
            "kernel_size_2: 5\n",
            "l2_regularization: 0.001\n",
            "dropout_2: 0.3\n",
            "use_lstm: True\n",
            "dropout_3: 0.3\n",
            "learning_rate: 0.001\n",
            "lstm_units: 64\n",
            "Score: 0.6573770344257355\n",
            "\n",
            "Trial 11 summary\n",
            "Hyperparameters:\n",
            "filters_1: 256\n",
            "kernel_size_1: 3\n",
            "dropout_1: 0.3\n",
            "filters_2: 128\n",
            "kernel_size_2: 7\n",
            "l2_regularization: 0.001\n",
            "dropout_2: 0.5\n",
            "use_lstm: True\n",
            "dropout_3: 0.6\n",
            "learning_rate: 0.001\n",
            "lstm_units: 32\n",
            "Score: 0.6270666122436523\n",
            "\n",
            "Trial 05 summary\n",
            "Hyperparameters:\n",
            "filters_1: 256\n",
            "kernel_size_1: 3\n",
            "dropout_1: 0.5\n",
            "filters_2: 128\n",
            "kernel_size_2: 5\n",
            "l2_regularization: 0.0001\n",
            "dropout_2: 0.6\n",
            "use_lstm: False\n",
            "dropout_3: 0.6\n",
            "learning_rate: 0.001\n",
            "lstm_units: 128\n",
            "Score: 0.6212417185306549\n",
            "\n",
            "Trial 00 summary\n",
            "Hyperparameters:\n",
            "filters_1: 64\n",
            "kernel_size_1: 3\n",
            "dropout_1: 0.3\n",
            "filters_2: 128\n",
            "kernel_size_2: 3\n",
            "l2_regularization: 0.0001\n",
            "dropout_2: 0.5\n",
            "use_lstm: False\n",
            "dropout_3: 0.5\n",
            "learning_rate: 0.001\n",
            "Score: 0.6166724860668182\n",
            "\n",
            "Trial 17 summary\n",
            "Hyperparameters:\n",
            "filters_1: 128\n",
            "kernel_size_1: 5\n",
            "dropout_1: 0.6\n",
            "filters_2: 64\n",
            "kernel_size_2: 7\n",
            "l2_regularization: 0.001\n",
            "dropout_2: 0.5\n",
            "use_lstm: False\n",
            "dropout_3: 0.5\n",
            "learning_rate: 0.001\n",
            "lstm_units: 64\n",
            "Score: 0.6162539422512054\n",
            "\n",
            "Trial 08 summary\n",
            "Hyperparameters:\n",
            "filters_1: 256\n",
            "kernel_size_1: 5\n",
            "dropout_1: 0.6\n",
            "filters_2: 256\n",
            "kernel_size_2: 3\n",
            "l2_regularization: 0.001\n",
            "dropout_2: 0.6\n",
            "use_lstm: True\n",
            "dropout_3: 0.5\n",
            "learning_rate: 0.001\n",
            "lstm_units: 64\n",
            "Score: 0.5987443327903748\n",
            "\n",
            "Trial 19 summary\n",
            "Hyperparameters:\n",
            "filters_1: 128\n",
            "kernel_size_1: 5\n",
            "dropout_1: 0.6\n",
            "filters_2: 128\n",
            "kernel_size_2: 7\n",
            "l2_regularization: 0.0001\n",
            "dropout_2: 0.5\n",
            "use_lstm: False\n",
            "dropout_3: 0.6\n",
            "learning_rate: 0.001\n",
            "lstm_units: 64\n",
            "Score: 0.5933031141757965\n",
            "\n",
            "Trial 12 summary\n",
            "Hyperparameters:\n",
            "filters_1: 128\n",
            "kernel_size_1: 5\n",
            "dropout_1: 0.6\n",
            "filters_2: 128\n",
            "kernel_size_2: 5\n",
            "l2_regularization: 0.0001\n",
            "dropout_2: 0.3\n",
            "use_lstm: True\n",
            "dropout_3: 0.6\n",
            "learning_rate: 0.0001\n",
            "lstm_units: 64\n",
            "Score: 0.5862922966480255\n",
            "\n",
            "Trial 01 summary\n",
            "Hyperparameters:\n",
            "filters_1: 64\n",
            "kernel_size_1: 3\n",
            "dropout_1: 0.5\n",
            "filters_2: 64\n",
            "kernel_size_2: 7\n",
            "l2_regularization: 0.0001\n",
            "dropout_2: 0.6\n",
            "use_lstm: True\n",
            "dropout_3: 0.6\n",
            "learning_rate: 0.001\n",
            "lstm_units: 32\n",
            "Score: 0.5854202806949615\n",
            "\n",
            "Trial 06 summary\n",
            "Hyperparameters:\n",
            "filters_1: 64\n",
            "kernel_size_1: 5\n",
            "dropout_1: 0.3\n",
            "filters_2: 128\n",
            "kernel_size_2: 3\n",
            "l2_regularization: 0.0001\n",
            "dropout_2: 0.5\n",
            "use_lstm: True\n",
            "dropout_3: 0.5\n",
            "learning_rate: 0.0001\n",
            "lstm_units: 128\n",
            "Score: 0.5834321677684784\n"
          ]
        }
      ],
      "source": [
        "tuner = kt.RandomSearch(\n",
        "    build_tuning_model,\n",
        "    objective='val_accuracy',  # Tuning for validation accuracy\n",
        "    max_trials=20,             # Number of different hyperparameter sets to try\n",
        "    executions_per_trial=2,    # Average results over multiple runs to reduce variance\n",
        "    directory='my_tuning_dir', # Directory to save tuning results\n",
        "    project_name='respiratory_activity_classification_no_gyro'\n",
        ")\n",
        "\n",
        "# Split your data if not already done\n",
        "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "tuner.search(X_train, y_train_one_hot,\n",
        "             epochs=20,               # Number of epochs for each trial\n",
        "             validation_data=(X_test, y_test_one_hot),\n",
        "             callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)])\n",
        "\n",
        "best_model1 = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Evaluate the best model\n",
        "best_model1.evaluate(X_test, y_test_one_hot)  # Replace with your test data\n",
        "tuner.results_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test"
      ],
      "metadata": {
        "id": "GPowWtrTujjf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CAVdBFILvQJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## best model previous tuner found on last year's data"
      ],
      "metadata": {
        "id": "Bojxlesy_5Zs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "C7ZSLu9uWnho",
        "outputId": "df7db4f7-b7fc-443f-839a-ffa0cbcd3644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv1d_14 (\u001b[38;5;33mConv1D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)                        \u001b[38;5;34m2,048\u001b[0m \n",
              "\n",
              " batch_normalization_12                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)                          \u001b[38;5;34m512\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
              "\n",
              " max_pooling1d_14 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_19 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv1d_15 (\u001b[38;5;33mConv1D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m164,096\u001b[0m \n",
              "\n",
              " batch_normalization_13                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)                        \u001b[38;5;34m1,024\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
              "\n",
              " max_pooling1d_15 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)                             \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_20 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)                             \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                          \u001b[38;5;34m197,120\u001b[0m \n",
              "\n",
              " flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_14 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                           \u001b[38;5;34m16,512\u001b[0m \n",
              "\n",
              " dropout_21 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_15 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                                \u001b[38;5;34m516\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " conv1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \n",
              "\n",
              " batch_normalization_12                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
              "\n",
              " max_pooling1d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">164,096</span> \n",
              "\n",
              " batch_normalization_13                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
              "\n",
              " max_pooling1d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> \n",
              "\n",
              " flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> \n",
              "\n",
              " dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m381,828\u001b[0m (1.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">381,828</span> (1.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m381,060\u001b[0m (1.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">381,060</span> (1.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# best model tuning found:\n",
        "def build_best_tuning_model(custom_input_shape=input_shape):\n",
        "    model = Sequential()\n",
        "\n",
        "    # First Conv1D Layer\n",
        "    model.add(Conv1D(\n",
        "        filters=128,\n",
        "        kernel_size=5,\n",
        "        activation='relu',\n",
        "        input_shape=custom_input_shape\n",
        "    ))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Dropout(rate=0.3))\n",
        "\n",
        "    # Second Conv1D Layer\n",
        "    model.add(Conv1D(\n",
        "        filters=256,\n",
        "        kernel_size=5,\n",
        "        activation='relu',\n",
        "        kernel_regularizer=l2(1e-3)\n",
        "    ))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Dropout(rate=0.3))\n",
        "\n",
        "    # Optional LSTM Layer\n",
        "    model.add(LSTM(units=128, return_sequences=False))\n",
        "\n",
        "    # Dense Layers\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(128, activation='relu')) #gpt suggested 64 but original model has 128\n",
        "\n",
        "    model.add(Dropout(rate=0.3))\n",
        "\n",
        "    model.add(Dense(num_classes, activation='softmax'))  # Assuming 4 classes for respiratory activities\n",
        "\n",
        "    # Compile Model\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "best_model = build_best_tuning_model()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = best_model.fit(X_train, y_train_one_hot,\n",
        "                    epochs=20,         # Train the model for 20 epochs\n",
        "                    batch_size=32,     # Use a batch size of 32\n",
        "                    validation_data=(X_test, y_test_one_hot)   # Validate on the test set after each epoch\n",
        "                )"
      ],
      "metadata": {
        "id": "CyRlkZinAK83",
        "outputId": "e6339c7a-ddd0-49ed-97e5-76d3a632737b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.5083 - loss: 1.3303 - val_accuracy: 0.5676 - val_loss: 1.0695\n",
            "Epoch 2/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.5527 - loss: 1.1055 - val_accuracy: 0.5994 - val_loss: 1.0007\n",
            "Epoch 3/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.5726 - loss: 1.0306 - val_accuracy: 0.6071 - val_loss: 0.9701\n",
            "Epoch 4/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.5997 - loss: 0.9800 - val_accuracy: 0.6376 - val_loss: 0.9152\n",
            "Epoch 5/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6122 - loss: 0.9618 - val_accuracy: 0.6545 - val_loss: 0.8686\n",
            "Epoch 6/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6190 - loss: 0.9281 - val_accuracy: 0.6560 - val_loss: 0.8701\n",
            "Epoch 7/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6342 - loss: 0.8979 - val_accuracy: 0.6383 - val_loss: 0.8648\n",
            "Epoch 8/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6346 - loss: 0.8926 - val_accuracy: 0.6312 - val_loss: 0.8805\n",
            "Epoch 9/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6461 - loss: 0.8699 - val_accuracy: 0.6330 - val_loss: 0.8730\n",
            "Epoch 10/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6454 - loss: 0.8694 - val_accuracy: 0.6453 - val_loss: 0.8513\n",
            "Epoch 11/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6520 - loss: 0.8602 - val_accuracy: 0.6198 - val_loss: 0.8698\n",
            "Epoch 12/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6604 - loss: 0.8386 - val_accuracy: 0.6324 - val_loss: 0.8517\n",
            "Epoch 13/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6538 - loss: 0.8447 - val_accuracy: 0.6305 - val_loss: 0.8557\n",
            "Epoch 14/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6617 - loss: 0.8401 - val_accuracy: 0.6593 - val_loss: 0.8124\n",
            "Epoch 15/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6658 - loss: 0.8230 - val_accuracy: 0.6714 - val_loss: 0.8128\n",
            "Epoch 16/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6706 - loss: 0.8161 - val_accuracy: 0.6144 - val_loss: 0.8977\n",
            "Epoch 17/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6735 - loss: 0.8031 - val_accuracy: 0.6699 - val_loss: 0.8102\n",
            "Epoch 18/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6774 - loss: 0.8035 - val_accuracy: 0.6363 - val_loss: 0.8367\n",
            "Epoch 19/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6754 - loss: 0.8043 - val_accuracy: 0.6616 - val_loss: 0.8041\n",
            "Epoch 20/20\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6798 - loss: 0.7936 - val_accuracy: 0.6845 - val_loss: 0.7797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test"
      ],
      "metadata": {
        "id": "S81T3q7NvT3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test(best_model,X_test,y_test_one_hot)"
      ],
      "metadata": {
        "id": "md3FI_XjvUxr",
        "outputId": "db9d8037-c39d-441f-fc9d-144044ce263d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m449/449\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6626    0.6016    0.6307      2794\n",
            "           1     0.8304    0.5479    0.6602      2163\n",
            "           2     0.7044    0.4087    0.5173      2163\n",
            "           3     0.6649    0.8401    0.7423      7217\n",
            "\n",
            "    accuracy                         0.6845     14337\n",
            "   macro avg     0.7156    0.5996    0.6376     14337\n",
            "weighted avg     0.6954    0.6845    0.6742     14337\n",
            "\n",
            "Per-class Recall:\n",
            "Class 0: 0.6016\n",
            "Class 1: 0.5479\n",
            "Class 2: 0.4087\n",
            "Class 3: 0.8401\n",
            "Per-class Accuracy:\n",
            "Class 0: 0.8627\n",
            "Class 1: 0.9149\n",
            "Class 2: 0.8849\n",
            "Class 3: 0.7064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5-fold cross-validation"
      ],
      "metadata": {
        "id": "V3Yj2rsbARcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Combine training and testing data\n",
        "X = np.concatenate((X_train, X_test), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "# Set up 5-fold cross-validation\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "class_accuracies = {}  # To store per-class accuracies across folds\n",
        "\n",
        "fold_no = 1\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "    X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
        "    y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
        "\n",
        "    # One-hot encode labels\n",
        "    num_classes = 4\n",
        "    y_train_fold_one_hot = to_categorical(y_train_fold, num_classes)\n",
        "    y_test_fold_one_hot = to_categorical(y_test_fold, num_classes)\n",
        "\n",
        "    # Build and compile the model\n",
        "    model = build_best_tuning_model()\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train_fold, y_train_fold_one_hot,\n",
        "                        epochs=20,\n",
        "                        batch_size=32,\n",
        "                        validation_data=(X_test_fold, y_test_fold_one_hot))\n",
        "\n",
        "    # Evaluate the model\n",
        "    scores = model.evaluate(X_test_fold, y_test_fold_one_hot, verbose=0)\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "\n",
        "    acc_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "\n",
        "    # Get predictions\n",
        "    y_pred_fold = model.predict(X_test_fold)\n",
        "    y_pred_classes = np.argmax(y_pred_fold, axis=1)\n",
        "    y_true_classes = np.argmax(y_test_fold_one_hot, axis=1)\n",
        "\n",
        "    # Print classification report\n",
        "    print(f'Classification Report for fold {fold_no}:')\n",
        "    print(classification_report(y_true_classes, y_pred_classes))\n",
        "\n",
        "    # Collect per-class accuracies\n",
        "    unique_classes = np.unique(y_true_classes)\n",
        "    for cls in unique_classes:\n",
        "        cls_indices = np.where(y_true_classes == cls)\n",
        "        cls_accuracy = accuracy_score(y_true_classes[cls_indices], y_pred_classes[cls_indices])\n",
        "        if cls not in class_accuracies:\n",
        "            class_accuracies[cls] = []\n",
        "        class_accuracies[cls].append(cls_accuracy)\n",
        "\n",
        "    fold_no += 1\n",
        "\n",
        "# Print the average scores\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(len(acc_per_fold)):\n",
        "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)}% (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')\n",
        "\n",
        "# Print average per-class accuracies over all folds\n",
        "print('Average Per-Class Accuracies over all folds:')\n",
        "for cls in unique_classes:\n",
        "    avg_accuracy = np.mean(class_accuracies[cls])\n",
        "    print(f'Class {cls}: {avg_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "376ImY84AUwc",
        "outputId": "3b68c0e3-0fcb-42b6-a34a-501078fc48d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for fold 1 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)                        \u001b[38;5;34m2,048\u001b[0m \n",
              "\n",
              " batch_normalization_2                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)                          \u001b[38;5;34m512\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
              "\n",
              " max_pooling1d_4 (\u001b[38;5;33mMaxPooling1D\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m164,096\u001b[0m \n",
              "\n",
              " batch_normalization_3                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)                        \u001b[38;5;34m1,024\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
              "\n",
              " max_pooling1d_5 (\u001b[38;5;33mMaxPooling1D\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)                             \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)                             \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                          \u001b[38;5;34m197,120\u001b[0m \n",
              "\n",
              " flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_4 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                           \u001b[38;5;34m16,512\u001b[0m \n",
              "\n",
              " dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_5 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                                \u001b[38;5;34m516\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \n",
              "\n",
              " batch_normalization_2                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
              "\n",
              " max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">164,096</span> \n",
              "\n",
              " batch_normalization_3                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
              "\n",
              " max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> \n",
              "\n",
              " flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> \n",
              "\n",
              " dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m381,828\u001b[0m (1.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">381,828</span> (1.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m381,060\u001b[0m (1.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">381,060</span> (1.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 9ms/step - accuracy: 0.5150 - loss: 1.3213 - val_accuracy: 0.5466 - val_loss: 1.2030\n",
            "Epoch 2/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.5530 - loss: 1.1067 - val_accuracy: 0.5692 - val_loss: 1.0307\n",
            "Epoch 3/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.5769 - loss: 1.0335 - val_accuracy: 0.6044 - val_loss: 0.9552\n",
            "Epoch 4/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6025 - loss: 0.9818 - val_accuracy: 0.6180 - val_loss: 0.9426\n",
            "Epoch 5/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6148 - loss: 0.9658 - val_accuracy: 0.5722 - val_loss: 0.9767\n",
            "Epoch 6/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6171 - loss: 0.9449 - val_accuracy: 0.6279 - val_loss: 0.8858\n",
            "Epoch 7/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6288 - loss: 0.9127 - val_accuracy: 0.6292 - val_loss: 0.9105\n",
            "Epoch 8/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6361 - loss: 0.9061 - val_accuracy: 0.6260 - val_loss: 0.9081\n",
            "Epoch 9/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6396 - loss: 0.8842 - val_accuracy: 0.6589 - val_loss: 0.8519\n",
            "Epoch 10/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6491 - loss: 0.8646 - val_accuracy: 0.6552 - val_loss: 0.8486\n",
            "Epoch 11/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6575 - loss: 0.8569 - val_accuracy: 0.6165 - val_loss: 0.8718\n",
            "Epoch 12/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6587 - loss: 0.8526 - val_accuracy: 0.6728 - val_loss: 0.8320\n",
            "Epoch 13/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6562 - loss: 0.8438 - val_accuracy: 0.6840 - val_loss: 0.8015\n",
            "Epoch 14/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6549 - loss: 0.8491 - val_accuracy: 0.6128 - val_loss: 0.8636\n",
            "Epoch 15/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6580 - loss: 0.8386 - val_accuracy: 0.6323 - val_loss: 0.8390\n",
            "Epoch 16/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6681 - loss: 0.8203 - val_accuracy: 0.6751 - val_loss: 0.8036\n",
            "Epoch 17/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6668 - loss: 0.8195 - val_accuracy: 0.6777 - val_loss: 0.7870\n",
            "Epoch 18/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6701 - loss: 0.8171 - val_accuracy: 0.6707 - val_loss: 0.7889\n",
            "Epoch 19/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6724 - loss: 0.8021 - val_accuracy: 0.6283 - val_loss: 0.8419\n",
            "Epoch 20/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6778 - loss: 0.7985 - val_accuracy: 0.6521 - val_loss: 0.8183\n",
            "Score for fold 1: loss of 0.8182913661003113; compile_metrics of 65.20888805389404%\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Classification Report for fold 1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.90      0.64      2780\n",
            "           1       0.76      0.65      0.70      2156\n",
            "           2       0.78      0.42      0.55      2166\n",
            "           3       0.72      0.63      0.67      7212\n",
            "\n",
            "    accuracy                           0.65     14314\n",
            "   macro avg       0.69      0.65      0.64     14314\n",
            "weighted avg       0.69      0.65      0.65     14314\n",
            "\n",
            "Training for fold 2 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)                        \u001b[38;5;34m2,048\u001b[0m \n",
              "\n",
              " batch_normalization_4                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)                          \u001b[38;5;34m512\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
              "\n",
              " max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m164,096\u001b[0m \n",
              "\n",
              " batch_normalization_5                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)                        \u001b[38;5;34m1,024\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
              "\n",
              " max_pooling1d_7 (\u001b[38;5;33mMaxPooling1D\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)                             \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)                             \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                          \u001b[38;5;34m197,120\u001b[0m \n",
              "\n",
              " flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_6 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                           \u001b[38;5;34m16,512\u001b[0m \n",
              "\n",
              " dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_7 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                                \u001b[38;5;34m516\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \n",
              "\n",
              " batch_normalization_4                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
              "\n",
              " max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">164,096</span> \n",
              "\n",
              " batch_normalization_5                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
              "\n",
              " max_pooling1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> \n",
              "\n",
              " flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> \n",
              "\n",
              " dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m381,828\u001b[0m (1.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">381,828</span> (1.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m381,060\u001b[0m (1.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">381,060</span> (1.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.5124 - loss: 1.3234 - val_accuracy: 0.5495 - val_loss: 1.1157\n",
            "Epoch 2/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.5482 - loss: 1.1102 - val_accuracy: 0.5840 - val_loss: 0.9895\n",
            "Epoch 3/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.5718 - loss: 1.0323 - val_accuracy: 0.5903 - val_loss: 0.9817\n",
            "Epoch 4/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.5923 - loss: 0.9896 - val_accuracy: 0.6063 - val_loss: 0.9517\n",
            "Epoch 5/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6003 - loss: 0.9665 - val_accuracy: 0.5975 - val_loss: 0.9677\n",
            "Epoch 6/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6123 - loss: 0.9420 - val_accuracy: 0.6269 - val_loss: 0.9127\n",
            "Epoch 7/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6268 - loss: 0.9182 - val_accuracy: 0.5816 - val_loss: 0.9469\n",
            "Epoch 8/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6292 - loss: 0.9017 - val_accuracy: 0.6345 - val_loss: 0.8514\n",
            "Epoch 9/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6337 - loss: 0.8924 - val_accuracy: 0.6462 - val_loss: 0.8660\n",
            "Epoch 10/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6363 - loss: 0.8835 - val_accuracy: 0.6210 - val_loss: 0.8784\n",
            "Epoch 11/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6474 - loss: 0.8605 - val_accuracy: 0.6258 - val_loss: 0.8763\n",
            "Epoch 12/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6509 - loss: 0.8595 - val_accuracy: 0.6306 - val_loss: 0.8721\n",
            "Epoch 13/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6455 - loss: 0.8696 - val_accuracy: 0.6649 - val_loss: 0.8254\n",
            "Epoch 14/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6558 - loss: 0.8432 - val_accuracy: 0.6723 - val_loss: 0.8112\n",
            "Epoch 15/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6629 - loss: 0.8290 - val_accuracy: 0.6297 - val_loss: 0.8558\n",
            "Epoch 16/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6642 - loss: 0.8228 - val_accuracy: 0.6739 - val_loss: 0.7982\n",
            "Epoch 17/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6668 - loss: 0.8151 - val_accuracy: 0.6766 - val_loss: 0.7929\n",
            "Epoch 18/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6711 - loss: 0.8061 - val_accuracy: 0.6735 - val_loss: 0.7681\n",
            "Epoch 19/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6705 - loss: 0.8065 - val_accuracy: 0.6483 - val_loss: 0.8314\n",
            "Epoch 20/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6708 - loss: 0.8039 - val_accuracy: 0.6397 - val_loss: 0.8121\n",
            "Score for fold 2: loss of 0.8121108412742615; compile_metrics of 63.97233605384827%\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Classification Report for fold 2:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.91      0.64      2779\n",
            "           1       0.78      0.58      0.67      2157\n",
            "           2       0.75      0.41      0.53      2166\n",
            "           3       0.70      0.62      0.66      7212\n",
            "\n",
            "    accuracy                           0.64     14314\n",
            "   macro avg       0.68      0.63      0.63     14314\n",
            "weighted avg       0.68      0.64      0.64     14314\n",
            "\n",
            "Training for fold 3 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)                        \u001b[38;5;34m2,048\u001b[0m \n",
              "\n",
              " batch_normalization_6                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)                          \u001b[38;5;34m512\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
              "\n",
              " max_pooling1d_8 (\u001b[38;5;33mMaxPooling1D\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m164,096\u001b[0m \n",
              "\n",
              " batch_normalization_7                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)                        \u001b[38;5;34m1,024\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
              "\n",
              " max_pooling1d_9 (\u001b[38;5;33mMaxPooling1D\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)                             \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_11 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)                             \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                          \u001b[38;5;34m197,120\u001b[0m \n",
              "\n",
              " flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_8 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                           \u001b[38;5;34m16,512\u001b[0m \n",
              "\n",
              " dropout_12 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_9 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                                \u001b[38;5;34m516\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \n",
              "\n",
              " batch_normalization_6                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
              "\n",
              " max_pooling1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">164,096</span> \n",
              "\n",
              " batch_normalization_7                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
              "\n",
              " max_pooling1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> \n",
              "\n",
              " flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> \n",
              "\n",
              " dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m381,828\u001b[0m (1.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">381,828</span> (1.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m381,060\u001b[0m (1.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">381,060</span> (1.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.5156 - loss: 1.3194 - val_accuracy: 0.5448 - val_loss: 1.2015\n",
            "Epoch 2/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.5550 - loss: 1.1160 - val_accuracy: 0.5821 - val_loss: 1.0511\n",
            "Epoch 3/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.5796 - loss: 1.0403 - val_accuracy: 0.6050 - val_loss: 0.9953\n",
            "Epoch 4/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6074 - loss: 0.9833 - val_accuracy: 0.6094 - val_loss: 0.9577\n",
            "Epoch 5/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6143 - loss: 0.9592 - val_accuracy: 0.6284 - val_loss: 0.9055\n",
            "Epoch 6/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6234 - loss: 0.9275 - val_accuracy: 0.6553 - val_loss: 0.8668\n",
            "Epoch 7/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6357 - loss: 0.9019 - val_accuracy: 0.6509 - val_loss: 0.8717\n",
            "Epoch 8/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6398 - loss: 0.8875 - val_accuracy: 0.6552 - val_loss: 0.8706\n",
            "Epoch 9/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6433 - loss: 0.8832 - val_accuracy: 0.6223 - val_loss: 0.8926\n",
            "Epoch 10/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6460 - loss: 0.8706 - val_accuracy: 0.6651 - val_loss: 0.8562\n",
            "Epoch 11/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6531 - loss: 0.8616 - val_accuracy: 0.6323 - val_loss: 0.8569\n",
            "Epoch 12/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6520 - loss: 0.8573 - val_accuracy: 0.6160 - val_loss: 0.8898\n",
            "Epoch 13/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6587 - loss: 0.8429 - val_accuracy: 0.6631 - val_loss: 0.8082\n",
            "Epoch 14/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6612 - loss: 0.8324 - val_accuracy: 0.6725 - val_loss: 0.8172\n",
            "Epoch 15/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6662 - loss: 0.8239 - val_accuracy: 0.6836 - val_loss: 0.7902\n",
            "Epoch 16/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6695 - loss: 0.8134 - val_accuracy: 0.6446 - val_loss: 0.8554\n",
            "Epoch 17/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6691 - loss: 0.8138 - val_accuracy: 0.6536 - val_loss: 0.8293\n",
            "Epoch 18/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6707 - loss: 0.8146 - val_accuracy: 0.6687 - val_loss: 0.7920\n",
            "Epoch 19/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6761 - loss: 0.7977 - val_accuracy: 0.6560 - val_loss: 0.8357\n",
            "Epoch 20/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6788 - loss: 0.7933 - val_accuracy: 0.6674 - val_loss: 0.7980\n",
            "Score for fold 3: loss of 0.7979980707168579; compile_metrics of 66.74351692199707%\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Classification Report for fold 3:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.80      0.64      2779\n",
            "           1       0.77      0.64      0.70      2157\n",
            "           2       0.71      0.50      0.59      2166\n",
            "           3       0.71      0.68      0.69      7211\n",
            "\n",
            "    accuracy                           0.67     14313\n",
            "   macro avg       0.68      0.65      0.65     14313\n",
            "weighted avg       0.69      0.67      0.67     14313\n",
            "\n",
            "Training for fold 4 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)                        \u001b[38;5;34m2,048\u001b[0m \n",
              "\n",
              " batch_normalization_8                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)                          \u001b[38;5;34m512\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
              "\n",
              " max_pooling1d_10 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_13 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m164,096\u001b[0m \n",
              "\n",
              " batch_normalization_9                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)                        \u001b[38;5;34m1,024\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
              "\n",
              " max_pooling1d_11 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)                             \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_14 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)                             \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                          \u001b[38;5;34m197,120\u001b[0m \n",
              "\n",
              " flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_10 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                           \u001b[38;5;34m16,512\u001b[0m \n",
              "\n",
              " dropout_15 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_11 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                                \u001b[38;5;34m516\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \n",
              "\n",
              " batch_normalization_8                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
              "\n",
              " max_pooling1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">164,096</span> \n",
              "\n",
              " batch_normalization_9                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
              "\n",
              " max_pooling1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> \n",
              "\n",
              " flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> \n",
              "\n",
              " dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m381,828\u001b[0m (1.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">381,828</span> (1.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m381,060\u001b[0m (1.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">381,060</span> (1.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.5134 - loss: 1.3260 - val_accuracy: 0.5593 - val_loss: 1.1203\n",
            "Epoch 2/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.5607 - loss: 1.0985 - val_accuracy: 0.5828 - val_loss: 1.0340\n",
            "Epoch 3/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.5819 - loss: 1.0313 - val_accuracy: 0.6009 - val_loss: 1.0034\n",
            "Epoch 4/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.5957 - loss: 1.0032 - val_accuracy: 0.6113 - val_loss: 0.9452\n",
            "Epoch 5/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6112 - loss: 0.9626 - val_accuracy: 0.6238 - val_loss: 0.9279\n",
            "Epoch 6/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6221 - loss: 0.9360 - val_accuracy: 0.6086 - val_loss: 0.9482\n",
            "Epoch 7/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6290 - loss: 0.9138 - val_accuracy: 0.6225 - val_loss: 0.9265\n",
            "Epoch 8/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6312 - loss: 0.8990 - val_accuracy: 0.6440 - val_loss: 0.8584\n",
            "Epoch 9/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6366 - loss: 0.8863 - val_accuracy: 0.6121 - val_loss: 0.9054\n",
            "Epoch 10/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6399 - loss: 0.8813 - val_accuracy: 0.6087 - val_loss: 0.9118\n",
            "Epoch 11/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6467 - loss: 0.8677 - val_accuracy: 0.6710 - val_loss: 0.8119\n",
            "Epoch 12/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6459 - loss: 0.8592 - val_accuracy: 0.6506 - val_loss: 0.8625\n",
            "Epoch 13/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6545 - loss: 0.8471 - val_accuracy: 0.6616 - val_loss: 0.8226\n",
            "Epoch 14/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6565 - loss: 0.8355 - val_accuracy: 0.6579 - val_loss: 0.8010\n",
            "Epoch 15/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6586 - loss: 0.8266 - val_accuracy: 0.6632 - val_loss: 0.8230\n",
            "Epoch 16/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6653 - loss: 0.8223 - val_accuracy: 0.6511 - val_loss: 0.8163\n",
            "Epoch 17/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6640 - loss: 0.8134 - val_accuracy: 0.6329 - val_loss: 0.8325\n",
            "Epoch 18/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6675 - loss: 0.8124 - val_accuracy: 0.6930 - val_loss: 0.7492\n",
            "Epoch 19/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6718 - loss: 0.7995 - val_accuracy: 0.6853 - val_loss: 0.7985\n",
            "Epoch 20/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6729 - loss: 0.8068 - val_accuracy: 0.6696 - val_loss: 0.7855\n",
            "Score for fold 4: loss of 0.7855247259140015; compile_metrics of 66.96010828018188%\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Classification Report for fold 4:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.78      0.64      2779\n",
            "           1       0.78      0.64      0.70      2156\n",
            "           2       0.71      0.45      0.55      2167\n",
            "           3       0.71      0.70      0.70      7211\n",
            "\n",
            "    accuracy                           0.67     14313\n",
            "   macro avg       0.69      0.64      0.65     14313\n",
            "weighted avg       0.69      0.67      0.67     14313\n",
            "\n",
            "Training for fold 5 ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)                        \u001b[38;5;34m2,048\u001b[0m \n",
              "\n",
              " batch_normalization_10                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)                          \u001b[38;5;34m512\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
              "\n",
              " max_pooling1d_12 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_16 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m164,096\u001b[0m \n",
              "\n",
              " batch_normalization_11                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)                        \u001b[38;5;34m1,024\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
              "\n",
              " max_pooling1d_13 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)                             \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_17 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)                             \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                          \u001b[38;5;34m197,120\u001b[0m \n",
              "\n",
              " flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_12 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                           \u001b[38;5;34m16,512\u001b[0m \n",
              "\n",
              " dropout_18 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_13 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                                \u001b[38;5;34m516\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \n",
              "\n",
              " batch_normalization_10                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
              "\n",
              " max_pooling1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">164,096</span> \n",
              "\n",
              " batch_normalization_11                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
              "\n",
              " max_pooling1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> \n",
              "\n",
              " flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> \n",
              "\n",
              " dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m381,828\u001b[0m (1.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">381,828</span> (1.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m381,060\u001b[0m (1.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">381,060</span> (1.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.5159 - loss: 1.3114 - val_accuracy: 0.5579 - val_loss: 1.1058\n",
            "Epoch 2/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.5645 - loss: 1.0814 - val_accuracy: 0.5902 - val_loss: 0.9951\n",
            "Epoch 3/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.5891 - loss: 1.0175 - val_accuracy: 0.6010 - val_loss: 1.0052\n",
            "Epoch 4/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6065 - loss: 0.9836 - val_accuracy: 0.6194 - val_loss: 0.9426\n",
            "Epoch 5/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6219 - loss: 0.9496 - val_accuracy: 0.6271 - val_loss: 0.9335\n",
            "Epoch 6/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6196 - loss: 0.9397 - val_accuracy: 0.6375 - val_loss: 0.9103\n",
            "Epoch 7/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6333 - loss: 0.9078 - val_accuracy: 0.6164 - val_loss: 0.9125\n",
            "Epoch 8/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6353 - loss: 0.8906 - val_accuracy: 0.6464 - val_loss: 0.8759\n",
            "Epoch 9/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6375 - loss: 0.8860 - val_accuracy: 0.6659 - val_loss: 0.8746\n",
            "Epoch 10/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6466 - loss: 0.8708 - val_accuracy: 0.6663 - val_loss: 0.8384\n",
            "Epoch 11/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6502 - loss: 0.8593 - val_accuracy: 0.6384 - val_loss: 0.8716\n",
            "Epoch 12/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6498 - loss: 0.8520 - val_accuracy: 0.6315 - val_loss: 0.8428\n",
            "Epoch 13/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6582 - loss: 0.8395 - val_accuracy: 0.6655 - val_loss: 0.8162\n",
            "Epoch 14/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6537 - loss: 0.8452 - val_accuracy: 0.6695 - val_loss: 0.8245\n",
            "Epoch 15/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6574 - loss: 0.8406 - val_accuracy: 0.6518 - val_loss: 0.8459\n",
            "Epoch 16/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6647 - loss: 0.8206 - val_accuracy: 0.6774 - val_loss: 0.8158\n",
            "Epoch 17/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6641 - loss: 0.8262 - val_accuracy: 0.6586 - val_loss: 0.8179\n",
            "Epoch 18/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6637 - loss: 0.8197 - val_accuracy: 0.6851 - val_loss: 0.7776\n",
            "Epoch 19/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6657 - loss: 0.8152 - val_accuracy: 0.6922 - val_loss: 0.7866\n",
            "Epoch 20/20\n",
            "\u001b[1m1790/1790\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6684 - loss: 0.8060 - val_accuracy: 0.6781 - val_loss: 0.7982\n",
            "Score for fold 5: loss of 0.7981600165367126; compile_metrics of 67.8054928779602%\n",
            "\u001b[1m448/448\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Classification Report for fold 5:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.73      0.65      2779\n",
            "           1       0.79      0.62      0.70      2156\n",
            "           2       0.68      0.47      0.56      2167\n",
            "           3       0.70      0.74      0.72      7211\n",
            "\n",
            "    accuracy                           0.68     14313\n",
            "   macro avg       0.69      0.64      0.65     14313\n",
            "weighted avg       0.69      0.68      0.68     14313\n",
            "\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "> Fold 1 - Loss: 0.8182913661003113 - Accuracy: 65.20888805389404%\n",
            "> Fold 2 - Loss: 0.8121108412742615 - Accuracy: 63.97233605384827%\n",
            "> Fold 3 - Loss: 0.7979980707168579 - Accuracy: 66.74351692199707%\n",
            "> Fold 4 - Loss: 0.7855247259140015 - Accuracy: 66.96010828018188%\n",
            "> Fold 5 - Loss: 0.7981600165367126 - Accuracy: 67.8054928779602%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 66.1380684375763% (+- 1.3694082355423614)\n",
            "> Loss: 0.802417004108429\n",
            "------------------------------------------------------------------------\n",
            "Average Per-Class Accuracies over all folds:\n",
            "Class 0: 82.44%\n",
            "Class 1: 62.68%\n",
            "Class 2: 45.28%\n",
            "Class 3: 67.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oHBJdUjWnho",
        "outputId": "23e8b155-56f6-4ee3-b86c-0927f294dc16"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> \n",
              "\n",
              " max_pooling1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> \n",
              "\n",
              " max_pooling1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">180,352</span> \n",
              "\n",
              " dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> \n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m1,216\u001b[0m \n",
              "\n",
              " max_pooling1d_10 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)                      \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m128\u001b[0m)                \u001b[38;5;34m24,704\u001b[0m \n",
              "\n",
              " max_pooling1d_11 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)                     \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)                        \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_10 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   \u001b[38;5;34m180,352\u001b[0m \n",
              "\n",
              " dropout_5 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_11 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                         \u001b[38;5;34m516\u001b[0m \n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">206,788</span> (807.77 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m206,788\u001b[0m (807.77 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">206,788</span> (807.77 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m206,788\u001b[0m (807.77 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# custom cell to rebuild modified versions of model\n",
        "model = build_1d_cnn_model(input_shape, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT34Pld9Wnho"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrSPBPh4KcBn"
      },
      "source": [
        "## Step 4: Evaluate the Model\n",
        "After training, you can evaluate the model on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4zICRasKPsT"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train_one_hot,\n",
        "                    epochs=20,         # Train the model for 20 epochs\n",
        "                    batch_size=32,     # Use a batch size of 32\n",
        "                    validation_data=(X_test, y_test_one_hot)   # Validate on the test set after each epoch\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB2Bi7ieKelv",
        "outputId": "6d80295e-e9dd-4783-bca4-361c14ef9ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m449/449\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6626    0.6016    0.6307      2794\n",
            "           1     0.8304    0.5479    0.6602      2163\n",
            "           2     0.7044    0.4087    0.5173      2163\n",
            "           3     0.6649    0.8401    0.7423      7217\n",
            "\n",
            "    accuracy                         0.6845     14337\n",
            "   macro avg     0.7156    0.5996    0.6376     14337\n",
            "weighted avg     0.6954    0.6845    0.6742     14337\n",
            "\n",
            "Per-class Accuracy:\n",
            "Class 0: 0.8627\n",
            "Class 1: 0.9149\n",
            "Class 2: 0.8849\n",
            "Class 3: 0.7064\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Get predicted probabilities for the test set\n",
        "y_pred_probs = best_model.predict(X_test)\n",
        "\n",
        "# Convert the predicted probabilities to class labels (taking the argmax of the probabilities)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Convert the true test labels from one-hot encoding back to class labels\n",
        "y_true_classes = np.argmax(y_test_one_hot, axis=1)\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(y_true_classes, y_pred_classes, digits=4)\n",
        "\n",
        "# Print the classification report\n",
        "print(report)\n",
        "\n",
        "# Assuming you already have y_pred_classes and y_true_classes\n",
        "# Get the unique class labels\n",
        "classes = np.unique(y_true_classes)\n",
        "\n",
        "# Initialize a dictionary to store per-class accuracy\n",
        "per_class_accuracy = {}\n",
        "\n",
        "# Calculate accuracy for each class\n",
        "for cls in classes:\n",
        "    # Get indices for the current class\n",
        "    cls_indices = (y_true_classes == cls)\n",
        "\n",
        "    # Include both true positives (correctly predicted for this class) and true negatives (correctly not predicted as this class)\n",
        "    cls_accuracy = np.mean((y_pred_classes == cls) == (y_true_classes == cls))\n",
        "\n",
        "    # Store the accuracy in the dictionary\n",
        "    per_class_accuracy[cls] = cls_accuracy\n",
        "\n",
        "# Print the per-class accuracy\n",
        "print(\"Per-class Accuracy:\")\n",
        "for cls, acc in per_class_accuracy.items():\n",
        "    print(f\"Class {cls}: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QXKh8ritRbw"
      },
      "source": [
        "As you can see from the model performance results, the classification performance isn't exactly impressive. For Coursework 3, your group should explore and experiment with various models, parameters, and techniques in order to improve your model's performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHNzGOHDtnQ4"
      },
      "source": [
        "# Exporting your model to TFLite\n",
        "\n",
        "You can use the TFLiteConverter class provided by TensorFlow to convert your trained model into the TensorFlow Lite format. We export models to TensorFlow Lite (TFLite) for several reasons, primarily because TFLite is designed for deployment on edge devices, such as mobile phones, embedded systems, IoT devices, and microcontrollers, where computational resources and power are limited. This is necessary as you will be running your ML models on your Android devices to perform live classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_QKoJtmufDa",
        "outputId": "48d281ab-4ed3-4ee1-fd47-30f7f4c10b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\luise\\AppData\\Local\\Temp\\tmppf3rz10g\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\luise\\AppData\\Local\\Temp\\tmppf3rz10g\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at 'C:\\Users\\luise\\AppData\\Local\\Temp\\tmppf3rz10g'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 50, 6), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  2847604399040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2847604400976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2847605255056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2847605246432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2847605248720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2847614338848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2847614349936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  2847614349232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Model successfully exported to model.tflite\n"
          ]
        }
      ],
      "source": [
        "# Convert the trained Keras model to TensorFlow Lite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)  # model is your trained Keras model\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the converted model to a .tflite file\n",
        "with open('model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(\"Model successfully exported to model.tflite\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGOj682D0PfS"
      },
      "source": [
        "# Good job!\n",
        "This is the end of Lab 3. In the next lab, you will focus on deploying your machine learning model onto your Android App in order to classify activities in real-time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCs_RtfjWnhp"
      },
      "source": [
        "# GPT's suggested models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model 1"
      ],
      "metadata": {
        "id": "0A8Ttqqjvp_e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "dcoVt_GCWnhp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "vm58CceDWnhp",
        "outputId": "824bfa64-473c-4f55-9d74-f620dd122ec3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.4970 - loss: 1.2566 - val_accuracy: 0.5034 - val_loss: 1.2319 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.5107 - loss: 1.2213 - val_accuracy: 0.5719 - val_loss: 1.0060 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.5495 - loss: 1.0417 - val_accuracy: 0.5908 - val_loss: 0.9288 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.5634 - loss: 0.9765 - val_accuracy: 0.5919 - val_loss: 1.0029 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.5758 - loss: 0.9397 - val_accuracy: 0.6075 - val_loss: 0.9002 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.5796 - loss: 0.9260 - val_accuracy: 0.6044 - val_loss: 0.8637 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.5861 - loss: 0.9036 - val_accuracy: 0.6067 - val_loss: 0.8868 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.5922 - loss: 0.8906 - val_accuracy: 0.6054 - val_loss: 0.8709 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.5902 - loss: 0.8942 - val_accuracy: 0.6183 - val_loss: 0.8248 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.5969 - loss: 0.8791 - val_accuracy: 0.5935 - val_loss: 0.8856 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6085 - loss: 0.8628 - val_accuracy: 0.6076 - val_loss: 0.8516 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6148 - loss: 0.8512 - val_accuracy: 0.6211 - val_loss: 0.8139 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6155 - loss: 0.8474 - val_accuracy: 0.6122 - val_loss: 0.8454 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6238 - loss: 0.8285 - val_accuracy: 0.6310 - val_loss: 0.8362 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6285 - loss: 0.8260 - val_accuracy: 0.6298 - val_loss: 0.8236 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6288 - loss: 0.8227 - val_accuracy: 0.6167 - val_loss: 0.8351 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6359 - loss: 0.8119 - val_accuracy: 0.6419 - val_loss: 0.8075 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6380 - loss: 0.8090 - val_accuracy: 0.6436 - val_loss: 0.7996 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6402 - loss: 0.8008 - val_accuracy: 0.6353 - val_loss: 0.8311 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6461 - loss: 0.7917 - val_accuracy: 0.6450 - val_loss: 0.8055 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6554 - loss: 0.7789 - val_accuracy: 0.6153 - val_loss: 0.8129 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6599 - loss: 0.7703 - val_accuracy: 0.6053 - val_loss: 0.8573 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6624 - loss: 0.7630 - val_accuracy: 0.5816 - val_loss: 0.8676 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6808 - loss: 0.7303 - val_accuracy: 0.6305 - val_loss: 0.8332 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6890 - loss: 0.7150 - val_accuracy: 0.6335 - val_loss: 0.8442 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6938 - loss: 0.7031 - val_accuracy: 0.6327 - val_loss: 0.8364 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6922 - loss: 0.7042 - val_accuracy: 0.6409 - val_loss: 0.8419 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6975 - loss: 0.6995 - val_accuracy: 0.6410 - val_loss: 0.8275 - learning_rate: 5.0000e-04\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5854 - loss: 0.8424\n",
            "Test Accuracy: 64.36%\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "breathingNormally       0.55      0.59      0.57      2794\n",
            "         coughing       0.79      0.66      0.72      2163\n",
            " hyperventilation       0.76      0.22      0.35      2163\n",
            "            other       0.64      0.79      0.70      7217\n",
            "\n",
            "         accuracy                           0.64     14337\n",
            "        macro avg       0.68      0.56      0.58     14337\n",
            "     weighted avg       0.66      0.64      0.63     14337\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define parameters\n",
        "input_shape = X_train.shape[1:]  # (window_size, num_features)\n",
        "num_classes = y_train_one_hot.shape[1]  # 4 respiratory states\n",
        "\n",
        "# Build the model\n",
        "gpt_model1 = Sequential()\n",
        "\n",
        "# Convolutional layers to capture spatial patterns\n",
        "gpt_model1.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "gpt_model1.add(MaxPooling1D(pool_size=2))\n",
        "gpt_model1.add(Dropout(0.3))\n",
        "\n",
        "gpt_model1.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
        "gpt_model1.add(MaxPooling1D(pool_size=2))\n",
        "gpt_model1.add(Dropout(0.3))\n",
        "\n",
        "# LSTM layer to capture temporal dependencies\n",
        "gpt_model1.add(LSTM(100, return_sequences=True))\n",
        "gpt_model1.add(LSTM(50))\n",
        "\n",
        "# Fully connected layers for classification\n",
        "gpt_model1.add(Dense(50, activation='relu'))\n",
        "gpt_model1.add(Dropout(0.5))\n",
        "gpt_model1.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "gpt_model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Set up callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "history = gpt_model1.fit(\n",
        "    X_train, y_train_one_hot,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test_one_hot),\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test"
      ],
      "metadata": {
        "id": "ZOFQbmRdvudM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test(gpt_model1,X_test,y_test_one_hot)"
      ],
      "metadata": {
        "id": "YQDIJrruvvWY",
        "outputId": "6231b246-051d-4db5-ece2-3e9069491378",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m449/449\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5484    0.5863    0.5667      2794\n",
            "           1     0.7913    0.6593    0.7193      2163\n",
            "           2     0.7555    0.2242    0.3458      2163\n",
            "           3     0.6375    0.7868    0.7043      7217\n",
            "\n",
            "    accuracy                         0.6436     14337\n",
            "   macro avg     0.6832    0.5641    0.5840     14337\n",
            "weighted avg     0.6612    0.6436    0.6257     14337\n",
            "\n",
            "Per-class Recall:\n",
            "Class 0: 0.5863\n",
            "Class 1: 0.6593\n",
            "Class 2: 0.2242\n",
            "Class 3: 0.7868\n",
            "Per-class Accuracy:\n",
            "Class 0: 0.8253\n",
            "Class 1: 0.9224\n",
            "Class 2: 0.8720\n",
            "Class 3: 0.6675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT52co9PWnhp"
      },
      "source": [
        "## model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "315aKR4jWnhp"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Bidirectional\n",
        "from sklearn.utils import class_weight\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "TqvssZEHWnhp"
      },
      "outputs": [],
      "source": [
        "y_true_classes = np.argmax(y_train_one_hot, axis=1)\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_true_classes), y=y_true_classes)\n",
        "class_weights_dict = dict(enumerate(class_weights))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "dXlP-iwYWnhp",
        "outputId": "734fe9fe-d2ac-47dc-99a7-bde720a4344d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13ms/step - accuracy: 0.3064 - loss: 1.3275 - val_accuracy: 0.3158 - val_loss: 1.1178 - learning_rate: 5.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.3667 - loss: 1.0835 - val_accuracy: 0.3727 - val_loss: 1.0633 - learning_rate: 5.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.3875 - loss: 1.0026 - val_accuracy: 0.3857 - val_loss: 1.0716 - learning_rate: 5.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.4146 - loss: 0.9566 - val_accuracy: 0.3776 - val_loss: 1.1026 - learning_rate: 5.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.4288 - loss: 0.9323 - val_accuracy: 0.3995 - val_loss: 1.0757 - learning_rate: 5.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.4446 - loss: 0.9146 - val_accuracy: 0.4274 - val_loss: 1.0344 - learning_rate: 5.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.4573 - loss: 0.9014 - val_accuracy: 0.4352 - val_loss: 1.0205 - learning_rate: 5.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.4651 - loss: 0.8798 - val_accuracy: 0.4441 - val_loss: 1.0746 - learning_rate: 5.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.4831 - loss: 0.8672 - val_accuracy: 0.4736 - val_loss: 0.9438 - learning_rate: 5.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.4919 - loss: 0.8456 - val_accuracy: 0.4848 - val_loss: 0.9476 - learning_rate: 5.0000e-04\n"
          ]
        }
      ],
      "source": [
        "# Update your model with deeper layers and bidirectional LSTM\n",
        "\n",
        "gpt_model2 = Sequential()\n",
        "\n",
        "# Convolutional layers\n",
        "gpt_model2.add(Conv1D(filters=128, kernel_size=5, activation='relu', input_shape=input_shape))\n",
        "gpt_model2.add(MaxPooling1D(pool_size=2))\n",
        "gpt_model2.add(Dropout(0.4))\n",
        "\n",
        "gpt_model2.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
        "gpt_model2.add(MaxPooling1D(pool_size=2))\n",
        "gpt_model2.add(Dropout(0.4))\n",
        "\n",
        "# Bidirectional LSTM layer\n",
        "gpt_model2.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
        "gpt_model2.add(Bidirectional(LSTM(100)))\n",
        "\n",
        "# Dense layers\n",
        "gpt_model2.add(Dense(100, activation='relu'))\n",
        "gpt_model2.add(Dropout(0.5))\n",
        "gpt_model2.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile with a lower learning rate\n",
        "gpt_model2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train with class weights if needed\n",
        "history = gpt_model2.fit(\n",
        "    X_train, y_train_one_hot,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test_one_hot),\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weights_dict  # Use class weights if classes are imbalanced\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test"
      ],
      "metadata": {
        "id": "H50IsQG-v_Yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test(gpt_model2,X_test,y_test_one_hot)"
      ],
      "metadata": {
        "id": "jsASmo-FwAXF",
        "outputId": "bad43c51-b2cc-4095-c097-894747d18755",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m449/449\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.2554    0.9728    0.4045      2794\n",
            "           1     0.5683    0.7443    0.6445      2163\n",
            "           2     0.2310    0.0915    0.1311      2163\n",
            "           3     0.3333    0.0001    0.0003      7217\n",
            "\n",
            "    accuracy                         0.3158     14337\n",
            "   macro avg     0.3470    0.4522    0.2951     14337\n",
            "weighted avg     0.3382    0.3158    0.1960     14337\n",
            "\n",
            "Per-class Recall:\n",
            "Class 0: 0.9728\n",
            "Class 1: 0.7443\n",
            "Class 2: 0.0915\n",
            "Class 3: 0.0001\n",
            "Per-class Accuracy:\n",
            "Class 0: 0.4419\n",
            "Class 1: 0.8761\n",
            "Class 2: 0.8170\n",
            "Class 3: 0.4965\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvSixSVBWnhp"
      },
      "source": [
        "## best model with class balancing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "evGpXSC9Wnhq",
        "outputId": "ddecb219-ed8b-42ae-8adc-4faf34a9e71b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.6131 - loss: 0.8182 - val_accuracy: 0.5888 - val_loss: 0.9240 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.6078 - loss: 0.8053 - val_accuracy: 0.5812 - val_loss: 0.9152 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6036 - loss: 0.8006 - val_accuracy: 0.5821 - val_loss: 0.9478 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6060 - loss: 0.7977 - val_accuracy: 0.5472 - val_loss: 0.9896 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6113 - loss: 0.7893 - val_accuracy: 0.5958 - val_loss: 0.9317 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6123 - loss: 0.7850 - val_accuracy: 0.6000 - val_loss: 0.9118 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6101 - loss: 0.7897 - val_accuracy: 0.5810 - val_loss: 0.9178 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6102 - loss: 0.7820 - val_accuracy: 0.5861 - val_loss: 0.9489 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.6165 - loss: 0.7724 - val_accuracy: 0.5805 - val_loss: 0.9453 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6184 - loss: 0.7732 - val_accuracy: 0.5903 - val_loss: 0.9157 - learning_rate: 0.0010\n"
          ]
        }
      ],
      "source": [
        "# Train with class weights if needed\n",
        "history = best_model.fit(\n",
        "    X_train, y_train_one_hot,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test_one_hot),\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weights_dict  # Use class weights if classes are imbalanced\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test"
      ],
      "metadata": {
        "id": "7au5m1u1wK3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test(best_model,X_test,y_test_one_hot)"
      ],
      "metadata": {
        "id": "7uZWJwQLwKlj",
        "outputId": "4efd5cf6-6f42-42f1-b4dd-55969d3f193c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m449/449\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4429    0.9306    0.6001      2794\n",
            "           1     0.6537    0.8141    0.7251      2163\n",
            "           2     0.5534    0.6255    0.5872      2163\n",
            "           3     0.8197    0.3779    0.5173      7217\n",
            "\n",
            "    accuracy                         0.5888     14337\n",
            "   macro avg     0.6174    0.6870    0.6074     14337\n",
            "weighted avg     0.6810    0.5888    0.5753     14337\n",
            "\n",
            "Per-class Recall:\n",
            "Class 0: 0.9306\n",
            "Class 1: 0.8141\n",
            "Class 2: 0.6255\n",
            "Class 3: 0.3779\n",
            "Per-class Accuracy:\n",
            "Class 0: 0.7583\n",
            "Class 1: 0.9069\n",
            "Class 2: 0.8673\n",
            "Class 3: 0.6450\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TUora7bWnhq"
      },
      "source": [
        "## adding summary features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "cJ4eVS93Wnhq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "ipXcgfHgWnhq"
      },
      "outputs": [],
      "source": [
        "def load_and_apply_sliding_windows2(file_paths, window_size, step_size, label):\n",
        "    \"\"\"\n",
        "    Load the data from each file, apply sliding windows, and return the windows and labels.\n",
        "\n",
        "    Parameters:\n",
        "    file_paths (list): List of file paths to CSV files. Each file contains sensor data (e.g., accelerometer, gyroscope).\n",
        "    window_size (int): The size of each sliding window (number of time steps).\n",
        "    step_size (int): The step size (stride) between consecutive windows.\n",
        "    label (int or str): The label for the activity corresponding to the folder.\n",
        "                        This label will be assigned to each sliding window extracted from the data.\n",
        "\n",
        "    Returns:\n",
        "    tuple:\n",
        "        - windows (numpy.ndarray): A 3D array of sliding windows, where each window has the shape\n",
        "                                   (num_windows, window_size, num_features).\n",
        "        - labels (numpy.ndarray): A 1D array of labels, where each label corresponds to a sliding window.\n",
        "    \"\"\"\n",
        "    # Initialize lists to store sliding windows and their corresponding labels\n",
        "    windows = []\n",
        "    labels = []\n",
        "\n",
        "    # Loop through each file in the provided file paths\n",
        "    for file_path in file_paths:\n",
        "        # Load the CSV file into a pandas DataFrame\n",
        "        data = pd.read_csv(file_path)\n",
        "\n",
        "        # Select the columns containing the necessary sensor data (acceleration and gyroscope readings)\n",
        "        # These columns might vary depending on your dataset's structure\n",
        "        data = data[['accel_x', 'accel_y', 'accel_z']]\n",
        "\n",
        "        # Convert the DataFrame into a numpy array for faster processing in the sliding window operation\n",
        "        data = data.to_numpy()\n",
        "\n",
        "        # Get the number of samples (rows) and features (columns) in the data\n",
        "        num_samples, num_features = data.shape\n",
        "\n",
        "        # Apply sliding windows to the data\n",
        "        # The range function defines the start of each window, moving step_size increments at a time\n",
        "        for i in range(0, num_samples - window_size + 1, step_size):\n",
        "            # Extract a window of size 'window_size' from the current position 'i'\n",
        "            window = data[i:i + window_size, :]\n",
        "\n",
        "            # Calculate statistics for each axis in the window\n",
        "            mean = np.mean(window, axis=0)\n",
        "            std = np.std(window, axis=0)\n",
        "            min_val = np.min(window, axis=0)\n",
        "            max_val = np.max(window, axis=0)\n",
        "            skewness = stats.skew(window, axis=0)\n",
        "            kurtosis = stats.kurtosis(window, axis=0)\n",
        "            # Concatenate features into a single array\n",
        "            window_features = np.concatenate([mean, std, min_val, max_val, skewness, kurtosis])\n",
        "\n",
        "            # Reshape window_features to match the dimensions for concatenation\n",
        "            # Expand dimensions to make it compatible with the window (1, num_statistical_features)\n",
        "            window_features = np.expand_dims(window_features, axis=0)\n",
        "\n",
        "            # Repeat window_features along the first dimension to match the window shape\n",
        "            window_features_expanded = np.repeat(window_features, window.shape[0], axis=0)\n",
        "\n",
        "            # Concatenate window_features with the original window along the last axis\n",
        "            augmented_window = np.concatenate([window, window_features_expanded], axis=1)\n",
        "\n",
        "            # Append the window to the windows list\n",
        "            windows.append(augmented_window)\n",
        "\n",
        "            # Assign the activity label to the window and append it to the labels list\n",
        "            labels.append(label)\n",
        "\n",
        "\n",
        "    # Convert the lists of windows and labels into numpy arrays for efficient numerical operations\n",
        "    return np.array(windows), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Tor8RbJgWnhq"
      },
      "outputs": [],
      "source": [
        "def process_activity2(activity, label, dataset_path, window_size=50, step_size=50, test_size=0.2):\n",
        "    \"\"\"\n",
        "    Processes an activity folder by loading the file list, splitting them into\n",
        "    train and test sets, and applying sliding windows to the files.\n",
        "\n",
        "    Args:\n",
        "        activity (str): Name of the activity (folder name). This refers to the specific physical activity\n",
        "                        like 'walking', 'running', etc.\n",
        "        label (int): Numeric label corresponding to the activity, used for classification.\n",
        "        dataset_path (str): Base path where the activity folders are located.\n",
        "        window_size (int): Size of the sliding window, i.e., the number of time steps included in each window.\n",
        "                           Default is 50.\n",
        "        step_size (int): Step size for the sliding window, i.e., how far the window moves along the data.\n",
        "                         Default is 50 (no overlap between windows).\n",
        "        test_size (float): Proportion of files to use for testing. Default is 0.2, meaning 20% of files will\n",
        "                           be allocated to the test set.\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - train_windows (numpy.ndarray): Sliding windows from the training files.\n",
        "            - train_labels (numpy.ndarray): Corresponding labels for the training windows.\n",
        "            - test_windows (numpy.ndarray): Sliding windows from the test files.\n",
        "            - test_labels (numpy.ndarray): Corresponding labels for the test windows.\n",
        "    \"\"\"\n",
        "    # Construct the full folder path where the activity files are stored\n",
        "    folder_path = os.path.join(dataset_path, activity)\n",
        "\n",
        "    # Load all CSV file paths for the given activity from the folder\n",
        "    file_list = load_files_from_folder(folder_path)\n",
        "\n",
        "    # Split the file list into training and testing sets\n",
        "    # train_files: files used for training\n",
        "    # test_files: files used for testing\n",
        "    train_files, test_files = split_files(file_list, test_size=test_size)\n",
        "\n",
        "    # Apply sliding windows to the training files\n",
        "    # The function 'load_and_apply_sliding_windows' returns the sliding windows (segments) and their corresponding labels\n",
        "    train_windows, train_labels = load_and_apply_sliding_windows2(train_files, window_size, step_size, label)\n",
        "\n",
        "    # Apply sliding windows to the testing files\n",
        "    test_windows, test_labels = load_and_apply_sliding_windows2(test_files, window_size, step_size, label)\n",
        "\n",
        "    # Return the sliding windows and their labels for both training and testing sets\n",
        "    return train_windows, train_labels, test_windows, test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "OiSiQxXhWnhq"
      },
      "outputs": [],
      "source": [
        "# Dictionary to store sliding windows and labels for both train and test sets for each activity\n",
        "# This will hold the training and test data after processing each activity.\n",
        "train_test_data2 = {}\n",
        "\n",
        "# Loop through each activity folder and process the data\n",
        "# Note, if you have large amounts of data, this step may take a while\n",
        "for activity, label in activities.items():\n",
        "    # Initialize an empty dictionary for each activity to store train and test windows and labels\n",
        "    train_test_data2[activity] = {}\n",
        "\n",
        "    # Call process_activity() to process the data for the current activity folder\n",
        "    # It loads the data, applies sliding windows, splits it into train and test sets,\n",
        "    # and returns the respective sliding windows and labels for both sets.\n",
        "    (train_test_data2[activity]['train_windows'], train_test_data2[activity]['train_labels'],\n",
        "     train_test_data2[activity]['test_windows'], train_test_data2[activity]['test_labels']) = process_activity2(\n",
        "        activity, label, your_dataset_path, window_size=50, step_size=50)\n",
        "\n",
        "# Explanation:\n",
        "    # - 'train_windows' and 'train_labels' store the windows and labels from the training files.\n",
        "    # - 'test_windows' and 'test_labels' store the windows and labels from the test files.\n",
        "    # - `your_dataset_path` should be replaced with the actual path to your dataset.\n",
        "    # - `process_activity` handles all the steps of loading data, splitting it, and applying sliding windows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "PYn3HFyLWnhq"
      },
      "outputs": [],
      "source": [
        "# Combine the sliding windows and labels for the training data from all activities\n",
        "# The combine_data() function concatenates the windows and labels across activities\n",
        "X_train2, y_train2 = combine_data(train_test_data2, 'train')\n",
        "\n",
        "# Combine the sliding windows and labels for the test data from all activities\n",
        "X_test2, y_test2 = combine_data(train_test_data2, 'test')\n",
        "\n",
        "# Explanation:\n",
        "# - `combine_data()` takes in the `train_test_data` dictionary and the data type ('train' or 'test') to specify\n",
        "#   whether we are combining training or testing data.\n",
        "# - It retrieves and concatenates the windows and labels from all activities into single arrays\n",
        "#   (`X_train` and `y_train` for training, `X_test` and `y_test` for testing).\n",
        "# - `X_train` and `X_test` are 3D arrays of sliding windows (shape: num_windows, window_size, num_features).\n",
        "# - `y_train` and `y_test` are 1D arrays containing the activity labels corresponding to each window."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "v46AxEjjWnhq",
        "outputId": "92db8930-9484-4762-aa78-fa53acf999ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train2 shape: (57224, 50, 21), y_train2 shape: (57224,)\n",
            "X_test2 shape: (14343, 50, 21), y_test2 shape: (14343,)\n"
          ]
        }
      ],
      "source": [
        "# Print the shapes of the training and test arrays to verify that everything has been combined correctly\n",
        "print(f\"X_train2 shape: {X_train2.shape}, y_train2 shape: {y_train2.shape}\")\n",
        "print(f\"X_test2 shape: {X_test2.shape}, y_test2 shape: {y_test2.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model 3, whatever that is"
      ],
      "metadata": {
        "id": "fLl1Y4Kr0IJB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "ZN6IwhHYWnhq"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "lFGVHuaVWnhr",
        "outputId": "5005bd8b-1a08-40a9-fed2-1d94544b4ea1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.5412 - loss: 1.0697 - val_accuracy: 0.5896 - val_loss: 0.8707 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.5934 - loss: 0.8829 - val_accuracy: 0.5939 - val_loss: 0.8896 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.5991 - loss: 0.8624 - val_accuracy: 0.6055 - val_loss: 0.8660 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6128 - loss: 0.8416 - val_accuracy: 0.5880 - val_loss: 0.8729 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6155 - loss: 0.8271 - val_accuracy: 0.6112 - val_loss: 0.8580 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6217 - loss: 0.8194 - val_accuracy: 0.6079 - val_loss: 0.8594 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6240 - loss: 0.8118 - val_accuracy: 0.6037 - val_loss: 0.8782 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6261 - loss: 0.8031 - val_accuracy: 0.5974 - val_loss: 0.8978 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6297 - loss: 0.7973 - val_accuracy: 0.6046 - val_loss: 0.8667 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6419 - loss: 0.7830 - val_accuracy: 0.5959 - val_loss: 0.9011 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6522 - loss: 0.7622 - val_accuracy: 0.6114 - val_loss: 0.8742 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.6566 - loss: 0.7509 - val_accuracy: 0.6098 - val_loss: 0.9040 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6596 - loss: 0.7459 - val_accuracy: 0.6098 - val_loss: 0.9041 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6616 - loss: 0.7421 - val_accuracy: 0.6124 - val_loss: 0.9193 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6614 - loss: 0.7323 - val_accuracy: 0.6108 - val_loss: 0.8986 - learning_rate: 5.0000e-04\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5389 - loss: 0.9451\n",
            "Test Accuracy: 61.12%\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "breathingNormally       0.68      0.47      0.55      2788\n",
            "         coughing       0.59      0.74      0.65      2166\n",
            " hyperventilation       0.50      0.29      0.36      2171\n",
            "            other       0.62      0.73      0.67      7218\n",
            "\n",
            "         accuracy                           0.61     14343\n",
            "        macro avg       0.60      0.55      0.56     14343\n",
            "     weighted avg       0.61      0.61      0.60     14343\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define the model architecture\n",
        "model3 = Sequential()\n",
        "\n",
        "# Convolutional layers\n",
        "model3.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(50, 21)))\n",
        "model3.add(MaxPooling1D(pool_size=2))\n",
        "model3.add(Dropout(0.3))\n",
        "\n",
        "model3.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
        "model3.add(MaxPooling1D(pool_size=2))\n",
        "model3.add(Dropout(0.3))\n",
        "\n",
        "# LSTM layers for temporal dependencies\n",
        "model3.add(LSTM(100, return_sequences=True))\n",
        "model3.add(LSTM(50))\n",
        "\n",
        "# Dense layers for classification\n",
        "model3.add(Dense(50, activation='relu'))\n",
        "model3.add(Dropout(0.5))\n",
        "model3.add(Dense(4, activation='softmax'))  # 4 classes\n",
        "\n",
        "# Compile the model\n",
        "model3.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callbacks for improved performance\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "history = model3.fit(\n",
        "    X_train2, y_train2,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test2, y_test2),\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test model 3"
      ],
      "metadata": {
        "id": "QIEqD_rG11H6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test(model3,X_test2,y_test_one_hot2)"
      ],
      "metadata": {
        "id": "_oivuNWs1j7h",
        "outputId": "2905e98a-8b99-443c-d637-9021c39e24f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m449/449\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6821    0.4656    0.5534      2788\n",
            "           1     0.5885    0.7368    0.6544      2166\n",
            "           2     0.4980    0.2856    0.3630      2171\n",
            "           3     0.6191    0.7276    0.6690      7218\n",
            "\n",
            "    accuracy                         0.6112     14343\n",
            "   macro avg     0.5969    0.5539    0.5599     14343\n",
            "weighted avg     0.6084    0.6112    0.5980     14343\n",
            "\n",
            "Per-class Recall:\n",
            "Class 0: 0.4656\n",
            "Class 1: 0.7368\n",
            "Class 2: 0.2856\n",
            "Class 3: 0.7276\n",
            "Per-class Accuracy:\n",
            "Class 0: 0.8539\n",
            "Class 1: 0.8825\n",
            "Class 2: 0.8483\n",
            "Class 3: 0.6377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### using best model"
      ],
      "metadata": {
        "id": "JO6zehjN0Ntg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ogg-NLhWnhr"
      },
      "source": [
        "using previous best model (not GPT's):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "qafNYKgTWnhr"
      },
      "outputs": [],
      "source": [
        "# Initialize the OneHotEncoder\n",
        "encoder2 = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Reshape y_train to a 2D array to meet the input format requirements of OneHotEncoder\n",
        "# - y_train is originally a 1D array of labels (shape: [num_samples]), but OneHotEncoder expects a 2D array of shape (num_samples, 1).\n",
        "# - reshape(-1, 1): The -1 means 'infer the correct size based on the other dimensions' (i.e., it adapts based on the length of y_train).\n",
        "# OneHotEncoder will then create a binary vector for each label.\n",
        "y_train_one_hot2 = encoder2.fit_transform(y_train2.reshape(-1, 1))\n",
        "\n",
        "# Apply the same transformation to the test labels (y_test)\n",
        "# - Since the encoder is already fitted on the training data, we use transform() for the test set.\n",
        "# - Reshape y_test to (num_samples, 1) for compatibility with the encoder.\n",
        "y_test_one_hot2 = encoder2.transform(y_test2.reshape(-1, 1))\n",
        "\n",
        "# Explanation:\n",
        "# - y_train_one_hot and y_test_one_hot are now 2D arrays where each row is a one-hot encoded binary vector corresponding to a class label.\n",
        "# - The number of columns in the one-hot encoded labels equals the number of unique classes (activities).\n",
        "# For example, if there are 6 unique activities, the encoded vector will have 6 elements, with a '1' indicating the correct class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "rLh602ROWnhr",
        "outputId": "e35d8a44-1bea-4640-b4f3-b83db4b06b4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train2 shape: (57224, 50, 21), y_train2 shape: (57224,)\n",
            "X_test2 shape: (14343, 50, 21), y_test2 shape: (14343,)\n",
            "y_train_one_hot2 shape: (57224, 4), y_test_one_hot2 shape: (14343, 4)\n"
          ]
        }
      ],
      "source": [
        "# Print the shapes of the training and test arrays to verify that everything has been combined correctly\n",
        "print(f\"X_train2 shape: {X_train2.shape}, y_train2 shape: {y_train2.shape}\")\n",
        "print(f\"X_test2 shape: {X_test2.shape}, y_test2 shape: {y_test2.shape}\")\n",
        "\n",
        "# Print the shapes of the one-hot encoded labels to verify that the transformation was successful\n",
        "print(f\"y_train_one_hot2 shape: {y_train_one_hot2.shape}, y_test_one_hot2 shape: {y_test_one_hot2.shape}\")\n",
        "\n",
        "# Explanation of shapes:\n",
        "# - The shape of y_train_one_hot will be (num_samples, num_classes), where:\n",
        "#     - num_samples is the number of training windows.\n",
        "#     - num_classes is the number of unique activities (the length of the one-hot vectors).\n",
        "# - Similarly, y_test_one_hot will have the same number of columns (num_classes) as y_train_one_hot but will have fewer rows (corresponding to the number of test windows)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "K7wVLd9OWnhr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "outputId": "af3ffb65-2136-44ea-be05-f5c13a5894e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv1d_26 (\u001b[38;5;33mConv1D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)                       \u001b[38;5;34m13,568\u001b[0m \n",
              "\n",
              " batch_normalization_14                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)                          \u001b[38;5;34m512\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
              "\n",
              " max_pooling1d_26 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_35 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m128\u001b[0m)                            \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv1d_27 (\u001b[38;5;33mConv1D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)                      \u001b[38;5;34m164,096\u001b[0m \n",
              "\n",
              " batch_normalization_15                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)                        \u001b[38;5;34m1,024\u001b[0m \n",
              " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                               \n",
              "\n",
              " max_pooling1d_27 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)                             \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dropout_36 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m)                             \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " lstm_15 (\u001b[38;5;33mLSTM\u001b[0m)                        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                          \u001b[38;5;34m197,120\u001b[0m \n",
              "\n",
              " flatten_9 (\u001b[38;5;33mFlatten\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_26 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                           \u001b[38;5;34m16,512\u001b[0m \n",
              "\n",
              " dropout_37 (\u001b[38;5;33mDropout\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_27 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                                \u001b[38;5;34m516\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " conv1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                       <span style=\"color: #00af00; text-decoration-color: #00af00\">13,568</span> \n",
              "\n",
              " batch_normalization_14                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
              "\n",
              " max_pooling1d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">164,096</span> \n",
              "\n",
              " batch_normalization_15                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                               \n",
              "\n",
              " max_pooling1d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dropout_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " lstm_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> \n",
              "\n",
              " flatten_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> \n",
              "\n",
              " dropout_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m393,348\u001b[0m (1.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">393,348</span> (1.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m392,580\u001b[0m (1.50 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">392,580</span> (1.50 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - accuracy: 0.5448 - loss: 1.1770 - val_accuracy: 0.5904 - val_loss: 0.9718 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.5836 - loss: 0.9685 - val_accuracy: 0.5809 - val_loss: 0.9616 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.5869 - loss: 0.9407 - val_accuracy: 0.5884 - val_loss: 0.9201 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.5938 - loss: 0.9305 - val_accuracy: 0.5950 - val_loss: 0.9098 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.5932 - loss: 0.9232 - val_accuracy: 0.5987 - val_loss: 0.9142 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.5984 - loss: 0.9135 - val_accuracy: 0.6126 - val_loss: 0.8996 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.5986 - loss: 0.9079 - val_accuracy: 0.6128 - val_loss: 0.8945 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6032 - loss: 0.9068 - val_accuracy: 0.6133 - val_loss: 0.8868 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6003 - loss: 0.9009 - val_accuracy: 0.5954 - val_loss: 0.9435 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.6030 - loss: 0.9035 - val_accuracy: 0.6076 - val_loss: 0.8828 - learning_rate: 0.0010\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "best_model2 = build_best_tuning_model(custom_input_shape=(50,21))\n",
        "history = best_model2.fit(\n",
        "    X_train2, y_train_one_hot2,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test2, y_test_one_hot2),\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test best model"
      ],
      "metadata": {
        "id": "WOlqQp9h2TyO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "Rxi_L2CcWnhr",
        "outputId": "15e176ea-d5ca-4e0c-d73d-7aa62bb30998",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m449/449\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8360    0.2048    0.3290      2788\n",
            "           1     0.6282    0.6357    0.6319      2166\n",
            "           2     0.5496    0.0995    0.1685      2171\n",
            "           3     0.5692    0.8734    0.6892      7218\n",
            "\n",
            "    accuracy                         0.5904     14343\n",
            "   macro avg     0.6458    0.4534    0.4547     14343\n",
            "weighted avg     0.6270    0.5904    0.5317     14343\n",
            "\n",
            "Per-class Recall:\n",
            "Class 0: 0.2048\n",
            "Class 1: 0.6357\n",
            "Class 2: 0.0995\n",
            "Class 3: 0.8734\n",
            "Per-class Accuracy:\n",
            "Class 0: 0.8376\n",
            "Class 1: 0.8882\n",
            "Class 2: 0.8514\n",
            "Class 3: 0.6036\n"
          ]
        }
      ],
      "source": [
        "test(best_model2,X_test2,y_test_one_hot2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aaet6hPzWnhr"
      },
      "source": [
        "### Transformer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "NQ_mQzvLWnhr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, MultiHeadAttention, LayerNormalization, Dropout, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "pWfRbfzFWnhr",
        "outputId": "77cd0738-4749-4dd1-ffc7-4c877ac4e566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1789/1789\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5048 - loss: 1.2481"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 14337\n'y' sizes: 84\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-4dff3a52afdb>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Instantiate and train the Transformer model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mtransformer_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_transformer_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m history = transformer_model.fit(\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Note: y_train2 should be integer encoded, not one-hot for 'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/data_adapter_utils.py\u001b[0m in \u001b[0;36mcheck_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    112\u001b[0m             )\n\u001b[1;32m    113\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"'{label}' sizes: {sizes}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 14337\n'y' sizes: 84\n"
          ]
        }
      ],
      "source": [
        "def build_transformer_model(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Multi-Head Attention Layer\n",
        "    x = MultiHeadAttention(num_heads=4, key_dim=64)(inputs, inputs)\n",
        "    x = LayerNormalization(epsilon=1e-6)(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    # Additional Feedforward Layer with residual connection\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "\n",
        "    # Final dense layers for classification\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Instantiate and train the Transformer model\n",
        "transformer_model = build_transformer_model(input_shape=input_shape, num_classes=4)\n",
        "history = transformer_model.fit(\n",
        "    X_train, y_train,  # Note: y_train2 should be integer encoded, not one-hot for 'sparse_categorical_crossentropy'\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### transformer test\n"
      ],
      "metadata": {
        "id": "-F29k30w3Sxu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NnAtdQkz3VFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7z1CE_BWnhr"
      },
      "source": [
        "# Models from papers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqLVc-L4Wnhs"
      },
      "source": [
        "https://ieeexplore.ieee.org/abstract/document/10331170\n",
        "\n",
        "gave up on this because their were layer shape mismatches in the model and it wasn't immediately obvious from the paper how they resolved those\n",
        "\n",
        "also haven't implemented their input optimisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "C09ateTUWnhs"
      },
      "outputs": [],
      "source": [
        "def build_1d_cnn_model4(hp):\n",
        "    \"\"\"\n",
        "    Builds and compiles a 1D CNN model for multi-class classification.\n",
        "\n",
        "    Args:\n",
        "        input_shape (tuple): The shape of the input data (timesteps, features).\n",
        "        num_classes (int): The number of output classes.\n",
        "\n",
        "    Returns:\n",
        "        model (Sequential): Compiled 1D CNN model.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    # First Conv1D layer\n",
        "    # You can try experimenting with different filters, kernel_size values and activiation functions\n",
        "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu', input_shape=input_shape))\n",
        "\n",
        "    #model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "    # Second Conv1D layer\n",
        "    # You can try experimenting with different filters, kernel_size values and activiation functions\n",
        "    model.add(Conv1D(filters=128,\n",
        "                     kernel_size=5,\n",
        "                     activation='relu',\n",
        "                     kernel_regularizer=l2(hp.Choice('l2_regularization', values=[1e-4, 1e-3])),\n",
        "                     bias_regularizer=l2(hp.Choice('l2_regularization_bias', values=[1e-4, 1e-3]))\n",
        "                    ))\n",
        "\n",
        "    #model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "    # Flatten the output from the convolutional layers\n",
        "\n",
        "    #model.add(Flatten())\n",
        "\n",
        "    # Fully connected layer\n",
        "\n",
        "    #model.add(Dense(128, activation='relu'))\n",
        "\n",
        "    # Dropout layer for regularization\n",
        "    # You can try experimenting with different dropout rates\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "    model.add(Dense(100,\n",
        "                    activation='softmax',\n",
        "                     kernel_regularizer=l2(hp.Choice('l2_regularization', values=[1e-4, 1e-3])),\n",
        "                     bias_regularizer=l2(hp.Choice('l2_regularization_bias', values=[1e-4, 1e-3]))\n",
        "                    ))\n",
        "\n",
        "    # Output layer with softmax for multi-class classification\n",
        "    model.add(Dense(4,\n",
        "                    activation='softmax',\n",
        "                     kernel_regularizer=l2(hp.Choice('l2_regularization', values=[1e-4, 1e-3])),\n",
        "                     bias_regularizer=l2(hp.Choice('l2_regularization_bias', values=[1e-4, 1e-3]))\n",
        "                    ))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    #  Prints a detailed summary of the model, showing the layers, their output shapes, and the number of trainable parameters\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "TL1UlHuoWnhs"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, LSTM\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWXrReDTWnhs",
        "outputId": "61c6814c-a054-47b9-d833-547d8ff3fe5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reloading Tuner from my_tuning_dir\\respiratory_activity_classification_model4\\tuner0.json\n",
            "\n",
            "Search: Running Trial #3\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "0.001             |0.001             |l2_regularization\n",
            "0.001             |0.001             |l2_regularization_bias\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
              "\n",
              " conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> \n",
              "\n",
              " conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> \n",
              "\n",
              " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">12,900</span> \n",
              "\n",
              " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">404</span> \n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv1d (\u001b[38;5;33mConv1D\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m2,048\u001b[0m \n",
              "\n",
              " conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m128\u001b[0m)                \u001b[38;5;34m82,048\u001b[0m \n",
              "\n",
              " dropout (\u001b[38;5;33mDropout\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m128\u001b[0m)                     \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m128\u001b[0m)                     \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m100\u001b[0m)                \u001b[38;5;34m12,900\u001b[0m \n",
              "\n",
              " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m4\u001b[0m)                     \u001b[38;5;34m404\u001b[0m \n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,400</span> (380.47 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m97,400\u001b[0m (380.47 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,400</span> (380.47 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m97,400\u001b[0m (380.47 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n",
            "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
            "  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n",
            "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
            "  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n",
            "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
            "  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n",
            "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
            "  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n",
            "    return model.fit(*args, **kwargs)\n",
            "  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 580, in categorical_crossentropy\n",
            "    raise ValueError(\n",
            "ValueError: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 4), output.shape=(None, 21, 4)\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 580, in categorical_crossentropy\n    raise ValueError(\nValueError: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 4), output.shape=(None, 21, 4)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [52], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m tuner4 \u001b[38;5;241m=\u001b[39m kt\u001b[38;5;241m.\u001b[39mRandomSearch(\n\u001b[0;32m      2\u001b[0m     build_1d_cnn_model4,\n\u001b[0;32m      3\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Tuning for validation accuracy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrespiratory_activity_classification_model4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Split your data if not already done\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mtuner4\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_one_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# Number of epochs for each trial\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m             \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_one_hot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m             \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m model4 \u001b[38;5;241m=\u001b[39m tuner4\u001b[38;5;241m.\u001b[39mget_best_models(num_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_trial_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:339\u001b[0m, in \u001b[0;36mBaseTuner.on_trial_end\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_trial_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;124;03m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\oracle.py:108\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m     LOCKS[oracle]\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    107\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m thread_name\n\u001b[1;32m--> 108\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_acquire:\n\u001b[0;32m    110\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\oracle.py:588\u001b[0m, in \u001b[0;36mOracle.end_trial\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry(trial):\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_order\u001b[38;5;241m.\u001b[39mappend(trial\u001b[38;5;241m.\u001b[39mtrial_id)\n\u001b[1;32m--> 588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_consecutive_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_trial(trial)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\oracle.py:545\u001b[0m, in \u001b[0;36mOracle._check_consecutive_failures\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    543\u001b[0m     consecutive_failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consecutive_failures \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials:\n\u001b[1;32m--> 545\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of consecutive failures exceeded the limit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    548\u001b[0m         \u001b[38;5;241m+\u001b[39m (trial\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    549\u001b[0m     )\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\luise\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\", line 580, in categorical_crossentropy\n    raise ValueError(\nValueError: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 4), output.shape=(None, 21, 4)\n"
          ]
        }
      ],
      "source": [
        "tuner4 = kt.RandomSearch(\n",
        "    build_1d_cnn_model4,\n",
        "    objective='val_accuracy',  # Tuning for validation accuracy\n",
        "    max_trials=20,             # Number of different hyperparameter sets to try\n",
        "    executions_per_trial=2,    # Average results over multiple runs to reduce variance\n",
        "    directory='my_tuning_dir', # Directory to save tuning results\n",
        "    project_name='respiratory_activity_classification_model4'\n",
        ")\n",
        "\n",
        "# Split your data if not already done\n",
        "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "tuner4.search(X_train, y_train_one_hot,\n",
        "             epochs=20,               # Number of epochs for each trial\n",
        "             validation_data=(X_test, y_test_one_hot),\n",
        "             callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)])\n",
        "\n",
        "model4 = tuner4.get_best_models(num_models=1)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRm1brrIWnhs"
      },
      "source": [
        "window_size = 4s = 100 timesteps (untested)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O-zwuiqWnhs"
      },
      "outputs": [],
      "source": [
        "# Dictionary to store sliding windows and labels for both train and test sets for each activity\n",
        "# This will hold the training and test data after processing each activity.\n",
        "train_test_data3 = {}\n",
        "\n",
        "# Loop through each activity folder and process the data\n",
        "# Note, if you have large amounts of data, this step may take a while\n",
        "for activity, label in activities.items():\n",
        "    # Initialize an empty dictionary for each activity to store train and test windows and labels\n",
        "    train_test_data3[activity] = {}\n",
        "\n",
        "    # Call process_activity() to process the data for the current activity folder\n",
        "    # It loads the data, applies sliding windows, splits it into train and test sets,\n",
        "    # and returns the respective sliding windows and labels for both sets.\n",
        "    (train_test_data3[activity]['train_windows'], train_test_data3[activity]['train_labels'],\n",
        "     train_test_data3[activity]['test_windows'], train_test_data3[activity]['test_labels']) = process_activity(\n",
        "        activity, label, your_dataset_path, window_size=100, step_size=50)\n",
        "\n",
        "# Explanation:\n",
        "    # - 'train_windows' and 'train_labels' store the windows and labels from the training files.\n",
        "    # - 'test_windows' and 'test_labels' store the windows and labels from the test files.\n",
        "    # - `your_dataset_path` should be replaced with the actual path to your dataset.\n",
        "    # - `process_activity` handles all the steps of loading data, splitting it, and applying sliding windows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmvRnHP5Wnht"
      },
      "outputs": [],
      "source": [
        "# Combine the sliding windows and labels for the training data from all activities\n",
        "# The combine_data() function concatenates the windows and labels across activities\n",
        "X_train3, y_train3 = combine_data(train_test_data3, 'train')\n",
        "\n",
        "# Combine the sliding windows and labels for the test data from all activities\n",
        "X_test3, y_test3 = combine_data(train_test_data3, 'test')\n",
        "\n",
        "# Explanation:\n",
        "# - `combine_data()` takes in the `train_test_data` dictionary and the data type ('train' or 'test') to specify\n",
        "#   whether we are combining training or testing data.\n",
        "# - It retrieves and concatenates the windows and labels from all activities into single arrays\n",
        "#   (`X_train` and `y_train` for training, `X_test` and `y_test` for testing).\n",
        "# - `X_train` and `X_test` are 3D arrays of sliding windows (shape: num_windows, window_size, num_features).\n",
        "# - `y_train` and `y_test` are 1D arrays containing the activity labels corresponding to each window."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikXvMGDcWnht"
      },
      "outputs": [],
      "source": [
        "# Initialize the OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Reshape y_train to a 2D array to meet the input format requirements of OneHotEncoder\n",
        "# - y_train is originally a 1D array of labels (shape: [num_samples]), but OneHotEncoder expects a 2D array of shape (num_samples, 1).\n",
        "# - reshape(-1, 1): The -1 means 'infer the correct size based on the other dimensions' (i.e., it adapts based on the length of y_train).\n",
        "# OneHotEncoder will then create a binary vector for each label.\n",
        "y_train_one_hot3 = encoder.fit_transform(y_train3.reshape(-1, 1))\n",
        "\n",
        "# Apply the same transformation to the test labels (y_test)\n",
        "# - Since the encoder is already fitted on the training data, we use transform() for the test set.\n",
        "# - Reshape y_test to (num_samples, 1) for compatibility with the encoder.\n",
        "y_test_one_hot3 = encoder.transform(y_test3.reshape(-1, 1))\n",
        "\n",
        "# Explanation:\n",
        "# - y_train_one_hot and y_test_one_hot are now 2D arrays where each row is a one-hot encoded binary vector corresponding to a class label.\n",
        "# - The number of columns in the one-hot encoded labels equals the number of unique classes (activities).\n",
        "# For example, if there are 6 unique activities, the encoded vector will have 6 elements, with a '1' indicating the correct class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0aGKR02bWnht"
      },
      "outputs": [],
      "source": [
        "# Print the shapes of the training and test arrays to verify that everything has been combined correctly\n",
        "print(f\"X_train3 shape: {X_train3.shape}, y_train3 shape: {y_train3.shape}\")\n",
        "print(f\"X_test3 shape: {X_test3.shape}, y_test3 shape: {y_test3.shape}\")\n",
        "# Print the shapes of the one-hot encoded labels to verify that the transformation was successful\n",
        "print(f\"y_train_one_hot3 shape: {y_train_one_hot3.shape}, y_test_one_hot3 shape: {y_test_one_hot3.shape}\")\n",
        "\n",
        "# Explanation of shapes:\n",
        "# - The shape of y_train_one_hot will be (num_samples, num_classes), where:\n",
        "#     - num_samples is the number of training windows.\n",
        "#     - num_classes is the number of unique activities (the length of the one-hot vectors).\n",
        "# - Similarly, y_test_one_hot will have the same number of columns (num_classes) as y_train_one_hot but will have fewer rows (corresponding to the number of test windows)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## s-GAN\n",
        "https://project-archive.inf.ed.ac.uk/ug4/20212442/ug4_proj.pdf#page=26.16"
      ],
      "metadata": {
        "id": "CY5bCBMZWzcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data processing, window size 128 overlapping"
      ],
      "metadata": {
        "id": "pKJ8ZiaagtXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store sliding windows and labels for both train and test sets for each activity\n",
        "# This will hold the training and test data after processing each activity.\n",
        "train_test_data4 = {}\n",
        "\n",
        "# Loop through each activity folder and process the data\n",
        "# Note, if you have large amounts of data, this step may take a while\n",
        "for activity, label in activities.items():\n",
        "    # Initialize an empty dictionary for each activity to store train and test windows and labels\n",
        "    train_test_data4[activity] = {}\n",
        "\n",
        "    # Call process_activity() to process the data for the current activity folder\n",
        "    # It loads the data, applies sliding windows, splits it into train and test sets,\n",
        "    # and returns the respective sliding windows and labels for both sets.\n",
        "    (train_test_data4[activity]['train_windows'], train_test_data4[activity]['train_labels'],\n",
        "     train_test_data4[activity]['test_windows'], train_test_data4[activity]['test_labels']) = process_activity(\n",
        "        activity, label, your_dataset_path, window_size=128, step_size=50)\n",
        "\n",
        "# Explanation:\n",
        "    # - 'train_windows' and 'train_labels' store the windows and labels from the training files.\n",
        "    # - 'test_windows' and 'test_labels' store the windows and labels from the test files.\n",
        "    # - `your_dataset_path` should be replaced with the actual path to your dataset.\n",
        "    # - `process_activity` handles all the steps of loading data, splitting it, and applying sliding windows.\n",
        "    # Combine the sliding windows and labels for the training data from all activities\n",
        "# The combine_data() function concatenates the windows and labels across activities\n",
        "X_train4, y_train4 = combine_data(train_test_data4, 'train')\n",
        "\n",
        "# Combine the sliding windows and labels for the test data from all activities\n",
        "X_test4, y_test4 = combine_data(train_test_data4, 'test')\n",
        "\n",
        "# Explanation:\n",
        "# - `combine_data()` takes in the `train_test_data` dictionary and the data type ('train' or 'test') to specify\n",
        "#   whether we are combining training or testing data.\n",
        "# - It retrieves and concatenates the windows and labels from all activities into single arrays\n",
        "#   (`X_train` and `y_train` for training, `X_test` and `y_test` for testing).\n",
        "# - `X_train` and `X_test` are 3D arrays of sliding windows (shape: num_windows, window_size, num_features).\n",
        "# - `y_train` and `y_test` are 1D arrays containing the activity labels corresponding to each window.\n",
        "# Initialize the OneHotEncoder\n",
        "encoder4 = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Reshape y_train to a 2D array to meet the input format requirements of OneHotEncoder\n",
        "# - y_train is originally a 1D array of labels (shape: [num_samples]), but OneHotEncoder expects a 2D array of shape (num_samples, 1).\n",
        "# - reshape(-1, 1): The -1 means 'infer the correct size based on the other dimensions' (i.e., it adapts based on the length of y_train).\n",
        "# OneHotEncoder will then create a binary vector for each label.\n",
        "y_train_one_hot4 = encoder4.fit_transform(y_train4.reshape(-1, 1))\n",
        "\n",
        "# Apply the same transformation to the test labels (y_test)\n",
        "# - Since the encoder is already fitted on the training data, we use transform() for the test set.\n",
        "# - Reshape y_test to (num_samples, 1) for compatibility with the encoder.\n",
        "y_test_one_hot4 = encoder4.transform(y_test4.reshape(-1, 1))\n",
        "\n",
        "# Explanation:\n",
        "# - y_train_one_hot and y_test_one_hot are now 2D arrays where each row is a one-hot encoded binary vector corresponding to a class label.\n",
        "# - The number of columns in the one-hot encoded labels equals the number of unique classes (activities).\n",
        "# For example, if there are 6 unique activities, the encoded vector will have 6 elements, with a '1' indicating the correct class.\n",
        "# Print the shapes of the training and test arrays to verify that everything has been combined correctly\n",
        "print(f\"X_train4 shape: {X_train4.shape}, y_train4 shape: {y_train4.shape}\")\n",
        "print(f\"X_test4 shape: {X_test4.shape}, y_test4 shape: {y_test4.shape}\")\n",
        "# Print the shapes of the one-hot encoded labels to verify that the transformation was successful\n",
        "print(f\"y_train_one_hot4 shape: {y_train_one_hot4.shape}, y_test_one_hot4 shape: {y_test_one_hot4.shape}\")\n",
        "\n",
        "# Explanation of shapes:\n",
        "# - The shape of y_train_one_hot will be (num_samples, num_classes), where:\n",
        "#     - num_samples is the number of training windows.\n",
        "#     - num_classes is the number of unique activities (the length of the one-hot vectors).\n",
        "# - Similarly, y_test_one_hot will have the same number of columns (num_classes) as y_train_one_hot but will have fewer rows (corresponding to the number of test windows).\n",
        "\n",
        "# Determine the input shape for the model\n",
        "input_shape4 = (X_train4.shape[1], X_train4.shape[2])"
      ],
      "metadata": {
        "id": "NMQ0ruwkgwJ-",
        "outputId": "f2200922-106b-4ef2-cfd8-c198a3b000e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train4 shape: (49898, 128, 3), y_train4 shape: (49898,)\n",
            "X_test4 shape: (12500, 128, 3), y_test4 shape: (12500,)\n",
            "y_train_one_hot4 shape: (49898, 4), y_test_one_hot4 shape: (12500, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model, window size 128"
      ],
      "metadata": {
        "id": "gXROE0G1fI6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "pWxwhd08W6M5"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim=100, output_channels=3):\n",
        "        super(Generator, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        self.fc1 = nn.Linear(latent_dim, 1024 * 4)  # Output: (batch_size, 4096)\n",
        "\n",
        "        self.deconv1 = nn.Sequential(\n",
        "            nn.ConvTranspose1d(1024, 512, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 512, 8)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.deconv2 = nn.Sequential(\n",
        "            nn.ConvTranspose1d(512, 256, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 256, 16)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.deconv3 = nn.Sequential(\n",
        "            nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 128, 32)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.deconv4 = nn.Sequential(\n",
        "            nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 64, 64)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.deconv5 = nn.Sequential(\n",
        "            nn.ConvTranspose1d(64, output_channels, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 3, 128)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        x = self.fc1(z)\n",
        "        x = x.view(-1, 1024, 4)\n",
        "        x = self.deconv1(x)\n",
        "        x = self.deconv2(x)\n",
        "        x = self.deconv3(x)\n",
        "        x = self.deconv4(x)\n",
        "        x = self.deconv5(x)\n",
        "        return x  # Output shape: (batch_size, 3, 128)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv1d(3, 512, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 512, 64)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv1d(512, 1024, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 1024, 32)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "        self.shared_features = nn.Flatten()  # Flattens to (batch_size, 1024*32)\n",
        "\n",
        "        self.classifier = nn.Linear(1024 * 32, num_classes)\n",
        "        self.discriminator = nn.Sequential(\n",
        "            nn.Linear(1024 * 32, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        features = self.shared_features(x)\n",
        "\n",
        "        class_output = self.classifier(features)\n",
        "        real_fake_output = self.discriminator(features)\n",
        "        return class_output, real_fake_output\n"
      ],
      "metadata": {
        "id": "sD4PG-BFeHyU"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_sgan(generator, discriminator, dataloader, num_classes, num_epochs=30, latent_dim=100):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "\n",
        "    criterion_class = nn.CrossEntropyLoss()\n",
        "    criterion_real_fake = nn.BCELoss()\n",
        "\n",
        "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (x_real, labels_real) in enumerate(dataloader):\n",
        "            x_real = x_real.to(device)  # Shape: (batch_size, 3, 128)\n",
        "            labels_real = labels_real.to(device)\n",
        "            batch_size = x_real.size(0)\n",
        "            half_batch = batch_size // 2\n",
        "\n",
        "            # Prepare labels\n",
        "            real_labels = torch.ones(half_batch, 1).to(device)\n",
        "            fake_labels = torch.zeros(half_batch, 1).to(device)\n",
        "\n",
        "            # ====================\n",
        "            # Train Discriminator\n",
        "            # ====================\n",
        "            discriminator.train()\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            # Train on real data\n",
        "            x_real_half = x_real[:half_batch]\n",
        "            labels_real_half = labels_real[:half_batch]\n",
        "            class_output_real, real_fake_output_real = discriminator(x_real_half)\n",
        "            d_loss_real_class = criterion_class(class_output_real, labels_real_half)\n",
        "            d_loss_real_rf = criterion_real_fake(real_fake_output_real, real_labels)\n",
        "\n",
        "            # Train on fake data\n",
        "            z = torch.randn(half_batch, latent_dim).to(device)\n",
        "            x_fake = generator(z)\n",
        "            class_output_fake, real_fake_output_fake = discriminator(x_fake.detach())\n",
        "            d_loss_fake_rf = criterion_real_fake(real_fake_output_fake, fake_labels)\n",
        "\n",
        "            # Total discriminator loss\n",
        "            d_loss = d_loss_real_class + d_loss_real_rf + d_loss_fake_rf\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # ====================\n",
        "            # Train Generator\n",
        "            # ====================\n",
        "            # Freeze discriminator parameters\n",
        "            for param in discriminator.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "            generator.train()\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            # Generate fake data\n",
        "            z = torch.randn(batch_size, latent_dim).to(device)\n",
        "            x_fake = generator(z)\n",
        "\n",
        "            # Forward pass through discriminator\n",
        "            _, real_fake_output_fake = discriminator(x_fake)\n",
        "\n",
        "            # Generator wants discriminator to classify fake data as real\n",
        "            real_labels_g = torch.ones(batch_size, 1).to(device)\n",
        "            g_loss_rf = criterion_real_fake(real_fake_output_fake, real_labels_g)\n",
        "            g_loss = g_loss_rf\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            # Unfreeze discriminator parameters\n",
        "            for param in discriminator.parameters():\n",
        "                param.requires_grad = True\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print(f'Epoch [{epoch+1}/{num_epochs}] Batch [{i}/{len(dataloader)}] '\n",
        "                      f'D_loss: {d_loss.item():.4f}, G_loss: {g_loss.item():.4f}')\n"
      ],
      "metadata": {
        "id": "iOUZJgXyizYk"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Compute the mean and standard deviation from the training data\n",
        "mean = X_train4.mean()\n",
        "std = X_train4.std()\n",
        "\n",
        "# Normalize the training and test data using the training mean and std\n",
        "X_train4 = (X_train4 - mean) / std\n",
        "X_test4 = (X_test4 - mean) / std\n",
        "\n",
        "# Clip the data to the range [-1, 1]\n",
        "X_train4 = np.clip(X_train4, -1, 1)\n",
        "X_test4 = np.clip(X_test4, -1, 1)"
      ],
      "metadata": {
        "id": "x1v4cIM0iVrb"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X  # NumPy array of shape (num_samples, seq_length, num_features)\n",
        "        self.y = y  # NumPy array of shape (num_samples,)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the sample and label\n",
        "        x = self.X[idx]  # Shape: (128, 3)\n",
        "        y = self.y[idx]\n",
        "\n",
        "        # Convert to torch tensors and transpose x to shape (num_features, seq_length)\n",
        "        x = torch.tensor(x, dtype=torch.float32).transpose(0, 1)  # Shape: (3, 128)\n",
        "        y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "gjAHVaRFiX6b"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128  # Adjust based on your memory constraints\n",
        "\n",
        "# Create dataset and dataloader\n",
        "train_dataset = CustomDataset(X_train4, y_train4)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Create dataset and dataloader\n",
        "train_dataset = CustomDataset(X_train4, y_train4)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "haarL_-ci_xP"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if __name__ == '__main__':\n",
        "    # Define hyperparameters\n",
        "    latent_dim = 100\n",
        "    num_classes = 4  # Replace with the actual number of activity classes\n",
        "    num_epochs = 30\n",
        "    batch_size = 128\n",
        "\n",
        "    # Initialize models\n",
        "    generator = Generator(latent_dim=latent_dim)\n",
        "    discriminator = Discriminator(num_classes=num_classes)\n",
        "\n",
        "    # Create DataLoader\n",
        "    train_dataset = CustomDataset(X_train4, y_train4)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    # Train the S-GAN\n",
        "    train_sgan(generator, discriminator, train_loader, num_classes, num_epochs, latent_dim)"
      ],
      "metadata": {
        "id": "oaHDZ0bGib39",
        "outputId": "84a5eec8-6627-4a81-b929-c663eaac9118",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30] Batch [0/390] D_loss: 2.7945, G_loss: 0.6534\n",
            "Epoch [1/30] Batch [100/390] D_loss: 1.4818, G_loss: 1.8593\n",
            "Epoch [1/30] Batch [200/390] D_loss: 1.5227, G_loss: 8.2651\n",
            "Epoch [1/30] Batch [300/390] D_loss: 1.7678, G_loss: 2.5286\n",
            "Epoch [2/30] Batch [0/390] D_loss: 1.8856, G_loss: 1.6281\n",
            "Epoch [2/30] Batch [100/390] D_loss: 1.9706, G_loss: 5.6919\n",
            "Epoch [2/30] Batch [200/390] D_loss: 1.5695, G_loss: 2.2228\n",
            "Epoch [2/30] Batch [300/390] D_loss: 1.7653, G_loss: 1.9664\n",
            "Epoch [3/30] Batch [0/390] D_loss: 2.1089, G_loss: 1.9010\n",
            "Epoch [3/30] Batch [100/390] D_loss: 1.7046, G_loss: 2.0794\n",
            "Epoch [3/30] Batch [200/390] D_loss: 2.2641, G_loss: 1.4079\n",
            "Epoch [3/30] Batch [300/390] D_loss: 2.2493, G_loss: 1.7989\n",
            "Epoch [4/30] Batch [0/390] D_loss: 2.0315, G_loss: 1.6682\n",
            "Epoch [4/30] Batch [100/390] D_loss: 1.8261, G_loss: 1.1798\n",
            "Epoch [4/30] Batch [200/390] D_loss: 2.0601, G_loss: 1.7807\n",
            "Epoch [4/30] Batch [300/390] D_loss: 2.1892, G_loss: 1.2485\n",
            "Epoch [5/30] Batch [0/390] D_loss: 2.2203, G_loss: 1.1509\n",
            "Epoch [5/30] Batch [100/390] D_loss: 2.0161, G_loss: 1.2328\n",
            "Epoch [5/30] Batch [200/390] D_loss: 1.7220, G_loss: 1.2616\n",
            "Epoch [5/30] Batch [300/390] D_loss: 2.1952, G_loss: 1.3304\n",
            "Epoch [6/30] Batch [0/390] D_loss: 1.9354, G_loss: 1.7107\n",
            "Epoch [6/30] Batch [100/390] D_loss: 1.9086, G_loss: 1.6734\n",
            "Epoch [6/30] Batch [200/390] D_loss: 1.8276, G_loss: 1.2297\n",
            "Epoch [6/30] Batch [300/390] D_loss: 1.7972, G_loss: 1.9110\n",
            "Epoch [7/30] Batch [0/390] D_loss: 1.9561, G_loss: 1.8187\n",
            "Epoch [7/30] Batch [100/390] D_loss: 1.7130, G_loss: 2.0461\n",
            "Epoch [7/30] Batch [200/390] D_loss: 1.7355, G_loss: 2.0796\n",
            "Epoch [7/30] Batch [300/390] D_loss: 2.1081, G_loss: 1.8730\n",
            "Epoch [8/30] Batch [0/390] D_loss: 2.1101, G_loss: 1.8510\n",
            "Epoch [8/30] Batch [100/390] D_loss: 2.0278, G_loss: 1.7556\n",
            "Epoch [8/30] Batch [200/390] D_loss: 2.0324, G_loss: 2.0430\n",
            "Epoch [8/30] Batch [300/390] D_loss: 1.8956, G_loss: 1.3668\n",
            "Epoch [9/30] Batch [0/390] D_loss: 2.0096, G_loss: 1.4704\n",
            "Epoch [9/30] Batch [100/390] D_loss: 1.7673, G_loss: 1.1074\n",
            "Epoch [9/30] Batch [200/390] D_loss: 1.6818, G_loss: 1.9300\n",
            "Epoch [9/30] Batch [300/390] D_loss: 1.6400, G_loss: 2.1528\n",
            "Epoch [10/30] Batch [0/390] D_loss: 2.0647, G_loss: 1.2420\n",
            "Epoch [10/30] Batch [100/390] D_loss: 1.7478, G_loss: 1.8002\n",
            "Epoch [10/30] Batch [200/390] D_loss: 1.8872, G_loss: 1.2294\n",
            "Epoch [10/30] Batch [300/390] D_loss: 1.7748, G_loss: 1.3512\n",
            "Epoch [11/30] Batch [0/390] D_loss: 1.8144, G_loss: 1.7512\n",
            "Epoch [11/30] Batch [100/390] D_loss: 1.8167, G_loss: 1.6695\n",
            "Epoch [11/30] Batch [200/390] D_loss: 1.7945, G_loss: 1.6805\n",
            "Epoch [11/30] Batch [300/390] D_loss: 1.7802, G_loss: 1.8167\n",
            "Epoch [12/30] Batch [0/390] D_loss: 1.8358, G_loss: 1.6777\n",
            "Epoch [12/30] Batch [100/390] D_loss: 1.6532, G_loss: 1.8061\n",
            "Epoch [12/30] Batch [200/390] D_loss: 1.8492, G_loss: 1.3726\n",
            "Epoch [12/30] Batch [300/390] D_loss: 1.8805, G_loss: 1.6791\n",
            "Epoch [13/30] Batch [0/390] D_loss: 2.0665, G_loss: 1.2934\n",
            "Epoch [13/30] Batch [100/390] D_loss: 1.9880, G_loss: 1.4157\n",
            "Epoch [13/30] Batch [200/390] D_loss: 2.1521, G_loss: 1.4758\n",
            "Epoch [13/30] Batch [300/390] D_loss: 1.9773, G_loss: 1.3800\n",
            "Epoch [14/30] Batch [0/390] D_loss: 1.8659, G_loss: 2.1222\n",
            "Epoch [14/30] Batch [100/390] D_loss: 1.6120, G_loss: 1.8027\n",
            "Epoch [14/30] Batch [200/390] D_loss: 1.8427, G_loss: 1.3523\n",
            "Epoch [14/30] Batch [300/390] D_loss: 1.7959, G_loss: 1.4644\n",
            "Epoch [15/30] Batch [0/390] D_loss: 2.0888, G_loss: 1.3072\n",
            "Epoch [15/30] Batch [100/390] D_loss: 1.6946, G_loss: 1.4500\n",
            "Epoch [15/30] Batch [200/390] D_loss: 2.0168, G_loss: 1.4428\n",
            "Epoch [15/30] Batch [300/390] D_loss: 1.9832, G_loss: 1.3801\n",
            "Epoch [16/30] Batch [0/390] D_loss: 1.6149, G_loss: 1.9219\n",
            "Epoch [16/30] Batch [100/390] D_loss: 1.7978, G_loss: 1.3368\n",
            "Epoch [16/30] Batch [200/390] D_loss: 1.5716, G_loss: 1.9667\n",
            "Epoch [16/30] Batch [300/390] D_loss: 1.6019, G_loss: 1.8413\n",
            "Epoch [17/30] Batch [0/390] D_loss: 1.5262, G_loss: 1.7992\n",
            "Epoch [17/30] Batch [100/390] D_loss: 1.8019, G_loss: 1.5691\n",
            "Epoch [17/30] Batch [200/390] D_loss: 1.6993, G_loss: 2.0226\n",
            "Epoch [17/30] Batch [300/390] D_loss: 1.8969, G_loss: 1.5480\n",
            "Epoch [18/30] Batch [0/390] D_loss: 1.6755, G_loss: 1.7791\n",
            "Epoch [18/30] Batch [100/390] D_loss: 1.6876, G_loss: 1.5513\n",
            "Epoch [18/30] Batch [200/390] D_loss: 1.8063, G_loss: 1.5870\n",
            "Epoch [18/30] Batch [300/390] D_loss: 1.9207, G_loss: 1.6409\n",
            "Epoch [19/30] Batch [0/390] D_loss: 1.5256, G_loss: 2.0344\n",
            "Epoch [19/30] Batch [100/390] D_loss: 1.7053, G_loss: 1.6808\n",
            "Epoch [19/30] Batch [200/390] D_loss: 1.6129, G_loss: 1.5436\n",
            "Epoch [19/30] Batch [300/390] D_loss: 1.9358, G_loss: 1.7303\n",
            "Epoch [20/30] Batch [0/390] D_loss: 1.9883, G_loss: 1.5321\n",
            "Epoch [20/30] Batch [100/390] D_loss: 1.5875, G_loss: 2.1587\n",
            "Epoch [20/30] Batch [200/390] D_loss: 1.9474, G_loss: 1.9687\n",
            "Epoch [20/30] Batch [300/390] D_loss: 1.6214, G_loss: 1.8468\n",
            "Epoch [21/30] Batch [0/390] D_loss: 1.6388, G_loss: 1.6032\n",
            "Epoch [21/30] Batch [100/390] D_loss: 1.6359, G_loss: 2.0799\n",
            "Epoch [21/30] Batch [200/390] D_loss: 1.6278, G_loss: 2.0319\n",
            "Epoch [21/30] Batch [300/390] D_loss: 1.8580, G_loss: 1.4106\n",
            "Epoch [22/30] Batch [0/390] D_loss: 1.6952, G_loss: 1.9241\n",
            "Epoch [22/30] Batch [100/390] D_loss: 1.6240, G_loss: 1.6235\n",
            "Epoch [22/30] Batch [200/390] D_loss: 1.6561, G_loss: 1.5918\n",
            "Epoch [22/30] Batch [300/390] D_loss: 1.7967, G_loss: 2.2620\n",
            "Epoch [23/30] Batch [0/390] D_loss: 1.6555, G_loss: 1.6816\n",
            "Epoch [23/30] Batch [100/390] D_loss: 1.6669, G_loss: 1.6681\n",
            "Epoch [23/30] Batch [200/390] D_loss: 1.5649, G_loss: 1.5346\n",
            "Epoch [23/30] Batch [300/390] D_loss: 1.6427, G_loss: 1.5937\n",
            "Epoch [24/30] Batch [0/390] D_loss: 1.4968, G_loss: 1.9022\n",
            "Epoch [24/30] Batch [100/390] D_loss: 1.5432, G_loss: 1.7810\n",
            "Epoch [24/30] Batch [200/390] D_loss: 1.4378, G_loss: 1.8594\n",
            "Epoch [24/30] Batch [300/390] D_loss: 1.8566, G_loss: 1.7301\n",
            "Epoch [25/30] Batch [0/390] D_loss: 1.6182, G_loss: 1.8815\n",
            "Epoch [25/30] Batch [100/390] D_loss: 1.7653, G_loss: 1.7479\n",
            "Epoch [25/30] Batch [200/390] D_loss: 1.7254, G_loss: 1.7335\n",
            "Epoch [25/30] Batch [300/390] D_loss: 1.4491, G_loss: 1.6791\n",
            "Epoch [26/30] Batch [0/390] D_loss: 1.5824, G_loss: 2.0109\n",
            "Epoch [26/30] Batch [100/390] D_loss: 1.9707, G_loss: 1.7955\n",
            "Epoch [26/30] Batch [200/390] D_loss: 1.4787, G_loss: 1.8880\n",
            "Epoch [26/30] Batch [300/390] D_loss: 1.8382, G_loss: 1.8049\n",
            "Epoch [27/30] Batch [0/390] D_loss: 1.4160, G_loss: 1.9156\n",
            "Epoch [27/30] Batch [100/390] D_loss: 1.5027, G_loss: 1.8403\n",
            "Epoch [27/30] Batch [200/390] D_loss: 1.2711, G_loss: 2.0129\n",
            "Epoch [27/30] Batch [300/390] D_loss: 1.8201, G_loss: 1.7440\n",
            "Epoch [28/30] Batch [0/390] D_loss: 1.6808, G_loss: 1.4356\n",
            "Epoch [28/30] Batch [100/390] D_loss: 1.6824, G_loss: 1.8530\n",
            "Epoch [28/30] Batch [200/390] D_loss: 1.2769, G_loss: 1.9442\n",
            "Epoch [28/30] Batch [300/390] D_loss: 1.4531, G_loss: 2.3723\n",
            "Epoch [29/30] Batch [0/390] D_loss: 1.5769, G_loss: 1.9126\n",
            "Epoch [29/30] Batch [100/390] D_loss: 1.6334, G_loss: 1.6761\n",
            "Epoch [29/30] Batch [200/390] D_loss: 1.6837, G_loss: 2.0254\n",
            "Epoch [29/30] Batch [300/390] D_loss: 1.6852, G_loss: 1.6223\n",
            "Epoch [30/30] Batch [0/390] D_loss: 1.6615, G_loss: 1.5501\n",
            "Epoch [30/30] Batch [100/390] D_loss: 1.5627, G_loss: 1.6335\n",
            "Epoch [30/30] Batch [200/390] D_loss: 1.5375, G_loss: 2.5614\n",
            "Epoch [30/30] Batch [300/390] D_loss: 1.6833, G_loss: 1.5468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test"
      ],
      "metadata": {
        "id": "NgIrcqyFmQYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already imported necessary libraries and defined CustomDataset\n",
        "\n",
        "# Create test dataset\n",
        "test_dataset = CustomDataset(X_test4, y_test4)\n",
        "\n",
        "# Create DataLoader\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "qa6kJsfWj8TL"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the discriminator to evaluation mode\n",
        "discriminator.eval()\n"
      ],
      "metadata": {
        "id": "1FUJ56YVkJg3",
        "outputId": "398f3d35-7e20-4481-a9b3-a3753eaf764d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv1d(3, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv1d(512, 1024, kernel_size=(4,), stride=(2,), padding=(1,))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (shared_features): Flatten(start_dim=1, end_dim=-1)\n",
              "  (classifier): Linear(in_features=32768, out_features=4, bias=True)\n",
              "  (discriminator): Sequential(\n",
              "    (0): Linear(in_features=32768, out_features=1, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Lists to store predictions and true labels\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "# Define the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_test, y_test in test_loader:\n",
        "        x_test = x_test.to(device)\n",
        "        y_test = y_test.to(device)\n",
        "\n",
        "        # Get the class outputs from the discriminator\n",
        "        class_output, _ = discriminator(x_test)\n",
        "\n",
        "        # Get the predicted class (the index with the highest score)\n",
        "        _, preds = torch.max(class_output, 1)\n",
        "\n",
        "        # Store predictions and true labels\n",
        "        all_preds.append(preds.cpu().numpy())\n",
        "        all_labels.append(y_test.cpu().numpy())\n",
        "\n",
        "# Concatenate all predictions and labels into single arrays\n",
        "all_preds = np.concatenate(all_preds)\n",
        "all_labels = np.concatenate(all_labels)\n",
        "\n",
        "# Compute overall accuracy\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(all_labels, all_preds, digits=4)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Generate a confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Compute per-class recall\n",
        "classes = np.unique(all_labels)\n",
        "per_class_recall = {}\n",
        "\n",
        "for idx, cls in enumerate(classes):\n",
        "    # True Positives (TP): Correct predictions for class 'cls'\n",
        "    TP = cm[idx, idx]\n",
        "    # False Negatives (FN): Actual class 'cls' but predicted differently\n",
        "    FN = np.sum(cm[idx, :]) - TP\n",
        "\n",
        "    # Recall = TP / (TP + FN)\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "    per_class_recall[cls] = recall\n",
        "\n",
        "# Print per-class recall\n",
        "print(\"Per-class Recall:\")\n",
        "for cls, recall in per_class_recall.items():\n",
        "    print(f\"Class {cls}: {recall:.4f}\")\n",
        "\n",
        "per_class_accuracy = {}\n",
        "\n",
        "for idx, cls in enumerate(classes):\n",
        "    # True Positives (TP): Correct predictions for class 'cls'\n",
        "    TP = cm[idx, idx]\n",
        "    # True Negatives (TN): Correct predictions for all other classes\n",
        "    TN = np.sum(cm) - (np.sum(cm[idx, :]) + np.sum(cm[:, idx]) - TP)\n",
        "    # False Positives (FP): Incorrectly predicted as class 'cls'\n",
        "    FP = np.sum(cm[:, idx]) - TP\n",
        "    # False Negatives (FN): Actual class 'cls' but predicted differently\n",
        "    FN = np.sum(cm[idx, :]) - TP\n",
        "\n",
        "    # Per-class accuracy\n",
        "    acc = (TP + TN) / total_samples\n",
        "    per_class_accuracy[cls] = acc\n",
        "\n",
        "# Print per-class accuracy\n",
        "print(\"Per-class Accuracy:\")\n",
        "for cls, acc in per_class_accuracy.items():\n",
        "    print(f\"Class {cls}: {acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "qFEiFYjikM4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff254b5-322f-4f4c-a23a-5e99a6d92f08"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5550\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7633    0.2357    0.3602      2435\n",
            "           1     0.4764    0.5637    0.5164      1884\n",
            "           2     0.3835    0.0986    0.1568      1887\n",
            "           3     0.5663    0.8128    0.6675      6294\n",
            "\n",
            "    accuracy                         0.5550     12500\n",
            "   macro avg     0.5474    0.4277    0.4252     12500\n",
            "weighted avg     0.5635    0.5550    0.5078     12500\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 574   25    7 1829]\n",
            " [  91 1062   68  663]\n",
            " [   6  269  186 1426]\n",
            " [  81  873  224 5116]]\n",
            "Per-class Recall:\n",
            "Class 0: 0.2357\n",
            "Class 1: 0.5637\n",
            "Class 2: 0.0986\n",
            "Class 3: 0.8128\n",
            "Per-class Accuracy:\n",
            "Class 0: 0.8369\n",
            "Class 1: 0.8409\n",
            "Class 2: 0.8400\n",
            "Class 3: 0.5923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AC-GAN"
      ],
      "metadata": {
        "id": "zaUg7mQddk1e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train"
      ],
      "metadata": {
        "id": "cmPXf0_9iEcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "BvlzSzN8dm0d"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator6(nn.Module):\n",
        "  def __init__(self, latent_dim=100, num_classes=4, output_channels=3):\n",
        "    super(Generator6, self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "    self.num_classes = num_classes\n",
        "\n",
        "    # Layers for processing noise vector z\n",
        "    self.fc_z = nn.Linear(latent_dim, 1024 * 4)  # Output: (batch_size, 4096)\n",
        "\n",
        "    # Layers for processing class labels c\n",
        "    self.fc_c = nn.Linear(num_classes, 1024 * 4)  # Output: (batch_size, 4096)\n",
        "\n",
        "    self.deconv1 = nn.Sequential(\n",
        "      nn.ConvTranspose1d(2048, 512, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 512, 8)\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "      nn.Dropout(0.5)\n",
        "    )\n",
        "    self.deconv2 = nn.Sequential(\n",
        "      nn.ConvTranspose1d(512, 256, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 256, 16)\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "      nn.Dropout(0.5)\n",
        "    )\n",
        "    self.deconv3 = nn.Sequential(\n",
        "      nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 128, 32)\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "      nn.Dropout(0.5)\n",
        "    )\n",
        "    self.deconv4 = nn.Sequential(\n",
        "      nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 64, 64)\n",
        "      nn.LeakyReLU(0.2, inplace=True),\n",
        "      nn.Dropout(0.5)\n",
        "    )\n",
        "    self.deconv5 = nn.Sequential(\n",
        "      nn.ConvTranspose1d(64, output_channels, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 3, 128)\n",
        "      nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, z, c):\n",
        "    # Process noise vector z\n",
        "    x_z = self.fc_z(z)  # Shape: (batch_size, 4096)\n",
        "    x_z = x_z.view(-1, 1024, 4)\n",
        "\n",
        "    # One-hot encode class labels and process\n",
        "    c = F.one_hot(c, num_classes=self.num_classes).float()\n",
        "    x_c = self.fc_c(c)  # Shape: (batch_size, 4096)\n",
        "    x_c = x_c.view(-1, 1024, 4)\n",
        "\n",
        "    # Concatenate feature maps\n",
        "    x = torch.cat([x_z, x_c], dim=1)  # Shape: (batch_size, 2048, 4)\n",
        "\n",
        "    # Pass through deconvolutional layers\n",
        "    x = self.deconv1(x)\n",
        "    x = self.deconv2(x)\n",
        "    x = self.deconv3(x)\n",
        "    x = self.deconv4(x)\n",
        "    x = self.deconv5(x)\n",
        "    return x  # Output shape: (batch_size, 3, 128)\n"
      ],
      "metadata": {
        "id": "BMUdkBIdhBbN"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator6(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Discriminator6, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv1d(3, 512, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 512, 64)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv1d(512, 1024, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 1024, 32)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "        self.shared_features = nn.Flatten()  # Flattens to (batch_size, 1024*32)\n",
        "\n",
        "        self.classifier = nn.Linear(1024 * 32, num_classes)\n",
        "        self.discriminator = nn.Sequential(\n",
        "            nn.Linear(1024 * 32, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        features = self.shared_features(x)\n",
        "\n",
        "        class_output = self.classifier(features)\n",
        "        real_fake_output = self.discriminator(features)\n",
        "        return class_output, real_fake_output"
      ],
      "metadata": {
        "id": "8pv2IrTDg-hc"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "def train_acgan6(generator, discriminator, dataloader, num_classes, num_epochs=30, latent_dim=100):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "\n",
        "    criterion_class = nn.CrossEntropyLoss()\n",
        "    criterion_real_fake = nn.BCELoss()\n",
        "\n",
        "    optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "    optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (x_real, labels_real) in enumerate(dataloader):\n",
        "            x_real = x_real.to(device)\n",
        "            labels_real = labels_real.to(device)\n",
        "            batch_size = x_real.size(0)\n",
        "            half_batch = batch_size // 2\n",
        "\n",
        "            # Prepare labels\n",
        "            real_labels = torch.ones(half_batch, 1).to(device)\n",
        "            fake_labels = torch.zeros(half_batch, 1).to(device)\n",
        "\n",
        "            # ====================\n",
        "            # Train Discriminator\n",
        "            # ====================\n",
        "            discriminator.train()\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            # Train on real data\n",
        "            x_real_half = x_real[:half_batch]\n",
        "            labels_real_half = labels_real[:half_batch]\n",
        "            class_output_real, real_fake_output_real = discriminator(x_real_half)\n",
        "            d_loss_real_class = criterion_class(class_output_real, labels_real_half)\n",
        "            d_loss_real_rf = criterion_real_fake(real_fake_output_real, real_labels)\n",
        "\n",
        "            # Train on fake data\n",
        "            z = torch.randn(half_batch, latent_dim).to(device)\n",
        "            c_fake = torch.randint(0, num_classes, (half_batch,)).to(device)\n",
        "            x_fake = generator(z, c_fake)\n",
        "            class_output_fake, real_fake_output_fake = discriminator(x_fake.detach())\n",
        "            d_loss_fake_class = criterion_class(class_output_fake, c_fake)\n",
        "            d_loss_fake_rf = criterion_real_fake(real_fake_output_fake, fake_labels)\n",
        "\n",
        "            # Total discriminator loss\n",
        "            d_loss = d_loss_real_class + d_loss_real_rf + d_loss_fake_class + d_loss_fake_rf\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "            # ====================\n",
        "            # Train Generator\n",
        "            # ====================\n",
        "            # Freeze discriminator parameters\n",
        "            for param in discriminator.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "            generator.train()\n",
        "            optimizer_G.zero_grad()\n",
        "\n",
        "            # Generate fake data\n",
        "            z = torch.randn(batch_size, latent_dim).to(device)\n",
        "            c_fake = torch.randint(0, num_classes, (batch_size,)).to(device)\n",
        "            x_fake = generator(z, c_fake)\n",
        "\n",
        "            # Forward pass through discriminator\n",
        "            class_output_fake, real_fake_output_fake = discriminator(x_fake)\n",
        "\n",
        "            # Generator wants discriminator to classify fake data as real and with correct class\n",
        "            real_labels_g = torch.ones(batch_size, 1).to(device)\n",
        "            g_loss_rf = criterion_real_fake(real_fake_output_fake, real_labels_g)\n",
        "            g_loss_class = criterion_class(class_output_fake, c_fake)\n",
        "            g_loss = g_loss_rf + g_loss_class\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            # Unfreeze discriminator parameters\n",
        "            for param in discriminator.parameters():\n",
        "                param.requires_grad = True\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print(f'Epoch [{epoch+1}/{num_epochs}] Batch [{i}/{len(dataloader)}] '\n",
        "                      f'D_loss: {d_loss.item():.4f}, G_loss: {g_loss.item():.4f}')\n",
        "\n",
        "# Normalize the data as before\n",
        "mean6 = X_train4.mean()\n",
        "std6 = X_train4.std()\n",
        "\n",
        "X_train4 = (X_train4 - mean6) / std6\n",
        "X_test4 = (X_test4 - mean6) / std6\n",
        "\n",
        "X_train4 = np.clip(X_train4, -1, 1)\n",
        "X_test4 = np.clip(X_test4, -1, 1)\n",
        "\n",
        "class CustomDataset6(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X  # NumPy array of shape (num_samples, seq_length, num_features)\n",
        "        self.y = y  # NumPy array of shape (num_samples,)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the sample and label\n",
        "        x = self.X[idx]  # Shape: (128, 3)\n",
        "        y = self.y[idx]\n",
        "\n",
        "        # Convert to torch tensors and transpose x to shape (num_features, seq_length)\n",
        "        x = torch.tensor(x, dtype=torch.float32).transpose(0, 1)  # Shape: (3, 128)\n",
        "        y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "N0kgC90JdtlB"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "if __name__ == '__main__':\n",
        "    # Define hyperparameters\n",
        "    latent_dim6 = 100\n",
        "    num_classes6 = 4  # Replace with the actual number of activity classes\n",
        "\n",
        "    #num_epochs6 = 30\n",
        "    batch_size6 = 128\n",
        "\n",
        "    # Initialize models\n",
        "    generator6 = Generator6(latent_dim=latent_dim6, num_classes=num_classes6)\n",
        "    discriminator6 = Discriminator6(num_classes=num_classes6)\n",
        "\n",
        "    # Create DataLoader\n",
        "    train_dataset6 = CustomDataset6(X_train4, y_train4)\n",
        "    sampler6 = RandomSampler(train_dataset6, replacement=True)\n",
        "    train_loader6 = DataLoader(train_dataset6, batch_size=batch_size6, sampler=sampler6)\n",
        "\n",
        "    num_mini_batches_per_epoch = len(train_loader6)\n",
        "    num_epochs6 = (25000 + num_mini_batches_per_epoch - 1) // num_mini_batches_per_epoch  # Ceiling division\n",
        "\n",
        "    # Train the AC-GAN\n",
        "    train_acgan6(generator6, discriminator6, train_loader6, num_classes6, num_epochs6, latent_dim6)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fg-EWKG8dr7p",
        "outputId": "2abc69ce-5a7c-4a52-b2da-87ec59102af5"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/65] Batch [0/390] D_loss: 4.1358, G_loss: 2.0260\n",
            "Epoch [1/65] Batch [100/390] D_loss: 2.3976, G_loss: 3.4361\n",
            "Epoch [1/65] Batch [200/390] D_loss: 1.3806, G_loss: 4.2746\n",
            "Epoch [1/65] Batch [300/390] D_loss: 1.9244, G_loss: 3.3999\n",
            "Epoch [2/65] Batch [0/390] D_loss: 1.5488, G_loss: 3.1709\n",
            "Epoch [2/65] Batch [100/390] D_loss: 2.1223, G_loss: 3.6851\n",
            "Epoch [2/65] Batch [200/390] D_loss: 2.2744, G_loss: 2.4735\n",
            "Epoch [2/65] Batch [300/390] D_loss: 1.9704, G_loss: 1.3341\n",
            "Epoch [3/65] Batch [0/390] D_loss: 2.3067, G_loss: 1.6056\n",
            "Epoch [3/65] Batch [100/390] D_loss: 2.4991, G_loss: 2.5250\n",
            "Epoch [3/65] Batch [200/390] D_loss: 2.0906, G_loss: 2.0461\n",
            "Epoch [3/65] Batch [300/390] D_loss: 2.0035, G_loss: 2.0822\n",
            "Epoch [4/65] Batch [0/390] D_loss: 1.8572, G_loss: 2.5043\n",
            "Epoch [4/65] Batch [100/390] D_loss: 1.9339, G_loss: 2.6107\n",
            "Epoch [4/65] Batch [200/390] D_loss: 2.1923, G_loss: 1.8695\n",
            "Epoch [4/65] Batch [300/390] D_loss: 1.9960, G_loss: 1.9276\n",
            "Epoch [5/65] Batch [0/390] D_loss: 2.1414, G_loss: 1.0374\n",
            "Epoch [5/65] Batch [100/390] D_loss: 2.1396, G_loss: 2.1063\n",
            "Epoch [5/65] Batch [200/390] D_loss: 1.7898, G_loss: 1.5358\n",
            "Epoch [5/65] Batch [300/390] D_loss: 1.7585, G_loss: 1.9460\n",
            "Epoch [6/65] Batch [0/390] D_loss: 1.9651, G_loss: 2.1896\n",
            "Epoch [6/65] Batch [100/390] D_loss: 1.8917, G_loss: 1.9696\n",
            "Epoch [6/65] Batch [200/390] D_loss: 1.9804, G_loss: 2.7757\n",
            "Epoch [6/65] Batch [300/390] D_loss: 2.0905, G_loss: 2.1519\n",
            "Epoch [7/65] Batch [0/390] D_loss: 1.8429, G_loss: 3.2544\n",
            "Epoch [7/65] Batch [100/390] D_loss: 1.8573, G_loss: 2.9413\n",
            "Epoch [7/65] Batch [200/390] D_loss: 1.8772, G_loss: 1.6618\n",
            "Epoch [7/65] Batch [300/390] D_loss: 1.7439, G_loss: 1.7684\n",
            "Epoch [8/65] Batch [0/390] D_loss: 1.8847, G_loss: 2.2735\n",
            "Epoch [8/65] Batch [100/390] D_loss: 2.1563, G_loss: 4.4999\n",
            "Epoch [8/65] Batch [200/390] D_loss: 2.0002, G_loss: 2.1928\n",
            "Epoch [8/65] Batch [300/390] D_loss: 1.8718, G_loss: 2.5647\n",
            "Epoch [9/65] Batch [0/390] D_loss: 1.7395, G_loss: 3.0174\n",
            "Epoch [9/65] Batch [100/390] D_loss: 1.9949, G_loss: 2.0175\n",
            "Epoch [9/65] Batch [200/390] D_loss: 2.0068, G_loss: 1.9297\n",
            "Epoch [9/65] Batch [300/390] D_loss: 2.1988, G_loss: 1.3646\n",
            "Epoch [10/65] Batch [0/390] D_loss: 2.1885, G_loss: 2.0894\n",
            "Epoch [10/65] Batch [100/390] D_loss: 2.0026, G_loss: 1.7887\n",
            "Epoch [10/65] Batch [200/390] D_loss: 1.9352, G_loss: 2.3830\n",
            "Epoch [10/65] Batch [300/390] D_loss: 2.1558, G_loss: 1.7498\n",
            "Epoch [11/65] Batch [0/390] D_loss: 1.7371, G_loss: 2.5047\n",
            "Epoch [11/65] Batch [100/390] D_loss: 2.0457, G_loss: 1.6277\n",
            "Epoch [11/65] Batch [200/390] D_loss: 1.7077, G_loss: 2.3973\n",
            "Epoch [11/65] Batch [300/390] D_loss: 1.8262, G_loss: 1.7574\n",
            "Epoch [12/65] Batch [0/390] D_loss: 1.8906, G_loss: 2.1598\n",
            "Epoch [12/65] Batch [100/390] D_loss: 1.9829, G_loss: 1.5394\n",
            "Epoch [12/65] Batch [200/390] D_loss: 1.5498, G_loss: 1.9686\n",
            "Epoch [12/65] Batch [300/390] D_loss: 1.8341, G_loss: 2.1147\n",
            "Epoch [13/65] Batch [0/390] D_loss: 1.6474, G_loss: 2.1946\n",
            "Epoch [13/65] Batch [100/390] D_loss: 1.8764, G_loss: 2.4840\n",
            "Epoch [13/65] Batch [200/390] D_loss: 1.6204, G_loss: 3.2624\n",
            "Epoch [13/65] Batch [300/390] D_loss: 1.8419, G_loss: 3.6074\n",
            "Epoch [14/65] Batch [0/390] D_loss: 1.8609, G_loss: 2.1583\n",
            "Epoch [14/65] Batch [100/390] D_loss: 2.0404, G_loss: 2.5469\n",
            "Epoch [14/65] Batch [200/390] D_loss: 1.8638, G_loss: 2.2250\n",
            "Epoch [14/65] Batch [300/390] D_loss: 1.6378, G_loss: 3.0544\n",
            "Epoch [15/65] Batch [0/390] D_loss: 2.0147, G_loss: 1.9108\n",
            "Epoch [15/65] Batch [100/390] D_loss: 1.9115, G_loss: 2.1704\n",
            "Epoch [15/65] Batch [200/390] D_loss: 1.7320, G_loss: 2.9174\n",
            "Epoch [15/65] Batch [300/390] D_loss: 1.6037, G_loss: 2.9092\n",
            "Epoch [16/65] Batch [0/390] D_loss: 2.0919, G_loss: 1.9952\n",
            "Epoch [16/65] Batch [100/390] D_loss: 1.8394, G_loss: 2.3348\n",
            "Epoch [16/65] Batch [200/390] D_loss: 1.8954, G_loss: 2.3435\n",
            "Epoch [16/65] Batch [300/390] D_loss: 1.7391, G_loss: 2.2163\n",
            "Epoch [17/65] Batch [0/390] D_loss: 1.8924, G_loss: 6.4068\n",
            "Epoch [17/65] Batch [100/390] D_loss: 3.1730, G_loss: 2.8204\n",
            "Epoch [17/65] Batch [200/390] D_loss: 2.2094, G_loss: 2.2236\n",
            "Epoch [17/65] Batch [300/390] D_loss: 2.0076, G_loss: 2.2049\n",
            "Epoch [18/65] Batch [0/390] D_loss: 2.0305, G_loss: 2.0959\n",
            "Epoch [18/65] Batch [100/390] D_loss: 1.9290, G_loss: 1.9447\n",
            "Epoch [18/65] Batch [200/390] D_loss: 2.0478, G_loss: 2.1508\n",
            "Epoch [18/65] Batch [300/390] D_loss: 1.9522, G_loss: 2.0010\n",
            "Epoch [19/65] Batch [0/390] D_loss: 2.2782, G_loss: 2.2321\n",
            "Epoch [19/65] Batch [100/390] D_loss: 1.8903, G_loss: 2.2359\n",
            "Epoch [19/65] Batch [200/390] D_loss: 1.9509, G_loss: 2.0406\n",
            "Epoch [19/65] Batch [300/390] D_loss: 1.7337, G_loss: 2.8168\n",
            "Epoch [20/65] Batch [0/390] D_loss: 1.7128, G_loss: 2.6004\n",
            "Epoch [20/65] Batch [100/390] D_loss: 1.8859, G_loss: 2.4169\n",
            "Epoch [20/65] Batch [200/390] D_loss: 1.9451, G_loss: 2.6447\n",
            "Epoch [20/65] Batch [300/390] D_loss: 2.0849, G_loss: 2.5986\n",
            "Epoch [21/65] Batch [0/390] D_loss: 1.7359, G_loss: 2.9762\n",
            "Epoch [21/65] Batch [100/390] D_loss: 1.4377, G_loss: 3.0447\n",
            "Epoch [21/65] Batch [200/390] D_loss: 1.9664, G_loss: 3.4942\n",
            "Epoch [21/65] Batch [300/390] D_loss: 1.5915, G_loss: 2.6210\n",
            "Epoch [22/65] Batch [0/390] D_loss: 1.8442, G_loss: 2.5030\n",
            "Epoch [22/65] Batch [100/390] D_loss: 1.7693, G_loss: 2.5795\n",
            "Epoch [22/65] Batch [200/390] D_loss: 1.8836, G_loss: 2.4179\n",
            "Epoch [22/65] Batch [300/390] D_loss: 1.8682, G_loss: 2.1861\n",
            "Epoch [23/65] Batch [0/390] D_loss: 1.8711, G_loss: 3.2328\n",
            "Epoch [23/65] Batch [100/390] D_loss: 1.9357, G_loss: 1.9466\n",
            "Epoch [23/65] Batch [200/390] D_loss: 1.5835, G_loss: 2.6723\n",
            "Epoch [23/65] Batch [300/390] D_loss: 1.6325, G_loss: 2.6519\n",
            "Epoch [24/65] Batch [0/390] D_loss: 1.6511, G_loss: 2.7408\n",
            "Epoch [24/65] Batch [100/390] D_loss: 1.7300, G_loss: 2.5434\n",
            "Epoch [24/65] Batch [200/390] D_loss: 1.9123, G_loss: 2.7570\n",
            "Epoch [24/65] Batch [300/390] D_loss: 1.5789, G_loss: 3.1329\n",
            "Epoch [25/65] Batch [0/390] D_loss: 1.8449, G_loss: 2.2153\n",
            "Epoch [25/65] Batch [100/390] D_loss: 1.7976, G_loss: 2.5637\n",
            "Epoch [25/65] Batch [200/390] D_loss: 1.9053, G_loss: 2.2421\n",
            "Epoch [25/65] Batch [300/390] D_loss: 2.1891, G_loss: 3.2717\n",
            "Epoch [26/65] Batch [0/390] D_loss: 1.6943, G_loss: 2.7232\n",
            "Epoch [26/65] Batch [100/390] D_loss: 1.9512, G_loss: 2.3227\n",
            "Epoch [26/65] Batch [200/390] D_loss: 1.7544, G_loss: 2.1686\n",
            "Epoch [26/65] Batch [300/390] D_loss: 1.7809, G_loss: 2.2318\n",
            "Epoch [27/65] Batch [0/390] D_loss: 1.9244, G_loss: 3.4413\n",
            "Epoch [27/65] Batch [100/390] D_loss: 1.9198, G_loss: 2.7394\n",
            "Epoch [27/65] Batch [200/390] D_loss: 2.2700, G_loss: 1.9498\n",
            "Epoch [27/65] Batch [300/390] D_loss: 1.9930, G_loss: 2.5049\n",
            "Epoch [28/65] Batch [0/390] D_loss: 2.1220, G_loss: 1.8747\n",
            "Epoch [28/65] Batch [100/390] D_loss: 1.8061, G_loss: 2.4284\n",
            "Epoch [28/65] Batch [200/390] D_loss: 1.7290, G_loss: 1.8923\n",
            "Epoch [28/65] Batch [300/390] D_loss: 1.7315, G_loss: 2.5846\n",
            "Epoch [29/65] Batch [0/390] D_loss: 2.0444, G_loss: 2.2356\n",
            "Epoch [29/65] Batch [100/390] D_loss: 1.9152, G_loss: 2.4498\n",
            "Epoch [29/65] Batch [200/390] D_loss: 1.3965, G_loss: 2.1457\n",
            "Epoch [29/65] Batch [300/390] D_loss: 1.6234, G_loss: 2.9260\n",
            "Epoch [30/65] Batch [0/390] D_loss: 1.5852, G_loss: 3.3207\n",
            "Epoch [30/65] Batch [100/390] D_loss: 1.8460, G_loss: 1.9282\n",
            "Epoch [30/65] Batch [200/390] D_loss: 1.5995, G_loss: 3.3661\n",
            "Epoch [30/65] Batch [300/390] D_loss: 1.6906, G_loss: 2.0911\n",
            "Epoch [31/65] Batch [0/390] D_loss: 1.5653, G_loss: 2.2842\n",
            "Epoch [31/65] Batch [100/390] D_loss: 1.8398, G_loss: 1.6791\n",
            "Epoch [31/65] Batch [200/390] D_loss: 1.7154, G_loss: 2.2807\n",
            "Epoch [31/65] Batch [300/390] D_loss: 1.6987, G_loss: 2.1481\n",
            "Epoch [32/65] Batch [0/390] D_loss: 1.9448, G_loss: 1.4908\n",
            "Epoch [32/65] Batch [100/390] D_loss: 1.5593, G_loss: 2.0286\n",
            "Epoch [32/65] Batch [200/390] D_loss: 1.6521, G_loss: 2.2845\n",
            "Epoch [32/65] Batch [300/390] D_loss: 1.5904, G_loss: 2.8915\n",
            "Epoch [33/65] Batch [0/390] D_loss: 1.8865, G_loss: 2.7039\n",
            "Epoch [33/65] Batch [100/390] D_loss: 1.5668, G_loss: 2.3560\n",
            "Epoch [33/65] Batch [200/390] D_loss: 1.7169, G_loss: 2.0477\n",
            "Epoch [33/65] Batch [300/390] D_loss: 1.5714, G_loss: 2.3852\n",
            "Epoch [34/65] Batch [0/390] D_loss: 2.1551, G_loss: 2.4803\n",
            "Epoch [34/65] Batch [100/390] D_loss: 1.5926, G_loss: 1.6942\n",
            "Epoch [34/65] Batch [200/390] D_loss: 1.6801, G_loss: 2.2392\n",
            "Epoch [34/65] Batch [300/390] D_loss: 1.6751, G_loss: 2.8015\n",
            "Epoch [35/65] Batch [0/390] D_loss: 1.8010, G_loss: 2.3766\n",
            "Epoch [35/65] Batch [100/390] D_loss: 1.5420, G_loss: 2.4251\n",
            "Epoch [35/65] Batch [200/390] D_loss: 1.9676, G_loss: 2.1394\n",
            "Epoch [35/65] Batch [300/390] D_loss: 1.7271, G_loss: 2.1535\n",
            "Epoch [36/65] Batch [0/390] D_loss: 1.8148, G_loss: 2.0473\n",
            "Epoch [36/65] Batch [100/390] D_loss: 1.3194, G_loss: 3.5700\n",
            "Epoch [36/65] Batch [200/390] D_loss: 1.5864, G_loss: 2.0557\n",
            "Epoch [36/65] Batch [300/390] D_loss: 1.7754, G_loss: 2.6973\n",
            "Epoch [37/65] Batch [0/390] D_loss: 1.6636, G_loss: 2.9453\n",
            "Epoch [37/65] Batch [100/390] D_loss: 1.4521, G_loss: 3.5876\n",
            "Epoch [37/65] Batch [200/390] D_loss: 1.6320, G_loss: 2.4437\n",
            "Epoch [37/65] Batch [300/390] D_loss: 1.7044, G_loss: 2.3880\n",
            "Epoch [38/65] Batch [0/390] D_loss: 1.5355, G_loss: 3.5977\n",
            "Epoch [38/65] Batch [100/390] D_loss: 1.9476, G_loss: 3.6899\n",
            "Epoch [38/65] Batch [200/390] D_loss: 1.8430, G_loss: 2.5644\n",
            "Epoch [38/65] Batch [300/390] D_loss: 1.7743, G_loss: 2.4088\n",
            "Epoch [39/65] Batch [0/390] D_loss: 1.6101, G_loss: 2.0830\n",
            "Epoch [39/65] Batch [100/390] D_loss: 1.7049, G_loss: 2.7897\n",
            "Epoch [39/65] Batch [200/390] D_loss: 1.6185, G_loss: 3.1466\n",
            "Epoch [39/65] Batch [300/390] D_loss: 1.7596, G_loss: 2.3622\n",
            "Epoch [40/65] Batch [0/390] D_loss: 1.8134, G_loss: 1.9291\n",
            "Epoch [40/65] Batch [100/390] D_loss: 1.8736, G_loss: 2.1265\n",
            "Epoch [40/65] Batch [200/390] D_loss: 1.6474, G_loss: 2.9254\n",
            "Epoch [40/65] Batch [300/390] D_loss: 1.3611, G_loss: 2.8390\n",
            "Epoch [41/65] Batch [0/390] D_loss: 1.8212, G_loss: 2.5382\n",
            "Epoch [41/65] Batch [100/390] D_loss: 1.9016, G_loss: 3.8433\n",
            "Epoch [41/65] Batch [200/390] D_loss: 1.8574, G_loss: 2.9701\n",
            "Epoch [41/65] Batch [300/390] D_loss: 1.8150, G_loss: 2.6658\n",
            "Epoch [42/65] Batch [0/390] D_loss: 1.6321, G_loss: 2.7660\n",
            "Epoch [42/65] Batch [100/390] D_loss: 1.5713, G_loss: 2.3376\n",
            "Epoch [42/65] Batch [200/390] D_loss: 1.7215, G_loss: 3.5254\n",
            "Epoch [42/65] Batch [300/390] D_loss: 2.0211, G_loss: 2.8519\n",
            "Epoch [43/65] Batch [0/390] D_loss: 1.6134, G_loss: 2.4449\n",
            "Epoch [43/65] Batch [100/390] D_loss: 1.7277, G_loss: 4.3466\n",
            "Epoch [43/65] Batch [200/390] D_loss: 1.5285, G_loss: 3.9293\n",
            "Epoch [43/65] Batch [300/390] D_loss: 1.2436, G_loss: 3.1532\n",
            "Epoch [44/65] Batch [0/390] D_loss: 1.7707, G_loss: 2.9163\n",
            "Epoch [44/65] Batch [100/390] D_loss: 1.5696, G_loss: 3.2783\n",
            "Epoch [44/65] Batch [200/390] D_loss: 1.9253, G_loss: 2.3380\n",
            "Epoch [44/65] Batch [300/390] D_loss: 1.7746, G_loss: 2.8130\n",
            "Epoch [45/65] Batch [0/390] D_loss: 2.0116, G_loss: 2.5924\n",
            "Epoch [45/65] Batch [100/390] D_loss: 1.6015, G_loss: 2.9199\n",
            "Epoch [45/65] Batch [200/390] D_loss: 1.5783, G_loss: 2.7598\n",
            "Epoch [45/65] Batch [300/390] D_loss: 1.6280, G_loss: 3.0395\n",
            "Epoch [46/65] Batch [0/390] D_loss: 1.4210, G_loss: 2.7318\n",
            "Epoch [46/65] Batch [100/390] D_loss: 1.7832, G_loss: 2.8706\n",
            "Epoch [46/65] Batch [200/390] D_loss: 1.6482, G_loss: 3.3052\n",
            "Epoch [46/65] Batch [300/390] D_loss: 1.5855, G_loss: 2.8528\n",
            "Epoch [47/65] Batch [0/390] D_loss: 1.6123, G_loss: 2.5536\n",
            "Epoch [47/65] Batch [100/390] D_loss: 1.2618, G_loss: 3.5586\n",
            "Epoch [47/65] Batch [200/390] D_loss: 2.0252, G_loss: 2.4761\n",
            "Epoch [47/65] Batch [300/390] D_loss: 2.0484, G_loss: 3.3430\n",
            "Epoch [48/65] Batch [0/390] D_loss: 1.7471, G_loss: 2.1430\n",
            "Epoch [48/65] Batch [100/390] D_loss: 1.5100, G_loss: 2.6508\n",
            "Epoch [48/65] Batch [200/390] D_loss: 2.1266, G_loss: 2.5317\n",
            "Epoch [48/65] Batch [300/390] D_loss: 1.8779, G_loss: 1.8709\n",
            "Epoch [49/65] Batch [0/390] D_loss: 1.9228, G_loss: 2.8441\n",
            "Epoch [49/65] Batch [100/390] D_loss: 1.8846, G_loss: 2.4257\n",
            "Epoch [49/65] Batch [200/390] D_loss: 1.6984, G_loss: 2.0165\n",
            "Epoch [49/65] Batch [300/390] D_loss: 2.0016, G_loss: 2.0748\n",
            "Epoch [50/65] Batch [0/390] D_loss: 1.5626, G_loss: 3.7573\n",
            "Epoch [50/65] Batch [100/390] D_loss: 1.5297, G_loss: 2.5836\n",
            "Epoch [50/65] Batch [200/390] D_loss: 1.4207, G_loss: 3.0142\n",
            "Epoch [50/65] Batch [300/390] D_loss: 1.4304, G_loss: 4.0278\n",
            "Epoch [51/65] Batch [0/390] D_loss: 2.5204, G_loss: 4.0616\n",
            "Epoch [51/65] Batch [100/390] D_loss: 1.4167, G_loss: 3.7955\n",
            "Epoch [51/65] Batch [200/390] D_loss: 1.5223, G_loss: 3.1913\n",
            "Epoch [51/65] Batch [300/390] D_loss: 1.5153, G_loss: 3.0781\n",
            "Epoch [52/65] Batch [0/390] D_loss: 1.7499, G_loss: 3.3656\n",
            "Epoch [52/65] Batch [100/390] D_loss: 2.0198, G_loss: 2.6449\n",
            "Epoch [52/65] Batch [200/390] D_loss: 1.4080, G_loss: 3.7065\n",
            "Epoch [52/65] Batch [300/390] D_loss: 1.3567, G_loss: 4.6256\n",
            "Epoch [53/65] Batch [0/390] D_loss: 1.6839, G_loss: 2.4818\n",
            "Epoch [53/65] Batch [100/390] D_loss: 1.4010, G_loss: 5.1775\n",
            "Epoch [53/65] Batch [200/390] D_loss: 1.3680, G_loss: 3.1648\n",
            "Epoch [53/65] Batch [300/390] D_loss: 1.5811, G_loss: 3.5373\n",
            "Epoch [54/65] Batch [0/390] D_loss: 1.4277, G_loss: 3.0750\n",
            "Epoch [54/65] Batch [100/390] D_loss: 1.5989, G_loss: 4.4963\n",
            "Epoch [54/65] Batch [200/390] D_loss: 1.4817, G_loss: 2.8456\n",
            "Epoch [54/65] Batch [300/390] D_loss: 1.3740, G_loss: 3.9659\n",
            "Epoch [55/65] Batch [0/390] D_loss: 1.7339, G_loss: 2.9502\n",
            "Epoch [55/65] Batch [100/390] D_loss: 1.6684, G_loss: 3.0303\n",
            "Epoch [55/65] Batch [200/390] D_loss: 1.3249, G_loss: 2.9938\n",
            "Epoch [55/65] Batch [300/390] D_loss: 1.4395, G_loss: 3.1171\n",
            "Epoch [56/65] Batch [0/390] D_loss: 2.4423, G_loss: 4.4595\n",
            "Epoch [56/65] Batch [100/390] D_loss: 1.7517, G_loss: 3.5696\n",
            "Epoch [56/65] Batch [200/390] D_loss: 1.5678, G_loss: 2.8574\n",
            "Epoch [56/65] Batch [300/390] D_loss: 1.8241, G_loss: 2.7564\n",
            "Epoch [57/65] Batch [0/390] D_loss: 1.4977, G_loss: 2.4857\n",
            "Epoch [57/65] Batch [100/390] D_loss: 1.6415, G_loss: 3.4186\n",
            "Epoch [57/65] Batch [200/390] D_loss: 2.3170, G_loss: 2.8138\n",
            "Epoch [57/65] Batch [300/390] D_loss: 1.8812, G_loss: 2.6741\n",
            "Epoch [58/65] Batch [0/390] D_loss: 1.4361, G_loss: 3.2010\n",
            "Epoch [58/65] Batch [100/390] D_loss: 2.0341, G_loss: 2.7492\n",
            "Epoch [58/65] Batch [200/390] D_loss: 1.6350, G_loss: 2.8514\n",
            "Epoch [58/65] Batch [300/390] D_loss: 1.4084, G_loss: 2.8280\n",
            "Epoch [59/65] Batch [0/390] D_loss: 1.6176, G_loss: 3.1520\n",
            "Epoch [59/65] Batch [100/390] D_loss: 1.3713, G_loss: 3.1799\n",
            "Epoch [59/65] Batch [200/390] D_loss: 1.5489, G_loss: 2.8850\n",
            "Epoch [59/65] Batch [300/390] D_loss: 1.8936, G_loss: 2.3910\n",
            "Epoch [60/65] Batch [0/390] D_loss: 1.7746, G_loss: 2.1549\n",
            "Epoch [60/65] Batch [100/390] D_loss: 1.6966, G_loss: 3.1714\n",
            "Epoch [60/65] Batch [200/390] D_loss: 1.1968, G_loss: 2.9910\n",
            "Epoch [60/65] Batch [300/390] D_loss: 1.3111, G_loss: 3.2774\n",
            "Epoch [61/65] Batch [0/390] D_loss: 1.1920, G_loss: 3.2664\n",
            "Epoch [61/65] Batch [100/390] D_loss: 1.5740, G_loss: 2.5820\n",
            "Epoch [61/65] Batch [200/390] D_loss: 1.7407, G_loss: 2.0976\n",
            "Epoch [61/65] Batch [300/390] D_loss: 1.5151, G_loss: 2.9465\n",
            "Epoch [62/65] Batch [0/390] D_loss: 2.0163, G_loss: 6.1330\n",
            "Epoch [62/65] Batch [100/390] D_loss: 1.3315, G_loss: 3.5682\n",
            "Epoch [62/65] Batch [200/390] D_loss: 1.8981, G_loss: 2.2569\n",
            "Epoch [62/65] Batch [300/390] D_loss: 1.4504, G_loss: 3.4085\n",
            "Epoch [63/65] Batch [0/390] D_loss: 1.8519, G_loss: 3.4204\n",
            "Epoch [63/65] Batch [100/390] D_loss: 1.5102, G_loss: 3.6121\n",
            "Epoch [63/65] Batch [200/390] D_loss: 1.6139, G_loss: 2.4920\n",
            "Epoch [63/65] Batch [300/390] D_loss: 1.8966, G_loss: 2.2870\n",
            "Epoch [64/65] Batch [0/390] D_loss: 1.4287, G_loss: 3.0492\n",
            "Epoch [64/65] Batch [100/390] D_loss: 1.4083, G_loss: 3.2115\n",
            "Epoch [64/65] Batch [200/390] D_loss: 1.1188, G_loss: 3.1596\n",
            "Epoch [64/65] Batch [300/390] D_loss: 1.4046, G_loss: 3.2076\n",
            "Epoch [65/65] Batch [0/390] D_loss: 1.1899, G_loss: 2.9528\n",
            "Epoch [65/65] Batch [100/390] D_loss: 1.3336, G_loss: 3.3845\n",
            "Epoch [65/65] Batch [200/390] D_loss: 1.4826, G_loss: 2.3993\n",
            "Epoch [65/65] Batch [300/390] D_loss: 1.1222, G_loss: 3.3940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test"
      ],
      "metadata": {
        "id": "xUrvFteyiHDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Assuming you have already imported necessary libraries and defined CustomDataset\n",
        "\n",
        "# Create test dataset\n",
        "test_dataset6 = CustomDataset6(X_test4, y_test4)\n",
        "\n",
        "# Create DataLoader\n",
        "test_loader6 = DataLoader(test_dataset6, batch_size=batch_size6, shuffle=False)\n",
        "\n",
        "# Set the discriminator to evaluation mode\n",
        "discriminator6.eval()\n",
        "\n",
        "# Lists to store predictions and true labels\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "# Define the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_test, y_test in test_loader:\n",
        "        x_test = x_test.to(device)\n",
        "        y_test = y_test.to(device)\n",
        "\n",
        "        # Get the class outputs from the discriminator\n",
        "        class_output, _ = discriminator(x_test)\n",
        "\n",
        "        # Get the predicted class (the index with the highest score)\n",
        "        _, preds = torch.max(class_output, 1)\n",
        "\n",
        "        # Store predictions and true labels\n",
        "        all_preds.append(preds.cpu().numpy())\n",
        "        all_labels.append(y_test.cpu().numpy())\n",
        "\n",
        "# Concatenate all predictions and labels into single arrays\n",
        "all_preds = np.concatenate(all_preds)\n",
        "all_labels = np.concatenate(all_labels)\n",
        "\n",
        "# Compute overall accuracy\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(all_labels, all_preds, digits=4)\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Generate a confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Compute per-class recall\n",
        "classes = np.unique(all_labels)\n",
        "per_class_recall = {}\n",
        "\n",
        "for idx, cls in enumerate(classes):\n",
        "    # True Positives (TP): Correct predictions for class 'cls'\n",
        "    TP = cm[idx, idx]\n",
        "    # False Negatives (FN): Actual class 'cls' but predicted differently\n",
        "    FN = np.sum(cm[idx, :]) - TP\n",
        "\n",
        "    # Recall = TP / (TP + FN)\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "    per_class_recall[cls] = recall\n",
        "\n",
        "# Print per-class recall\n",
        "print(\"Per-class Recall:\")\n",
        "for cls, recall in per_class_recall.items():\n",
        "    print(f\"Class {cls}: {recall:.4f}\")\n",
        "\n",
        "per_class_accuracy = {}\n",
        "\n",
        "for idx, cls in enumerate(classes):\n",
        "    # True Positives (TP): Correct predictions for class 'cls'\n",
        "    TP = cm[idx, idx]\n",
        "    # True Negatives (TN): Correct predictions for all other classes\n",
        "    TN = np.sum(cm) - (np.sum(cm[idx, :]) + np.sum(cm[:, idx]) - TP)\n",
        "    # False Positives (FP): Incorrectly predicted as class 'cls'\n",
        "    FP = np.sum(cm[:, idx]) - TP\n",
        "    # False Negatives (FN): Actual class 'cls' but predicted differently\n",
        "    FN = np.sum(cm[idx, :]) - TP\n",
        "\n",
        "    # Per-class accuracy\n",
        "    acc = (TP + TN) / total_samples\n",
        "    per_class_accuracy[cls] = acc\n",
        "\n",
        "# Print per-class accuracy\n",
        "print(\"Per-class Accuracy:\")\n",
        "for cls, acc in per_class_accuracy.items():\n",
        "    print(f\"Class {cls}: {acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwsHd3ZDiI-9",
        "outputId": "4c1c10da-7173-45f7-843a-4d59f760f726"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5550\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7633    0.2357    0.3602      2435\n",
            "           1     0.4764    0.5637    0.5164      1884\n",
            "           2     0.3835    0.0986    0.1568      1887\n",
            "           3     0.5663    0.8128    0.6675      6294\n",
            "\n",
            "    accuracy                         0.5550     12500\n",
            "   macro avg     0.5474    0.4277    0.4252     12500\n",
            "weighted avg     0.5635    0.5550    0.5078     12500\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 574   25    7 1829]\n",
            " [  91 1062   68  663]\n",
            " [   6  269  186 1426]\n",
            " [  81  873  224 5116]]\n",
            "Per-class Recall:\n",
            "Class 0: 0.2357\n",
            "Class 1: 0.5637\n",
            "Class 2: 0.0986\n",
            "Class 3: 0.8128\n",
            "Per-class Accuracy:\n",
            "Class 0: 0.8369\n",
            "Class 1: 0.8409\n",
            "Class 2: 0.8400\n",
            "Class 3: 0.5923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data processing, window size 24 non-overlapping"
      ],
      "metadata": {
        "id": "QVne33aLr6K5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store sliding windows and labels for both train and test sets for each activity\n",
        "# This will hold the training and test data after processing each activity.\n",
        "train_test_data24 = {}\n",
        "\n",
        "# Loop through each activity folder and process the data\n",
        "# Note, if you have large amounts of data, this step may take a while\n",
        "for activity, label in activities.items():\n",
        "    # Initialize an empty dictionary for each activity to store train and test windows and labels\n",
        "    train_test_data24[activity] = {}\n",
        "\n",
        "    # Call process_activity() to process the data for the current activity folder\n",
        "    # It loads the data, applies sliding windows, splits it into train and test sets,\n",
        "    # and returns the respective sliding windows and labels for both sets.\n",
        "    (train_test_data24[activity]['train_windows'], train_test_data24[activity]['train_labels'],\n",
        "     train_test_data24[activity]['test_windows'], train_test_data24[activity]['test_labels']) = process_activity(\n",
        "        activity, label, your_dataset_path, window_size=24, step_size=24)\n",
        "\n",
        "# Explanation:\n",
        "    # - 'train_windows' and 'train_labels' store the windows and labels from the training files.\n",
        "    # - 'test_windows' and 'test_labels' store the windows and labels from the test files.\n",
        "    # - `your_dataset_path` should be replaced with the actual path to your dataset.\n",
        "    # - `process_activity` handles all the steps of loading data, splitting it, and applying sliding windows.\n",
        "    # Combine the sliding windows and labels for the training data from all activities\n",
        "# The combine_data() function concatenates the windows and labels across activities\n",
        "X_train24, y_train24 = combine_data(train_test_data24, 'train')\n",
        "\n",
        "# Combine the sliding windows and labels for the test data from all activities\n",
        "X_test24, y_test24 = combine_data(train_test_data24, 'test')\n",
        "\n",
        "# Explanation:\n",
        "# - `combine_data()` takes in the `train_test_data` dictionary and the data type ('train' or 'test') to specify\n",
        "#   whether we are combining training or testing data.\n",
        "# - It retrieves and concatenates the windows and labels from all activities into single arrays\n",
        "#   (`X_train` and `y_train` for training, `X_test` and `y_test` for testing).\n",
        "# - `X_train` and `X_test` are 3D arrays of sliding windows (shape: num_windows, window_size, num_features).\n",
        "# - `y_train` and `y_test` are 1D arrays containing the activity labels corresponding to each window.\n",
        "# Initialize the OneHotEncoder\n",
        "encoder24 = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Reshape y_train to a 2D array to meet the input format requirements of OneHotEncoder\n",
        "# - y_train is originally a 1D array of labels (shape: [num_samples]), but OneHotEncoder expects a 2D array of shape (num_samples, 1).\n",
        "# - reshape(-1, 1): The -1 means 'infer the correct size based on the other dimensions' (i.e., it adapts based on the length of y_train).\n",
        "# OneHotEncoder will then create a binary vector for each label.\n",
        "y_train_one_hot24 = encoder24.fit_transform(y_train24.reshape(-1, 1))\n",
        "\n",
        "# Apply the same transformation to the test labels (y_test)\n",
        "# - Since the encoder is already fitted on the training data, we use transform() for the test set.\n",
        "# - Reshape y_test to (num_samples, 1) for compatibility with the encoder.\n",
        "y_test_one_hot24 = encoder24.transform(y_test24.reshape(-1, 1))\n",
        "\n",
        "# Explanation:\n",
        "# - y_train_one_hot and y_test_one_hot are now 2D arrays where each row is a one-hot encoded binary vector corresponding to a class label.\n",
        "# - The number of columns in the one-hot encoded labels equals the number of unique classes (activities).\n",
        "# For example, if there are 6 unique activities, the encoded vector will have 6 elements, with a '1' indicating the correct class.\n",
        "# Print the shapes of the training and test arrays to verify that everything has been combined correctly\n",
        "print(f\"X_train24 shape: {X_train24.shape}, y_train24 shape: {y_train24.shape}\")\n",
        "print(f\"X_test24 shape: {X_test24.shape}, y_test24 shape: {y_test24.shape}\")\n",
        "# Print the shapes of the one-hot encoded labels to verify that the transformation was successful\n",
        "print(f\"y_train_one_hot24 shape: {y_train_one_hot24.shape}, y_test_one_hot24 shape: {y_test_one_hot24.shape}\")\n",
        "\n",
        "# Explanation of shapes:\n",
        "# - The shape of y_train_one_hot will be (num_samples, num_classes), where:\n",
        "#     - num_samples is the number of training windows.\n",
        "#     - num_classes is the number of unique activities (the length of the one-hot vectors).\n",
        "# - Similarly, y_test_one_hot will have the same number of columns (num_classes) as y_train_one_hot but will have fewer rows (corresponding to the number of test windows).\n",
        "\n",
        "# Determine the input shape for the model\n",
        "input_shape24 = (X_train24.shape[1], X_train24.shape[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxuP7Q9ar9Yc",
        "outputId": "49dbbf26-2c7d-4b0a-906d-51e57631c9d2"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train24 shape: (118880, 24, 3), y_train24 shape: (118880,)\n",
            "X_test24 shape: (29785, 24, 3), y_test24 shape: (29785,)\n",
            "y_train_one_hot24 shape: (118880, 4), y_test_one_hot24 shape: (29785, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train, window size 24 non-overlapping"
      ],
      "metadata": {
        "id": "ZTZ61Tf9tJbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator24(nn.Module):\n",
        "    def __init__(self, latent_dim=100, num_classes=4, output_channels=3):\n",
        "        super(Generator24, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Layers for processing noise vector z\n",
        "        self.fc_z = nn.Linear(latent_dim, 1024 * 4)  # Output: (batch_size, 4096)\n",
        "\n",
        "        # Layers for processing class labels c\n",
        "        self.fc_c = nn.Linear(num_classes, 1024 * 4)  # Output: (batch_size, 4096)\n",
        "\n",
        "        self.deconv1 = nn.Sequential(\n",
        "            nn.ConvTranspose1d(2048, 512, kernel_size=3, stride=2, padding=1),  # Output: (batch_size, 512, 7)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.deconv2 = nn.Sequential(\n",
        "            nn.ConvTranspose1d(512, 256, kernel_size=3, stride=2, padding=1),  # Output: (batch_size, 256, 13)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.deconv3 = nn.Sequential(\n",
        "            nn.ConvTranspose1d(256, 128, kernel_size=4, stride=1, padding=1),  # Output: (batch_size, 128, 14)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.deconv4 = nn.Sequential(\n",
        "            nn.ConvTranspose1d(128, 64, kernel_size=3, stride=1, padding=1),  # Output: (batch_size, 64, 14)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.deconv5 = nn.Sequential(\n",
        "            nn.ConvTranspose1d(64, output_channels, kernel_size=11, stride=1, padding=0),  # Output: (batch_size, 3, 24)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z, c):\n",
        "        # Process noise vector z\n",
        "        x_z = self.fc_z(z)  # Shape: (batch_size, 4096)\n",
        "        x_z = x_z.view(-1, 1024, 4)\n",
        "\n",
        "        # One-hot encode class labels and process\n",
        "        c = F.one_hot(c, num_classes=self.num_classes).float()\n",
        "        x_c = self.fc_c(c)  # Shape: (batch_size, 4096)\n",
        "        x_c = x_c.view(-1, 1024, 4)\n",
        "\n",
        "        # Concatenate feature maps\n",
        "        x = torch.cat([x_z, x_c], dim=1)  # Shape: (batch_size, 2048, 4)\n",
        "\n",
        "        # Pass through deconvolutional layers\n",
        "        x = self.deconv1(x)  # Output: (batch_size, 512, 7)\n",
        "        x = self.deconv2(x)  # Output: (batch_size, 256, 13)\n",
        "        x = self.deconv3(x)  # Output: (batch_size, 128, 14)\n",
        "        x = self.deconv4(x)  # Output: (batch_size, 64, 14)\n",
        "        x = self.deconv5(x)  # Output: (batch_size, 3, 24)\n",
        "        return x  # Output shape: (batch_size, 3, 24)"
      ],
      "metadata": {
        "id": "W9Pq6Q6btMuR"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator24(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Discriminator24, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv1d(3, 512, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 512, 12)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv1d(512, 1024, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 1024, 6)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "        self.shared_features = nn.Flatten()  # Flattens to (batch_size, 1024*6)\n",
        "\n",
        "        self.classifier = nn.Linear(1024 * 6, num_classes)\n",
        "        self.discriminator = nn.Sequential(\n",
        "            nn.Linear(1024 * 6, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)  # Output: (batch_size, 512, 12)\n",
        "        x = self.conv2(x)  # Output: (batch_size, 1024, 6)\n",
        "        features = self.shared_features(x)\n",
        "\n",
        "        class_output = self.classifier(features)\n",
        "        real_fake_output = self.discriminator(features)\n",
        "        return class_output, real_fake_output\n"
      ],
      "metadata": {
        "id": "_Nl1KHsFwlk3"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "if __name__ == '__main__':\n",
        "    # Define hyperparameters\n",
        "    latent_dim24 = 100\n",
        "    num_classes24 = 4  # Replace with the actual number of activity classes\n",
        "\n",
        "    #num_epochs6 = 30\n",
        "    batch_size24 = 128\n",
        "\n",
        "    # Initialize models\n",
        "    generator24 = Generator24(latent_dim=latent_dim24, num_classes=num_classes24)\n",
        "    discriminator24 = Discriminator24(num_classes=num_classes24)\n",
        "\n",
        "    # Create DataLoader\n",
        "    train_dataset24 = CustomDataset6(X_train24, y_train24)\n",
        "    sampler24 = RandomSampler(train_dataset24, replacement=True)\n",
        "    train_loader24 = DataLoader(train_dataset24, batch_size=batch_size24, sampler=sampler24)\n",
        "\n",
        "    num_mini_batches_per_epoch = len(train_loader24)\n",
        "    num_epochs24 = (25000 + num_mini_batches_per_epoch - 1) // num_mini_batches_per_epoch  # Ceiling division\n",
        "\n",
        "    # Train the AC-GAN\n",
        "    train_acgan6(generator24, discriminator24, train_loader24, num_classes24, num_epochs24, latent_dim24)\n"
      ],
      "metadata": {
        "id": "kwTEnPfnwnlh",
        "outputId": "63a21971-24b7-4033-c24d-cfea8425a820",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/27] Batch [0/929] D_loss: 4.1849, G_loss: 2.0776\n",
            "Epoch [1/27] Batch [100/929] D_loss: 2.0287, G_loss: 1.8450\n",
            "Epoch [1/27] Batch [200/929] D_loss: 2.4215, G_loss: 2.1883\n",
            "Epoch [1/27] Batch [300/929] D_loss: 2.6351, G_loss: 2.7430\n",
            "Epoch [1/27] Batch [400/929] D_loss: 2.5649, G_loss: 1.8901\n",
            "Epoch [1/27] Batch [500/929] D_loss: 2.2857, G_loss: 2.1200\n",
            "Epoch [1/27] Batch [600/929] D_loss: 2.4641, G_loss: 2.0242\n",
            "Epoch [1/27] Batch [700/929] D_loss: 3.1856, G_loss: 1.9802\n",
            "Epoch [1/27] Batch [800/929] D_loss: 2.5127, G_loss: 1.5335\n",
            "Epoch [1/27] Batch [900/929] D_loss: 2.5783, G_loss: 1.7196\n",
            "Epoch [2/27] Batch [0/929] D_loss: 2.5111, G_loss: 1.8425\n",
            "Epoch [2/27] Batch [100/929] D_loss: 2.8252, G_loss: 1.6676\n",
            "Epoch [2/27] Batch [200/929] D_loss: 2.6246, G_loss: 1.8482\n",
            "Epoch [2/27] Batch [300/929] D_loss: 2.5394, G_loss: 1.7965\n",
            "Epoch [2/27] Batch [400/929] D_loss: 2.4083, G_loss: 1.3879\n",
            "Epoch [2/27] Batch [500/929] D_loss: 2.4138, G_loss: 1.5676\n",
            "Epoch [2/27] Batch [600/929] D_loss: 2.4915, G_loss: 2.1441\n",
            "Epoch [2/27] Batch [700/929] D_loss: 2.5142, G_loss: 2.1599\n",
            "Epoch [2/27] Batch [800/929] D_loss: 2.4740, G_loss: 2.3247\n",
            "Epoch [2/27] Batch [900/929] D_loss: 2.1661, G_loss: 2.4622\n",
            "Epoch [3/27] Batch [0/929] D_loss: 2.3009, G_loss: 3.5029\n",
            "Epoch [3/27] Batch [100/929] D_loss: 2.5067, G_loss: 1.9383\n",
            "Epoch [3/27] Batch [200/929] D_loss: 2.2908, G_loss: 2.1829\n",
            "Epoch [3/27] Batch [300/929] D_loss: 2.3729, G_loss: 1.9340\n",
            "Epoch [3/27] Batch [400/929] D_loss: 2.6976, G_loss: 2.0714\n",
            "Epoch [3/27] Batch [500/929] D_loss: 2.1040, G_loss: 2.6135\n",
            "Epoch [3/27] Batch [600/929] D_loss: 2.1905, G_loss: 2.1981\n",
            "Epoch [3/27] Batch [700/929] D_loss: 2.2572, G_loss: 2.2471\n",
            "Epoch [3/27] Batch [800/929] D_loss: 2.4137, G_loss: 2.5648\n",
            "Epoch [3/27] Batch [900/929] D_loss: 2.3484, G_loss: 2.1071\n",
            "Epoch [4/27] Batch [0/929] D_loss: 2.6918, G_loss: 1.4830\n",
            "Epoch [4/27] Batch [100/929] D_loss: 2.7537, G_loss: 1.3523\n",
            "Epoch [4/27] Batch [200/929] D_loss: 2.4678, G_loss: 1.5299\n",
            "Epoch [4/27] Batch [300/929] D_loss: 2.8749, G_loss: 1.4829\n",
            "Epoch [4/27] Batch [400/929] D_loss: 2.8235, G_loss: 1.5877\n",
            "Epoch [4/27] Batch [500/929] D_loss: 2.7943, G_loss: 1.5322\n",
            "Epoch [4/27] Batch [600/929] D_loss: 2.9630, G_loss: 1.3532\n",
            "Epoch [4/27] Batch [700/929] D_loss: 2.7486, G_loss: 1.5710\n",
            "Epoch [4/27] Batch [800/929] D_loss: 2.4243, G_loss: 1.6744\n",
            "Epoch [4/27] Batch [900/929] D_loss: 2.3048, G_loss: 1.5213\n",
            "Epoch [5/27] Batch [0/929] D_loss: 2.3096, G_loss: 1.7742\n",
            "Epoch [5/27] Batch [100/929] D_loss: 2.2371, G_loss: 1.5616\n",
            "Epoch [5/27] Batch [200/929] D_loss: 2.7855, G_loss: 1.4986\n",
            "Epoch [5/27] Batch [300/929] D_loss: 2.3840, G_loss: 1.6949\n",
            "Epoch [5/27] Batch [400/929] D_loss: 2.3527, G_loss: 1.8040\n",
            "Epoch [5/27] Batch [500/929] D_loss: 2.5992, G_loss: 1.7696\n",
            "Epoch [5/27] Batch [600/929] D_loss: 3.0509, G_loss: 1.4454\n",
            "Epoch [5/27] Batch [700/929] D_loss: 2.1907, G_loss: 1.5294\n",
            "Epoch [5/27] Batch [800/929] D_loss: 2.2070, G_loss: 1.5506\n",
            "Epoch [5/27] Batch [900/929] D_loss: 2.5210, G_loss: 1.5393\n",
            "Epoch [6/27] Batch [0/929] D_loss: 2.6875, G_loss: 1.4870\n",
            "Epoch [6/27] Batch [100/929] D_loss: 2.5349, G_loss: 1.6831\n",
            "Epoch [6/27] Batch [200/929] D_loss: 2.1701, G_loss: 1.6849\n",
            "Epoch [6/27] Batch [300/929] D_loss: 2.4347, G_loss: 2.1097\n",
            "Epoch [6/27] Batch [400/929] D_loss: 2.3265, G_loss: 1.6008\n",
            "Epoch [6/27] Batch [500/929] D_loss: 2.8743, G_loss: 1.6258\n",
            "Epoch [6/27] Batch [600/929] D_loss: 2.2203, G_loss: 1.5589\n",
            "Epoch [6/27] Batch [700/929] D_loss: 2.3928, G_loss: 2.0079\n",
            "Epoch [6/27] Batch [800/929] D_loss: 2.5395, G_loss: 1.5713\n",
            "Epoch [6/27] Batch [900/929] D_loss: 2.4471, G_loss: 1.7125\n",
            "Epoch [7/27] Batch [0/929] D_loss: 2.5083, G_loss: 1.7343\n",
            "Epoch [7/27] Batch [100/929] D_loss: 2.2806, G_loss: 1.7382\n",
            "Epoch [7/27] Batch [200/929] D_loss: 2.4848, G_loss: 1.7773\n",
            "Epoch [7/27] Batch [300/929] D_loss: 2.3510, G_loss: 1.7559\n",
            "Epoch [7/27] Batch [400/929] D_loss: 2.0348, G_loss: 1.8245\n",
            "Epoch [7/27] Batch [500/929] D_loss: 2.9540, G_loss: 1.5047\n",
            "Epoch [7/27] Batch [600/929] D_loss: 2.2514, G_loss: 1.6450\n",
            "Epoch [7/27] Batch [700/929] D_loss: 2.4193, G_loss: 1.5668\n",
            "Epoch [7/27] Batch [800/929] D_loss: 2.3892, G_loss: 1.6221\n",
            "Epoch [7/27] Batch [900/929] D_loss: 2.1773, G_loss: 1.9738\n",
            "Epoch [8/27] Batch [0/929] D_loss: 2.5081, G_loss: 1.9018\n",
            "Epoch [8/27] Batch [100/929] D_loss: 2.3723, G_loss: 1.9174\n",
            "Epoch [8/27] Batch [200/929] D_loss: 2.2317, G_loss: 2.4338\n",
            "Epoch [8/27] Batch [300/929] D_loss: 1.8992, G_loss: 3.0012\n",
            "Epoch [8/27] Batch [400/929] D_loss: 1.9499, G_loss: 2.6501\n",
            "Epoch [8/27] Batch [500/929] D_loss: 1.9523, G_loss: 2.8970\n",
            "Epoch [8/27] Batch [600/929] D_loss: 2.0024, G_loss: 2.5111\n",
            "Epoch [8/27] Batch [700/929] D_loss: 1.7703, G_loss: 2.5984\n",
            "Epoch [8/27] Batch [800/929] D_loss: 1.8493, G_loss: 2.7294\n",
            "Epoch [8/27] Batch [900/929] D_loss: 1.8802, G_loss: 3.3113\n",
            "Epoch [9/27] Batch [0/929] D_loss: 2.2173, G_loss: 4.1488\n",
            "Epoch [9/27] Batch [100/929] D_loss: 2.0919, G_loss: 3.1524\n",
            "Epoch [9/27] Batch [200/929] D_loss: 1.8341, G_loss: 3.7268\n",
            "Epoch [9/27] Batch [300/929] D_loss: 1.9296, G_loss: 2.2254\n",
            "Epoch [9/27] Batch [400/929] D_loss: 2.2211, G_loss: 1.5114\n",
            "Epoch [9/27] Batch [500/929] D_loss: 2.5208, G_loss: 1.5931\n",
            "Epoch [9/27] Batch [600/929] D_loss: 1.8507, G_loss: 1.9597\n",
            "Epoch [9/27] Batch [700/929] D_loss: 2.0266, G_loss: 1.7309\n",
            "Epoch [9/27] Batch [800/929] D_loss: 2.4055, G_loss: 1.7169\n",
            "Epoch [9/27] Batch [900/929] D_loss: 1.8522, G_loss: 2.1925\n",
            "Epoch [10/27] Batch [0/929] D_loss: 2.7687, G_loss: 2.9840\n",
            "Epoch [10/27] Batch [100/929] D_loss: 2.5371, G_loss: 2.0294\n",
            "Epoch [10/27] Batch [200/929] D_loss: 1.9996, G_loss: 1.5426\n",
            "Epoch [10/27] Batch [300/929] D_loss: 2.0699, G_loss: 1.8957\n",
            "Epoch [10/27] Batch [400/929] D_loss: 2.2774, G_loss: 1.4723\n",
            "Epoch [10/27] Batch [500/929] D_loss: 2.1759, G_loss: 2.0496\n",
            "Epoch [10/27] Batch [600/929] D_loss: 2.0458, G_loss: 1.9022\n",
            "Epoch [10/27] Batch [700/929] D_loss: 2.1074, G_loss: 1.6932\n",
            "Epoch [10/27] Batch [800/929] D_loss: 1.9882, G_loss: 1.5049\n",
            "Epoch [10/27] Batch [900/929] D_loss: 2.0690, G_loss: 1.7812\n",
            "Epoch [11/27] Batch [0/929] D_loss: 1.7670, G_loss: 2.0999\n",
            "Epoch [11/27] Batch [100/929] D_loss: 2.0507, G_loss: 1.7855\n",
            "Epoch [11/27] Batch [200/929] D_loss: 2.1547, G_loss: 1.7744\n",
            "Epoch [11/27] Batch [300/929] D_loss: 2.1773, G_loss: 2.0200\n",
            "Epoch [11/27] Batch [400/929] D_loss: 2.2272, G_loss: 1.7828\n",
            "Epoch [11/27] Batch [500/929] D_loss: 2.2914, G_loss: 1.7303\n",
            "Epoch [11/27] Batch [600/929] D_loss: 2.2388, G_loss: 2.0594\n",
            "Epoch [11/27] Batch [700/929] D_loss: 2.3245, G_loss: 1.7796\n",
            "Epoch [11/27] Batch [800/929] D_loss: 2.2670, G_loss: 1.6020\n",
            "Epoch [11/27] Batch [900/929] D_loss: 2.3082, G_loss: 1.8054\n",
            "Epoch [12/27] Batch [0/929] D_loss: 2.0123, G_loss: 1.8827\n",
            "Epoch [12/27] Batch [100/929] D_loss: 2.5002, G_loss: 1.7400\n",
            "Epoch [12/27] Batch [200/929] D_loss: 1.9144, G_loss: 2.0137\n",
            "Epoch [12/27] Batch [300/929] D_loss: 2.1634, G_loss: 1.8588\n",
            "Epoch [12/27] Batch [400/929] D_loss: 2.0718, G_loss: 2.0305\n",
            "Epoch [12/27] Batch [500/929] D_loss: 2.2271, G_loss: 1.9653\n",
            "Epoch [12/27] Batch [600/929] D_loss: 2.0216, G_loss: 1.9176\n",
            "Epoch [12/27] Batch [700/929] D_loss: 2.3300, G_loss: 1.9938\n",
            "Epoch [12/27] Batch [800/929] D_loss: 2.1485, G_loss: 1.7858\n",
            "Epoch [12/27] Batch [900/929] D_loss: 1.8719, G_loss: 2.3178\n",
            "Epoch [13/27] Batch [0/929] D_loss: 2.1127, G_loss: 2.1349\n",
            "Epoch [13/27] Batch [100/929] D_loss: 2.1672, G_loss: 2.0272\n",
            "Epoch [13/27] Batch [200/929] D_loss: 1.9361, G_loss: 1.9349\n",
            "Epoch [13/27] Batch [300/929] D_loss: 1.6782, G_loss: 2.3000\n",
            "Epoch [13/27] Batch [400/929] D_loss: 2.2612, G_loss: 1.6500\n",
            "Epoch [13/27] Batch [500/929] D_loss: 2.3233, G_loss: 2.0920\n",
            "Epoch [13/27] Batch [600/929] D_loss: 2.0806, G_loss: 2.0800\n",
            "Epoch [13/27] Batch [700/929] D_loss: 2.1755, G_loss: 1.6927\n",
            "Epoch [13/27] Batch [800/929] D_loss: 2.0417, G_loss: 2.0452\n",
            "Epoch [13/27] Batch [900/929] D_loss: 2.3348, G_loss: 2.2009\n",
            "Epoch [14/27] Batch [0/929] D_loss: 1.8503, G_loss: 1.9281\n",
            "Epoch [14/27] Batch [100/929] D_loss: 2.2365, G_loss: 1.5987\n",
            "Epoch [14/27] Batch [200/929] D_loss: 2.4835, G_loss: 2.0102\n",
            "Epoch [14/27] Batch [300/929] D_loss: 2.0150, G_loss: 2.1899\n",
            "Epoch [14/27] Batch [400/929] D_loss: 2.2608, G_loss: 2.0304\n",
            "Epoch [14/27] Batch [500/929] D_loss: 2.1560, G_loss: 2.5215\n",
            "Epoch [14/27] Batch [600/929] D_loss: 1.8522, G_loss: 1.9283\n",
            "Epoch [14/27] Batch [700/929] D_loss: 2.0954, G_loss: 2.4889\n",
            "Epoch [14/27] Batch [800/929] D_loss: 2.1507, G_loss: 1.7803\n",
            "Epoch [14/27] Batch [900/929] D_loss: 1.8075, G_loss: 2.1537\n",
            "Epoch [15/27] Batch [0/929] D_loss: 1.8177, G_loss: 3.5481\n",
            "Epoch [15/27] Batch [100/929] D_loss: 1.8214, G_loss: 2.3656\n",
            "Epoch [15/27] Batch [200/929] D_loss: 1.9617, G_loss: 2.4022\n",
            "Epoch [15/27] Batch [300/929] D_loss: 1.8366, G_loss: 2.0192\n",
            "Epoch [15/27] Batch [400/929] D_loss: 2.1293, G_loss: 2.4549\n",
            "Epoch [15/27] Batch [500/929] D_loss: 1.6849, G_loss: 2.1949\n",
            "Epoch [15/27] Batch [600/929] D_loss: 2.0792, G_loss: 2.0819\n",
            "Epoch [15/27] Batch [700/929] D_loss: 1.9298, G_loss: 1.6565\n",
            "Epoch [15/27] Batch [800/929] D_loss: 2.0359, G_loss: 1.9614\n",
            "Epoch [15/27] Batch [900/929] D_loss: 2.1048, G_loss: 2.1262\n",
            "Epoch [16/27] Batch [0/929] D_loss: 1.7828, G_loss: 3.8232\n",
            "Epoch [16/27] Batch [100/929] D_loss: 1.7361, G_loss: 2.8743\n",
            "Epoch [16/27] Batch [200/929] D_loss: 1.7107, G_loss: 3.8575\n",
            "Epoch [16/27] Batch [300/929] D_loss: 1.4620, G_loss: 3.3598\n",
            "Epoch [16/27] Batch [400/929] D_loss: 1.4216, G_loss: 3.7924\n",
            "Epoch [16/27] Batch [500/929] D_loss: 1.6019, G_loss: 3.5466\n",
            "Epoch [16/27] Batch [600/929] D_loss: 2.0021, G_loss: 3.7824\n",
            "Epoch [16/27] Batch [700/929] D_loss: 2.0100, G_loss: 5.0677\n",
            "Epoch [16/27] Batch [800/929] D_loss: 1.8829, G_loss: 5.7433\n",
            "Epoch [16/27] Batch [900/929] D_loss: 1.7044, G_loss: 3.9509\n",
            "Epoch [17/27] Batch [0/929] D_loss: 1.7664, G_loss: 3.2430\n",
            "Epoch [17/27] Batch [100/929] D_loss: 2.0778, G_loss: 4.0573\n",
            "Epoch [17/27] Batch [200/929] D_loss: 2.8681, G_loss: 5.7484\n",
            "Epoch [17/27] Batch [300/929] D_loss: 1.6946, G_loss: 3.0026\n",
            "Epoch [17/27] Batch [400/929] D_loss: 2.0802, G_loss: 2.1456\n",
            "Epoch [17/27] Batch [500/929] D_loss: 1.6999, G_loss: 2.5740\n",
            "Epoch [17/27] Batch [600/929] D_loss: 1.8376, G_loss: 2.2698\n",
            "Epoch [17/27] Batch [700/929] D_loss: 1.9557, G_loss: 2.7234\n",
            "Epoch [17/27] Batch [800/929] D_loss: 2.2440, G_loss: 2.0105\n",
            "Epoch [17/27] Batch [900/929] D_loss: 1.8809, G_loss: 2.0686\n",
            "Epoch [18/27] Batch [0/929] D_loss: 1.9603, G_loss: 2.4758\n",
            "Epoch [18/27] Batch [100/929] D_loss: 2.1077, G_loss: 2.2152\n",
            "Epoch [18/27] Batch [200/929] D_loss: 1.5645, G_loss: 2.5863\n",
            "Epoch [18/27] Batch [300/929] D_loss: 1.8824, G_loss: 3.2724\n",
            "Epoch [18/27] Batch [400/929] D_loss: 2.0531, G_loss: 3.0303\n",
            "Epoch [18/27] Batch [500/929] D_loss: 1.9915, G_loss: 4.1297\n",
            "Epoch [18/27] Batch [600/929] D_loss: 1.6972, G_loss: 3.5498\n",
            "Epoch [18/27] Batch [700/929] D_loss: 1.6309, G_loss: 4.2349\n",
            "Epoch [18/27] Batch [800/929] D_loss: 1.4646, G_loss: 3.7009\n",
            "Epoch [18/27] Batch [900/929] D_loss: 1.7859, G_loss: 4.2740\n",
            "Epoch [19/27] Batch [0/929] D_loss: 1.4429, G_loss: 4.1157\n",
            "Epoch [19/27] Batch [100/929] D_loss: 1.7757, G_loss: 3.4733\n",
            "Epoch [19/27] Batch [200/929] D_loss: 1.4895, G_loss: 3.3442\n",
            "Epoch [19/27] Batch [300/929] D_loss: 1.6753, G_loss: 4.9189\n",
            "Epoch [19/27] Batch [400/929] D_loss: 1.7137, G_loss: 4.1795\n",
            "Epoch [19/27] Batch [500/929] D_loss: 1.5927, G_loss: 3.6083\n",
            "Epoch [19/27] Batch [600/929] D_loss: 1.8492, G_loss: 3.8658\n",
            "Epoch [19/27] Batch [700/929] D_loss: 1.6598, G_loss: 3.0636\n",
            "Epoch [19/27] Batch [800/929] D_loss: 1.5973, G_loss: 4.5049\n",
            "Epoch [19/27] Batch [900/929] D_loss: 1.8067, G_loss: 5.2329\n",
            "Epoch [20/27] Batch [0/929] D_loss: 1.6267, G_loss: 4.5302\n",
            "Epoch [20/27] Batch [100/929] D_loss: 1.4574, G_loss: 3.5395\n",
            "Epoch [20/27] Batch [200/929] D_loss: 1.6385, G_loss: 5.0467\n",
            "Epoch [20/27] Batch [300/929] D_loss: 1.9186, G_loss: 5.1727\n",
            "Epoch [20/27] Batch [400/929] D_loss: 1.8888, G_loss: 3.6567\n",
            "Epoch [20/27] Batch [500/929] D_loss: 1.8645, G_loss: 3.3460\n",
            "Epoch [20/27] Batch [600/929] D_loss: 1.7109, G_loss: 4.4185\n",
            "Epoch [20/27] Batch [700/929] D_loss: 1.4582, G_loss: 3.7808\n",
            "Epoch [20/27] Batch [800/929] D_loss: 1.6706, G_loss: 5.1447\n",
            "Epoch [20/27] Batch [900/929] D_loss: 1.8203, G_loss: 4.2800\n",
            "Epoch [21/27] Batch [0/929] D_loss: 1.9287, G_loss: 3.9928\n",
            "Epoch [21/27] Batch [100/929] D_loss: 1.8099, G_loss: 6.1457\n",
            "Epoch [21/27] Batch [200/929] D_loss: 1.4918, G_loss: 3.5852\n",
            "Epoch [21/27] Batch [300/929] D_loss: 1.3396, G_loss: 4.2044\n",
            "Epoch [21/27] Batch [400/929] D_loss: 1.8992, G_loss: 3.8761\n",
            "Epoch [21/27] Batch [500/929] D_loss: 1.7688, G_loss: 5.6957\n",
            "Epoch [21/27] Batch [600/929] D_loss: 1.4527, G_loss: 5.7551\n",
            "Epoch [21/27] Batch [700/929] D_loss: 1.6268, G_loss: 4.7126\n",
            "Epoch [21/27] Batch [800/929] D_loss: 1.7337, G_loss: 4.7819\n",
            "Epoch [21/27] Batch [900/929] D_loss: 1.5568, G_loss: 3.7283\n",
            "Epoch [22/27] Batch [0/929] D_loss: 1.4662, G_loss: 3.4555\n",
            "Epoch [22/27] Batch [100/929] D_loss: 1.6289, G_loss: 5.2819\n",
            "Epoch [22/27] Batch [200/929] D_loss: 1.5398, G_loss: 4.3410\n",
            "Epoch [22/27] Batch [300/929] D_loss: 1.3438, G_loss: 3.8336\n",
            "Epoch [22/27] Batch [400/929] D_loss: 1.6019, G_loss: 3.9400\n",
            "Epoch [22/27] Batch [500/929] D_loss: 1.5705, G_loss: 4.0488\n",
            "Epoch [22/27] Batch [600/929] D_loss: 1.7084, G_loss: 5.1690\n",
            "Epoch [22/27] Batch [700/929] D_loss: 1.6514, G_loss: 4.6375\n",
            "Epoch [22/27] Batch [800/929] D_loss: 1.3694, G_loss: 5.2375\n",
            "Epoch [22/27] Batch [900/929] D_loss: 1.5960, G_loss: 4.6357\n",
            "Epoch [23/27] Batch [0/929] D_loss: 1.6166, G_loss: 5.2953\n",
            "Epoch [23/27] Batch [100/929] D_loss: 1.5924, G_loss: 3.3979\n",
            "Epoch [23/27] Batch [200/929] D_loss: 2.0260, G_loss: 5.4675\n",
            "Epoch [23/27] Batch [300/929] D_loss: 1.6378, G_loss: 6.0998\n",
            "Epoch [23/27] Batch [400/929] D_loss: 1.6244, G_loss: 5.2143\n",
            "Epoch [23/27] Batch [500/929] D_loss: 1.7847, G_loss: 2.3204\n",
            "Epoch [23/27] Batch [600/929] D_loss: 1.8199, G_loss: 1.7944\n",
            "Epoch [23/27] Batch [700/929] D_loss: 1.6701, G_loss: 2.1568\n",
            "Epoch [23/27] Batch [800/929] D_loss: 1.4907, G_loss: 2.2549\n",
            "Epoch [23/27] Batch [900/929] D_loss: 1.9350, G_loss: 2.0054\n",
            "Epoch [24/27] Batch [0/929] D_loss: 1.6465, G_loss: 2.4824\n",
            "Epoch [24/27] Batch [100/929] D_loss: 1.8197, G_loss: 2.0375\n",
            "Epoch [24/27] Batch [200/929] D_loss: 1.9620, G_loss: 2.8259\n",
            "Epoch [24/27] Batch [300/929] D_loss: 1.8229, G_loss: 2.1778\n",
            "Epoch [24/27] Batch [400/929] D_loss: 1.9807, G_loss: 2.2491\n",
            "Epoch [24/27] Batch [500/929] D_loss: 1.7874, G_loss: 2.5591\n",
            "Epoch [24/27] Batch [600/929] D_loss: 1.8095, G_loss: 2.1138\n",
            "Epoch [24/27] Batch [700/929] D_loss: 1.7476, G_loss: 2.3535\n",
            "Epoch [24/27] Batch [800/929] D_loss: 1.8591, G_loss: 2.0607\n",
            "Epoch [24/27] Batch [900/929] D_loss: 2.0310, G_loss: 1.6059\n",
            "Epoch [25/27] Batch [0/929] D_loss: 1.7032, G_loss: 2.2844\n",
            "Epoch [25/27] Batch [100/929] D_loss: 1.9352, G_loss: 2.3497\n",
            "Epoch [25/27] Batch [200/929] D_loss: 1.8082, G_loss: 2.0769\n",
            "Epoch [25/27] Batch [300/929] D_loss: 1.6290, G_loss: 2.0861\n",
            "Epoch [25/27] Batch [400/929] D_loss: 1.9454, G_loss: 2.5609\n",
            "Epoch [25/27] Batch [500/929] D_loss: 1.7593, G_loss: 2.4782\n",
            "Epoch [25/27] Batch [600/929] D_loss: 2.0602, G_loss: 2.3341\n",
            "Epoch [25/27] Batch [700/929] D_loss: 1.7904, G_loss: 2.3670\n",
            "Epoch [25/27] Batch [800/929] D_loss: 1.6005, G_loss: 2.4133\n",
            "Epoch [25/27] Batch [900/929] D_loss: 1.7457, G_loss: 2.8822\n",
            "Epoch [26/27] Batch [0/929] D_loss: 2.1516, G_loss: 2.4276\n",
            "Epoch [26/27] Batch [100/929] D_loss: 1.8314, G_loss: 2.4233\n",
            "Epoch [26/27] Batch [200/929] D_loss: 1.8045, G_loss: 2.9675\n",
            "Epoch [26/27] Batch [300/929] D_loss: 2.7566, G_loss: 3.7492\n",
            "Epoch [26/27] Batch [400/929] D_loss: 1.9837, G_loss: 2.2274\n",
            "Epoch [26/27] Batch [500/929] D_loss: 1.7343, G_loss: 2.7097\n",
            "Epoch [26/27] Batch [600/929] D_loss: 1.7840, G_loss: 2.3858\n",
            "Epoch [26/27] Batch [700/929] D_loss: 1.8120, G_loss: 2.4394\n",
            "Epoch [26/27] Batch [800/929] D_loss: 1.9803, G_loss: 2.8167\n",
            "Epoch [26/27] Batch [900/929] D_loss: 1.9261, G_loss: 2.1530\n",
            "Epoch [27/27] Batch [0/929] D_loss: 1.8371, G_loss: 2.2876\n",
            "Epoch [27/27] Batch [100/929] D_loss: 2.1403, G_loss: 3.4826\n",
            "Epoch [27/27] Batch [200/929] D_loss: 2.1714, G_loss: 2.1391\n",
            "Epoch [27/27] Batch [300/929] D_loss: 1.8546, G_loss: 2.3196\n",
            "Epoch [27/27] Batch [400/929] D_loss: 1.5978, G_loss: 2.2895\n",
            "Epoch [27/27] Batch [500/929] D_loss: 2.2189, G_loss: 2.3268\n",
            "Epoch [27/27] Batch [600/929] D_loss: 1.7469, G_loss: 2.3637\n",
            "Epoch [27/27] Batch [700/929] D_loss: 1.7767, G_loss: 2.2353\n",
            "Epoch [27/27] Batch [800/929] D_loss: 1.8451, G_loss: 2.0221\n",
            "Epoch [27/27] Batch [900/929] D_loss: 1.6681, G_loss: 2.4083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test"
      ],
      "metadata": {
        "id": "6DNuooLzv1DU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Assuming you have already imported necessary libraries and defined CustomDataset\n",
        "\n",
        "# Create test dataset\n",
        "test_dataset24 = CustomDataset6(X_test24, y_test24)\n",
        "\n",
        "# Create DataLoader\n",
        "test_loader24 = DataLoader(test_dataset24, batch_size=batch_size24, shuffle=False)\n",
        "\n",
        "# Set the discriminator to evaluation mode\n",
        "discriminator24.eval()\n",
        "\n",
        "def test_gan(test_loader, discriminator):\n",
        "\n",
        "  # Lists to store predictions and true labels\n",
        "  all_preds = []\n",
        "  all_labels = []\n",
        "  # Define the device\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for x_test, y_test in test_loader:\n",
        "          x_test = x_test.to(device)\n",
        "          y_test = y_test.to(device)\n",
        "\n",
        "          # Get the class outputs from the discriminator\n",
        "          class_output, _ = discriminator(x_test)\n",
        "\n",
        "          # Get the predicted class (the index with the highest score)\n",
        "          _, preds = torch.max(class_output, 1)\n",
        "\n",
        "          # Store predictions and true labels\n",
        "          all_preds.append(preds.cpu().numpy())\n",
        "          all_labels.append(y_test.cpu().numpy())\n",
        "\n",
        "  # Concatenate all predictions and labels into single arrays\n",
        "  all_preds = np.concatenate(all_preds)\n",
        "  all_labels = np.concatenate(all_labels)\n",
        "\n",
        "  # Compute overall accuracy\n",
        "  accuracy = accuracy_score(all_labels, all_preds)\n",
        "  print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "  # Generate a classification report\n",
        "  report = classification_report(all_labels, all_preds, digits=4)\n",
        "  print(\"Classification Report:\")\n",
        "  print(report)\n",
        "\n",
        "  # Generate a confusion matrix\n",
        "  cm = confusion_matrix(all_labels, all_preds)\n",
        "  print(\"Confusion Matrix:\")\n",
        "  print(cm)\n",
        "\n",
        "  # Compute per-class recall\n",
        "  classes = np.unique(all_labels)\n",
        "  per_class_recall = {}\n",
        "\n",
        "  for idx, cls in enumerate(classes):\n",
        "      # True Positives (TP): Correct predictions for class 'cls'\n",
        "      TP = cm[idx, idx]\n",
        "      # False Negatives (FN): Actual class 'cls' but predicted differently\n",
        "      FN = np.sum(cm[idx, :]) - TP\n",
        "\n",
        "      # Recall = TP / (TP + FN)\n",
        "      recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
        "      per_class_recall[cls] = recall\n",
        "\n",
        "  # Print per-class recall\n",
        "  print(\"Per-class Recall:\")\n",
        "  for cls, recall in per_class_recall.items():\n",
        "      print(f\"Class {cls}: {recall:.4f}\")\n",
        "\n",
        "  per_class_accuracy = {}\n",
        "\n",
        "  for idx, cls in enumerate(classes):\n",
        "      # True Positives (TP): Correct predictions for class 'cls'\n",
        "      TP = cm[idx, idx]\n",
        "      # True Negatives (TN): Correct predictions for all other classes\n",
        "      TN = np.sum(cm) - (np.sum(cm[idx, :]) + np.sum(cm[:, idx]) - TP)\n",
        "      # False Positives (FP): Incorrectly predicted as class 'cls'\n",
        "      FP = np.sum(cm[:, idx]) - TP\n",
        "      # False Negatives (FN): Actual class 'cls' but predicted differently\n",
        "      FN = np.sum(cm[idx, :]) - TP\n",
        "\n",
        "      # Per-class accuracy\n",
        "      acc = (TP + TN) / total_samples\n",
        "      per_class_accuracy[cls] = acc\n",
        "\n",
        "  # Print per-class accuracy\n",
        "  print(\"Per-class Accuracy:\")\n",
        "  for cls, acc in per_class_accuracy.items():\n",
        "      print(f\"Class {cls}: {acc:.4f}\")\n",
        "\n",
        "test_gan(test_loader24, discriminator24)"
      ],
      "metadata": {
        "id": "_A8eWZaev3jg",
        "outputId": "b7abf822-9557-4eb6-e989-456771eec752",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4940\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.4479    0.2815    0.3457      5805\n",
            "           1     0.4525    0.5310    0.4886      4488\n",
            "           2     0.2886    0.2186    0.2488      4510\n",
            "           3     0.5563    0.6481    0.5987     14982\n",
            "\n",
            "    accuracy                         0.4940     29785\n",
            "   macro avg     0.4363    0.4198    0.4205     29785\n",
            "weighted avg     0.4790    0.4940    0.4798     29785\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1634  172  254 3745]\n",
            " [ 282 2383  390 1433]\n",
            " [ 278  679  986 2567]\n",
            " [1454 2032 1786 9710]]\n",
            "Per-class Recall:\n",
            "Class 0: 0.2815\n",
            "Class 1: 0.5310\n",
            "Class 2: 0.2186\n",
            "Class 3: 0.6481\n",
            "Per-class Accuracy:\n",
            "Class 0: 1.8880\n",
            "Class 1: 1.9838\n",
            "Class 2: 1.9065\n",
            "Class 3: 1.3414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data processing, window size 24 overlapping"
      ],
      "metadata": {
        "id": "d9Xsbi5ltrXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store sliding windows and labels for both train and test sets for each activity\n",
        "# This will hold the training and test data after processing each activity.\n",
        "train_test_data24o = {}\n",
        "\n",
        "# Loop through each activity folder and process the data\n",
        "# Note, if you have large amounts of data, this step may take a while\n",
        "for activity, label in activities.items():\n",
        "    # Initialize an empty dictionary for each activity to store train and test windows and labels\n",
        "    train_test_data24o[activity] = {}\n",
        "\n",
        "    # Call process_activity() to process the data for the current activity folder\n",
        "    # It loads the data, applies sliding windows, splits it into train and test sets,\n",
        "    # and returns the respective sliding windows and labels for both sets.\n",
        "    (train_test_data24o[activity]['train_windows'], train_test_data24o[activity]['train_labels'],\n",
        "     train_test_data24o[activity]['test_windows'], train_test_data24o[activity]['test_labels']) = process_activity(\n",
        "        activity, label, your_dataset_path, window_size=24, step_size=12)\n",
        "\n",
        "# Explanation:\n",
        "    # - 'train_windows' and 'train_labels' store the windows and labels from the training files.\n",
        "    # - 'test_windows' and 'test_labels' store the windows and labels from the test files.\n",
        "    # - `your_dataset_path` should be replaced with the actual path to your dataset.\n",
        "    # - `process_activity` handles all the steps of loading data, splitting it, and applying sliding windows.\n",
        "    # Combine the sliding windows and labels for the training data from all activities\n",
        "# The combine_data() function concatenates the windows and labels across activities\n",
        "X_train24o, y_train24o = combine_data(train_test_data24o, 'train')\n",
        "\n",
        "# Combine the sliding windows and labels for the test data from all activities\n",
        "X_test24o, y_test24o = combine_data(train_test_data24o, 'test')\n",
        "\n",
        "# Explanation:\n",
        "# - `combine_data()` takes in the `train_test_data` dictionary and the data type ('train' or 'test') to specify\n",
        "#   whether we are combining training or testing data.\n",
        "# - It retrieves and concatenates the windows and labels from all activities into single arrays\n",
        "#   (`X_train` and `y_train` for training, `X_test` and `y_test` for testing).\n",
        "# - `X_train` and `X_test` are 3D arrays of sliding windows (shape: num_windows, window_size, num_features).\n",
        "# - `y_train` and `y_test` are 1D arrays containing the activity labels corresponding to each window.\n",
        "# Initialize the OneHotEncoder\n",
        "encoder24o = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Reshape y_train to a 2D array to meet the input format requirements of OneHotEncoder\n",
        "# - y_train is originally a 1D array of labels (shape: [num_samples]), but OneHotEncoder expects a 2D array of shape (num_samples, 1).\n",
        "# - reshape(-1, 1): The -1 means 'infer the correct size based on the other dimensions' (i.e., it adapts based on the length of y_train).\n",
        "# OneHotEncoder will then create a binary vector for each label.\n",
        "y_train_one_hot24o = encoder24o.fit_transform(y_train24o.reshape(-1, 1))\n",
        "\n",
        "# Apply the same transformation to the test labels (y_test)\n",
        "# - Since the encoder is already fitted on the training data, we use transform() for the test set.\n",
        "# - Reshape y_test to (num_samples, 1) for compatibility with the encoder.\n",
        "y_test_one_hot24o = encoder24o.transform(y_test24o.reshape(-1, 1))\n",
        "\n",
        "# Explanation:\n",
        "# - y_train_one_hot and y_test_one_hot are now 2D arrays where each row is a one-hot encoded binary vector corresponding to a class label.\n",
        "# - The number of columns in the one-hot encoded labels equals the number of unique classes (activities).\n",
        "# For example, if there are 6 unique activities, the encoded vector will have 6 elements, with a '1' indicating the correct class.\n",
        "# Print the shapes of the training and test arrays to verify that everything has been combined correctly\n",
        "print(f\"X_train24 shape: {X_train24o.shape}, y_train24 shape: {y_train24o.shape}\")\n",
        "print(f\"X_test24 shape: {X_test24o.shape}, y_test24 shape: {y_test24o.shape}\")\n",
        "# Print the shapes of the one-hot encoded labels to verify that the transformation was successful\n",
        "print(f\"y_train_one_hot24 shape: {y_train_one_hot24o.shape}, y_test_one_hot24 shape: {y_test_one_hot24o.shape}\")\n",
        "\n",
        "# Explanation of shapes:\n",
        "# - The shape of y_train_one_hot will be (num_samples, num_classes), where:\n",
        "#     - num_samples is the number of training windows.\n",
        "#     - num_classes is the number of unique activities (the length of the one-hot vectors).\n",
        "# - Similarly, y_test_one_hot will have the same number of columns (num_classes) as y_train_one_hot but will have fewer rows (corresponding to the number of test windows).\n",
        "\n",
        "# Determine the input shape for the model\n",
        "input_shape24o = (X_train24o.shape[1], X_train24o.shape[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIa2BDyxttpf",
        "outputId": "15c73561-6f46-4469-eba3-e9f3a02afd87"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train24 shape: (236924, 24, 3), y_train24 shape: (236924,)\n",
            "X_test24 shape: (59379, 24, 3), y_test24 shape: (59379,)\n",
            "y_train_one_hot24 shape: (236924, 4), y_test_one_hot24 shape: (59379, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train, window size 24 overlapping"
      ],
      "metadata": {
        "id": "7XjuXOfVuCtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "if __name__ == '__main__':\n",
        "    # Define hyperparameters\n",
        "    latent_dim24o = 100\n",
        "    num_classes24o = 4  # Replace with the actual number of activity classes\n",
        "\n",
        "    #num_epochs6 = 30\n",
        "    batch_size24o = 128\n",
        "\n",
        "    # Initialize models\n",
        "    generator24o = Generator24(latent_dim=latent_dim24o, num_classes=num_classes24o)\n",
        "    discriminator24o = Discriminator24(num_classes=num_classes24o)\n",
        "\n",
        "    # Create DataLoader\n",
        "    train_dataset24o = CustomDataset6(X_train24o, y_train24o)\n",
        "    sampler24o = RandomSampler(train_dataset24o, replacement=True)\n",
        "    train_loader24o = DataLoader(train_dataset24o, batch_size=batch_size24o, sampler=sampler24o)\n",
        "\n",
        "    num_mini_batches_per_epoch = len(train_loader24o)\n",
        "    num_epochs24o = (25000 + num_mini_batches_per_epoch - 1) // num_mini_batches_per_epoch  # Ceiling division\n",
        "\n",
        "    # Train the AC-GAN\n",
        "    train_acgan6(generator24o, discriminator24o, train_loader24o, num_classes24o, num_epochs24o, latent_dim24o)\n"
      ],
      "metadata": {
        "id": "w92-trX2vud7",
        "outputId": "55fa8ba2-2816-4146-8b83-aa61c80e0c8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/14] Batch [0/1851] D_loss: 4.1794, G_loss: 2.1222\n",
            "Epoch [1/14] Batch [100/1851] D_loss: 1.9169, G_loss: 2.0047\n",
            "Epoch [1/14] Batch [200/1851] D_loss: 2.1982, G_loss: 2.6662\n",
            "Epoch [1/14] Batch [300/1851] D_loss: 2.2979, G_loss: 2.1057\n",
            "Epoch [1/14] Batch [400/1851] D_loss: 2.6313, G_loss: 2.3029\n",
            "Epoch [1/14] Batch [500/1851] D_loss: 2.4399, G_loss: 1.9309\n",
            "Epoch [1/14] Batch [600/1851] D_loss: 2.2821, G_loss: 1.8141\n",
            "Epoch [1/14] Batch [700/1851] D_loss: 2.5884, G_loss: 1.5447\n",
            "Epoch [1/14] Batch [800/1851] D_loss: 2.4811, G_loss: 1.8847\n",
            "Epoch [1/14] Batch [900/1851] D_loss: 2.6047, G_loss: 1.6182\n",
            "Epoch [1/14] Batch [1000/1851] D_loss: 2.8094, G_loss: 1.5535\n",
            "Epoch [1/14] Batch [1100/1851] D_loss: 2.4821, G_loss: 1.6065\n",
            "Epoch [1/14] Batch [1200/1851] D_loss: 2.6715, G_loss: 1.6061\n",
            "Epoch [1/14] Batch [1300/1851] D_loss: 2.3117, G_loss: 1.5888\n",
            "Epoch [1/14] Batch [1400/1851] D_loss: 2.6207, G_loss: 1.3975\n",
            "Epoch [1/14] Batch [1500/1851] D_loss: 2.6623, G_loss: 1.4997\n",
            "Epoch [1/14] Batch [1600/1851] D_loss: 3.1973, G_loss: 1.4267\n",
            "Epoch [1/14] Batch [1700/1851] D_loss: 2.6827, G_loss: 1.7707\n",
            "Epoch [1/14] Batch [1800/1851] D_loss: 2.6692, G_loss: 1.7471\n",
            "Epoch [2/14] Batch [0/1851] D_loss: 2.6712, G_loss: 1.2278\n",
            "Epoch [2/14] Batch [100/1851] D_loss: 2.9765, G_loss: 1.2952\n",
            "Epoch [2/14] Batch [200/1851] D_loss: 2.6778, G_loss: 1.5330\n",
            "Epoch [2/14] Batch [300/1851] D_loss: 2.9047, G_loss: 1.3356\n",
            "Epoch [2/14] Batch [400/1851] D_loss: 2.6757, G_loss: 1.2823\n",
            "Epoch [2/14] Batch [500/1851] D_loss: 2.6411, G_loss: 1.3170\n",
            "Epoch [2/14] Batch [600/1851] D_loss: 2.6128, G_loss: 1.5142\n",
            "Epoch [2/14] Batch [700/1851] D_loss: 2.5798, G_loss: 1.2161\n",
            "Epoch [2/14] Batch [800/1851] D_loss: 2.4180, G_loss: 1.3048\n",
            "Epoch [2/14] Batch [900/1851] D_loss: 2.3041, G_loss: 1.7972\n",
            "Epoch [2/14] Batch [1000/1851] D_loss: 2.5073, G_loss: 1.3888\n",
            "Epoch [2/14] Batch [1100/1851] D_loss: 2.4442, G_loss: 1.8506\n",
            "Epoch [2/14] Batch [1200/1851] D_loss: 2.4477, G_loss: 1.5714\n",
            "Epoch [2/14] Batch [1300/1851] D_loss: 2.6020, G_loss: 1.5930\n",
            "Epoch [2/14] Batch [1400/1851] D_loss: 2.4254, G_loss: 1.4215\n",
            "Epoch [2/14] Batch [1500/1851] D_loss: 2.5623, G_loss: 1.4409\n",
            "Epoch [2/14] Batch [1600/1851] D_loss: 2.1333, G_loss: 1.7242\n",
            "Epoch [2/14] Batch [1700/1851] D_loss: 2.5902, G_loss: 1.8171\n",
            "Epoch [2/14] Batch [1800/1851] D_loss: 2.5275, G_loss: 1.8320\n",
            "Epoch [3/14] Batch [0/1851] D_loss: 2.8970, G_loss: 1.3697\n",
            "Epoch [3/14] Batch [100/1851] D_loss: 2.2724, G_loss: 1.8611\n",
            "Epoch [3/14] Batch [200/1851] D_loss: 2.8323, G_loss: 1.5509\n",
            "Epoch [3/14] Batch [300/1851] D_loss: 2.5412, G_loss: 1.3796\n",
            "Epoch [3/14] Batch [400/1851] D_loss: 2.1257, G_loss: 1.7537\n",
            "Epoch [3/14] Batch [500/1851] D_loss: 2.3517, G_loss: 1.3411\n",
            "Epoch [3/14] Batch [600/1851] D_loss: 2.4087, G_loss: 1.7294\n",
            "Epoch [3/14] Batch [700/1851] D_loss: 2.4009, G_loss: 1.7472\n",
            "Epoch [3/14] Batch [800/1851] D_loss: 2.2846, G_loss: 1.7249\n",
            "Epoch [3/14] Batch [900/1851] D_loss: 2.1580, G_loss: 1.9814\n",
            "Epoch [3/14] Batch [1000/1851] D_loss: 2.3148, G_loss: 2.0155\n",
            "Epoch [3/14] Batch [1100/1851] D_loss: 2.2255, G_loss: 1.4677\n",
            "Epoch [3/14] Batch [1200/1851] D_loss: 2.1112, G_loss: 1.8810\n",
            "Epoch [3/14] Batch [1300/1851] D_loss: 1.9480, G_loss: 1.8770\n",
            "Epoch [3/14] Batch [1400/1851] D_loss: 2.5769, G_loss: 1.7637\n",
            "Epoch [3/14] Batch [1500/1851] D_loss: 2.6313, G_loss: 1.4296\n",
            "Epoch [3/14] Batch [1600/1851] D_loss: 2.0283, G_loss: 1.6711\n",
            "Epoch [3/14] Batch [1700/1851] D_loss: 2.4745, G_loss: 1.7025\n",
            "Epoch [3/14] Batch [1800/1851] D_loss: 2.2317, G_loss: 2.0366\n",
            "Epoch [4/14] Batch [0/1851] D_loss: 2.5787, G_loss: 2.0555\n",
            "Epoch [4/14] Batch [100/1851] D_loss: 2.3153, G_loss: 1.4281\n",
            "Epoch [4/14] Batch [200/1851] D_loss: 2.2060, G_loss: 2.0584\n",
            "Epoch [4/14] Batch [300/1851] D_loss: 2.0534, G_loss: 1.8293\n",
            "Epoch [4/14] Batch [400/1851] D_loss: 2.2172, G_loss: 1.7449\n",
            "Epoch [4/14] Batch [500/1851] D_loss: 2.4837, G_loss: 1.7332\n",
            "Epoch [4/14] Batch [600/1851] D_loss: 2.1984, G_loss: 2.2982\n",
            "Epoch [4/14] Batch [700/1851] D_loss: 2.3771, G_loss: 1.8135\n",
            "Epoch [4/14] Batch [800/1851] D_loss: 2.0804, G_loss: 2.4787\n",
            "Epoch [4/14] Batch [900/1851] D_loss: 1.8712, G_loss: 3.3622\n",
            "Epoch [4/14] Batch [1000/1851] D_loss: 2.5807, G_loss: 1.8305\n",
            "Epoch [4/14] Batch [1100/1851] D_loss: 2.2719, G_loss: 1.6233\n",
            "Epoch [4/14] Batch [1200/1851] D_loss: 1.9361, G_loss: 1.9794\n",
            "Epoch [4/14] Batch [1300/1851] D_loss: 2.3758, G_loss: 1.8912\n",
            "Epoch [4/14] Batch [1400/1851] D_loss: 2.4786, G_loss: 1.5202\n",
            "Epoch [4/14] Batch [1500/1851] D_loss: 2.5590, G_loss: 1.7161\n",
            "Epoch [4/14] Batch [1600/1851] D_loss: 2.0785, G_loss: 1.8068\n",
            "Epoch [4/14] Batch [1700/1851] D_loss: 1.9254, G_loss: 1.8035\n",
            "Epoch [4/14] Batch [1800/1851] D_loss: 2.3062, G_loss: 1.7360\n",
            "Epoch [5/14] Batch [0/1851] D_loss: 1.9273, G_loss: 1.6554\n",
            "Epoch [5/14] Batch [100/1851] D_loss: 2.7126, G_loss: 1.6656\n",
            "Epoch [5/14] Batch [200/1851] D_loss: 2.3837, G_loss: 1.5902\n",
            "Epoch [5/14] Batch [300/1851] D_loss: 2.1461, G_loss: 1.6825\n",
            "Epoch [5/14] Batch [400/1851] D_loss: 2.3082, G_loss: 2.0520\n",
            "Epoch [5/14] Batch [500/1851] D_loss: 2.4866, G_loss: 2.6120\n",
            "Epoch [5/14] Batch [600/1851] D_loss: 2.1116, G_loss: 1.9828\n",
            "Epoch [5/14] Batch [700/1851] D_loss: 2.2587, G_loss: 1.8514\n",
            "Epoch [5/14] Batch [800/1851] D_loss: 2.1518, G_loss: 2.0032\n",
            "Epoch [5/14] Batch [900/1851] D_loss: 2.6037, G_loss: 1.8238\n",
            "Epoch [5/14] Batch [1000/1851] D_loss: 2.1794, G_loss: 2.1427\n",
            "Epoch [5/14] Batch [1100/1851] D_loss: 2.2531, G_loss: 2.3269\n",
            "Epoch [5/14] Batch [1200/1851] D_loss: 1.9886, G_loss: 1.9922\n",
            "Epoch [5/14] Batch [1300/1851] D_loss: 1.9599, G_loss: 2.2293\n",
            "Epoch [5/14] Batch [1400/1851] D_loss: 1.8349, G_loss: 1.9853\n",
            "Epoch [5/14] Batch [1500/1851] D_loss: 1.9580, G_loss: 2.0323\n",
            "Epoch [5/14] Batch [1600/1851] D_loss: 1.8459, G_loss: 1.7827\n",
            "Epoch [5/14] Batch [1700/1851] D_loss: 1.8457, G_loss: 1.8579\n",
            "Epoch [5/14] Batch [1800/1851] D_loss: 2.0873, G_loss: 2.6321\n",
            "Epoch [6/14] Batch [0/1851] D_loss: 1.9252, G_loss: 3.1794\n",
            "Epoch [6/14] Batch [100/1851] D_loss: 2.1332, G_loss: 1.7811\n",
            "Epoch [6/14] Batch [200/1851] D_loss: 2.3730, G_loss: 1.7434\n",
            "Epoch [6/14] Batch [300/1851] D_loss: 2.1212, G_loss: 1.9790\n",
            "Epoch [6/14] Batch [400/1851] D_loss: 1.9624, G_loss: 1.9171\n",
            "Epoch [6/14] Batch [500/1851] D_loss: 1.9428, G_loss: 1.8086\n",
            "Epoch [6/14] Batch [600/1851] D_loss: 2.1951, G_loss: 1.7727\n",
            "Epoch [6/14] Batch [700/1851] D_loss: 2.0698, G_loss: 2.2417\n",
            "Epoch [6/14] Batch [800/1851] D_loss: 2.2977, G_loss: 1.8730\n",
            "Epoch [6/14] Batch [900/1851] D_loss: 2.0819, G_loss: 2.0749\n",
            "Epoch [6/14] Batch [1000/1851] D_loss: 2.1488, G_loss: 1.7538\n",
            "Epoch [6/14] Batch [1100/1851] D_loss: 2.0954, G_loss: 1.7433\n",
            "Epoch [6/14] Batch [1200/1851] D_loss: 2.1832, G_loss: 1.7296\n",
            "Epoch [6/14] Batch [1300/1851] D_loss: 2.0078, G_loss: 1.7709\n",
            "Epoch [6/14] Batch [1400/1851] D_loss: 1.8491, G_loss: 3.3475\n",
            "Epoch [6/14] Batch [1500/1851] D_loss: 1.8871, G_loss: 1.7868\n",
            "Epoch [6/14] Batch [1600/1851] D_loss: 2.0458, G_loss: 2.1198\n",
            "Epoch [6/14] Batch [1700/1851] D_loss: 1.8655, G_loss: 2.1645\n",
            "Epoch [6/14] Batch [1800/1851] D_loss: 2.3296, G_loss: 1.9552\n",
            "Epoch [7/14] Batch [0/1851] D_loss: 2.0155, G_loss: 2.0396\n",
            "Epoch [7/14] Batch [100/1851] D_loss: 2.1481, G_loss: 1.9951\n",
            "Epoch [7/14] Batch [200/1851] D_loss: 2.3461, G_loss: 2.0749\n",
            "Epoch [7/14] Batch [300/1851] D_loss: 1.9737, G_loss: 2.0764\n",
            "Epoch [7/14] Batch [400/1851] D_loss: 2.3266, G_loss: 2.1241\n",
            "Epoch [7/14] Batch [500/1851] D_loss: 2.0639, G_loss: 1.7350\n",
            "Epoch [7/14] Batch [600/1851] D_loss: 1.9624, G_loss: 1.8300\n",
            "Epoch [7/14] Batch [700/1851] D_loss: 2.2489, G_loss: 1.6919\n",
            "Epoch [7/14] Batch [800/1851] D_loss: 1.9683, G_loss: 1.9923\n",
            "Epoch [7/14] Batch [900/1851] D_loss: 1.7904, G_loss: 2.7599\n",
            "Epoch [7/14] Batch [1000/1851] D_loss: 1.8487, G_loss: 1.7895\n",
            "Epoch [7/14] Batch [1100/1851] D_loss: 2.1403, G_loss: 1.6001\n",
            "Epoch [7/14] Batch [1200/1851] D_loss: 1.9618, G_loss: 1.8744\n",
            "Epoch [7/14] Batch [1300/1851] D_loss: 1.9596, G_loss: 1.7961\n",
            "Epoch [7/14] Batch [1400/1851] D_loss: 2.0006, G_loss: 2.0679\n",
            "Epoch [7/14] Batch [1500/1851] D_loss: 2.0843, G_loss: 2.2501\n",
            "Epoch [7/14] Batch [1600/1851] D_loss: 2.2753, G_loss: 1.8713\n",
            "Epoch [7/14] Batch [1700/1851] D_loss: 2.2978, G_loss: 2.4340\n",
            "Epoch [7/14] Batch [1800/1851] D_loss: 1.7398, G_loss: 2.8828\n",
            "Epoch [8/14] Batch [0/1851] D_loss: 1.7673, G_loss: 3.4733\n",
            "Epoch [8/14] Batch [100/1851] D_loss: 1.6739, G_loss: 3.6257\n",
            "Epoch [8/14] Batch [200/1851] D_loss: 1.8305, G_loss: 3.1741\n",
            "Epoch [8/14] Batch [300/1851] D_loss: 1.7782, G_loss: 3.5511\n",
            "Epoch [8/14] Batch [400/1851] D_loss: 1.9487, G_loss: 4.4819\n",
            "Epoch [8/14] Batch [500/1851] D_loss: 1.4796, G_loss: 4.1159\n",
            "Epoch [8/14] Batch [600/1851] D_loss: 1.8306, G_loss: 4.2368\n",
            "Epoch [8/14] Batch [700/1851] D_loss: 1.5660, G_loss: 4.1914\n",
            "Epoch [8/14] Batch [800/1851] D_loss: 1.7831, G_loss: 5.1385\n",
            "Epoch [8/14] Batch [900/1851] D_loss: 1.8193, G_loss: 3.6774\n",
            "Epoch [8/14] Batch [1000/1851] D_loss: 1.4841, G_loss: 4.8371\n",
            "Epoch [8/14] Batch [1100/1851] D_loss: 1.8696, G_loss: 3.0847\n",
            "Epoch [8/14] Batch [1200/1851] D_loss: 1.6593, G_loss: 3.6584\n",
            "Epoch [8/14] Batch [1300/1851] D_loss: 1.7020, G_loss: 4.7951\n",
            "Epoch [8/14] Batch [1400/1851] D_loss: 1.5509, G_loss: 3.8573\n",
            "Epoch [8/14] Batch [1500/1851] D_loss: 1.6718, G_loss: 2.8019\n",
            "Epoch [8/14] Batch [1600/1851] D_loss: 1.7137, G_loss: 3.5812\n",
            "Epoch [8/14] Batch [1700/1851] D_loss: 1.9111, G_loss: 3.0470\n",
            "Epoch [8/14] Batch [1800/1851] D_loss: 1.9996, G_loss: 3.7094\n",
            "Epoch [9/14] Batch [0/1851] D_loss: 1.5665, G_loss: 3.2826\n",
            "Epoch [9/14] Batch [100/1851] D_loss: 1.4968, G_loss: 3.5953\n",
            "Epoch [9/14] Batch [200/1851] D_loss: 1.6839, G_loss: 3.6869\n",
            "Epoch [9/14] Batch [300/1851] D_loss: 1.7198, G_loss: 4.1703\n",
            "Epoch [9/14] Batch [400/1851] D_loss: 1.7407, G_loss: 3.3833\n",
            "Epoch [9/14] Batch [500/1851] D_loss: 1.7899, G_loss: 2.5910\n",
            "Epoch [9/14] Batch [600/1851] D_loss: 2.1360, G_loss: 5.6641\n",
            "Epoch [9/14] Batch [700/1851] D_loss: 1.7401, G_loss: 3.9100\n",
            "Epoch [9/14] Batch [800/1851] D_loss: 1.9227, G_loss: 4.6584\n",
            "Epoch [9/14] Batch [900/1851] D_loss: 1.8383, G_loss: 4.4967\n",
            "Epoch [9/14] Batch [1000/1851] D_loss: 1.7343, G_loss: 4.2756\n",
            "Epoch [9/14] Batch [1100/1851] D_loss: 1.8524, G_loss: 5.2830\n",
            "Epoch [9/14] Batch [1200/1851] D_loss: 1.4936, G_loss: 3.2142\n",
            "Epoch [9/14] Batch [1300/1851] D_loss: 1.8537, G_loss: 3.1189\n",
            "Epoch [9/14] Batch [1400/1851] D_loss: 1.7598, G_loss: 3.1518\n",
            "Epoch [9/14] Batch [1500/1851] D_loss: 1.2699, G_loss: 4.8901\n",
            "Epoch [9/14] Batch [1600/1851] D_loss: 1.7875, G_loss: 2.2568\n",
            "Epoch [9/14] Batch [1700/1851] D_loss: 1.7318, G_loss: 2.3649\n",
            "Epoch [9/14] Batch [1800/1851] D_loss: 2.3139, G_loss: 2.2145\n",
            "Epoch [10/14] Batch [0/1851] D_loss: 2.1107, G_loss: 2.3441\n",
            "Epoch [10/14] Batch [100/1851] D_loss: 1.8189, G_loss: 1.8939\n",
            "Epoch [10/14] Batch [200/1851] D_loss: 1.9611, G_loss: 2.2721\n",
            "Epoch [10/14] Batch [300/1851] D_loss: 2.0504, G_loss: 2.4743\n",
            "Epoch [10/14] Batch [400/1851] D_loss: 2.0059, G_loss: 2.4257\n",
            "Epoch [10/14] Batch [500/1851] D_loss: 2.1419, G_loss: 2.7986\n",
            "Epoch [10/14] Batch [600/1851] D_loss: 2.0744, G_loss: 2.2630\n",
            "Epoch [10/14] Batch [700/1851] D_loss: 2.0634, G_loss: 2.3381\n",
            "Epoch [10/14] Batch [800/1851] D_loss: 1.9815, G_loss: 2.0375\n",
            "Epoch [10/14] Batch [900/1851] D_loss: 1.6699, G_loss: 2.4367\n",
            "Epoch [10/14] Batch [1000/1851] D_loss: 1.8855, G_loss: 2.1242\n",
            "Epoch [10/14] Batch [1100/1851] D_loss: 2.0077, G_loss: 2.2860\n",
            "Epoch [10/14] Batch [1200/1851] D_loss: 2.1543, G_loss: 2.1226\n",
            "Epoch [10/14] Batch [1300/1851] D_loss: 2.3069, G_loss: 2.7614\n",
            "Epoch [10/14] Batch [1400/1851] D_loss: 2.2734, G_loss: 2.3809\n",
            "Epoch [10/14] Batch [1500/1851] D_loss: 2.2489, G_loss: 1.6526\n",
            "Epoch [10/14] Batch [1600/1851] D_loss: 2.1673, G_loss: 2.5819\n",
            "Epoch [10/14] Batch [1700/1851] D_loss: 2.1162, G_loss: 2.1663\n",
            "Epoch [10/14] Batch [1800/1851] D_loss: 1.5581, G_loss: 2.1748\n",
            "Epoch [11/14] Batch [0/1851] D_loss: 1.8064, G_loss: 2.4151\n",
            "Epoch [11/14] Batch [100/1851] D_loss: 1.4988, G_loss: 2.5558\n",
            "Epoch [11/14] Batch [200/1851] D_loss: 1.7331, G_loss: 2.1805\n",
            "Epoch [11/14] Batch [300/1851] D_loss: 2.6637, G_loss: 2.5230\n",
            "Epoch [11/14] Batch [400/1851] D_loss: 1.9783, G_loss: 2.2437\n",
            "Epoch [11/14] Batch [500/1851] D_loss: 1.8581, G_loss: 2.2121\n",
            "Epoch [11/14] Batch [600/1851] D_loss: 1.8862, G_loss: 2.2441\n",
            "Epoch [11/14] Batch [700/1851] D_loss: 1.7894, G_loss: 2.7609\n",
            "Epoch [11/14] Batch [800/1851] D_loss: 1.7037, G_loss: 2.9220\n",
            "Epoch [11/14] Batch [900/1851] D_loss: 1.9607, G_loss: 2.8287\n",
            "Epoch [11/14] Batch [1000/1851] D_loss: 1.6866, G_loss: 2.3111\n",
            "Epoch [11/14] Batch [1100/1851] D_loss: 1.7727, G_loss: 2.2240\n",
            "Epoch [11/14] Batch [1200/1851] D_loss: 1.7741, G_loss: 2.1578\n",
            "Epoch [11/14] Batch [1300/1851] D_loss: 1.8536, G_loss: 2.2634\n",
            "Epoch [11/14] Batch [1400/1851] D_loss: 2.3653, G_loss: 4.2593\n",
            "Epoch [11/14] Batch [1500/1851] D_loss: 1.7815, G_loss: 2.0306\n",
            "Epoch [11/14] Batch [1600/1851] D_loss: 1.4921, G_loss: 2.2943\n",
            "Epoch [11/14] Batch [1700/1851] D_loss: 1.9846, G_loss: 2.2220\n",
            "Epoch [11/14] Batch [1800/1851] D_loss: 1.5679, G_loss: 1.9837\n",
            "Epoch [12/14] Batch [0/1851] D_loss: 1.9091, G_loss: 2.4055\n",
            "Epoch [12/14] Batch [100/1851] D_loss: 1.7874, G_loss: 2.3860\n",
            "Epoch [12/14] Batch [200/1851] D_loss: 1.7191, G_loss: 2.7633\n",
            "Epoch [12/14] Batch [300/1851] D_loss: 1.7546, G_loss: 2.4112\n",
            "Epoch [12/14] Batch [400/1851] D_loss: 1.7663, G_loss: 2.5313\n",
            "Epoch [12/14] Batch [500/1851] D_loss: 1.5807, G_loss: 2.3939\n",
            "Epoch [12/14] Batch [600/1851] D_loss: 1.7781, G_loss: 2.2416\n",
            "Epoch [12/14] Batch [700/1851] D_loss: 1.8440, G_loss: 2.2737\n",
            "Epoch [12/14] Batch [800/1851] D_loss: 2.1717, G_loss: 2.7793\n",
            "Epoch [12/14] Batch [900/1851] D_loss: 1.9971, G_loss: 2.4737\n",
            "Epoch [12/14] Batch [1000/1851] D_loss: 1.8074, G_loss: 1.8536\n",
            "Epoch [12/14] Batch [1100/1851] D_loss: 1.9373, G_loss: 2.1266\n",
            "Epoch [12/14] Batch [1200/1851] D_loss: 1.9963, G_loss: 2.2659\n",
            "Epoch [12/14] Batch [1300/1851] D_loss: 1.8300, G_loss: 2.3403\n",
            "Epoch [12/14] Batch [1400/1851] D_loss: 2.0721, G_loss: 2.2301\n",
            "Epoch [12/14] Batch [1500/1851] D_loss: 2.1436, G_loss: 2.4100\n",
            "Epoch [12/14] Batch [1600/1851] D_loss: 1.5744, G_loss: 3.6107\n",
            "Epoch [12/14] Batch [1700/1851] D_loss: 2.0529, G_loss: 2.4522\n",
            "Epoch [12/14] Batch [1800/1851] D_loss: 1.6382, G_loss: 2.3397\n",
            "Epoch [13/14] Batch [0/1851] D_loss: 1.4398, G_loss: 3.5159\n",
            "Epoch [13/14] Batch [100/1851] D_loss: 1.6790, G_loss: 3.6156\n",
            "Epoch [13/14] Batch [200/1851] D_loss: 1.5912, G_loss: 2.5113\n",
            "Epoch [13/14] Batch [300/1851] D_loss: 1.6903, G_loss: 2.4843\n",
            "Epoch [13/14] Batch [400/1851] D_loss: 1.7895, G_loss: 2.4484\n",
            "Epoch [13/14] Batch [500/1851] D_loss: 1.8030, G_loss: 2.5805\n",
            "Epoch [13/14] Batch [600/1851] D_loss: 1.8114, G_loss: 2.8831\n",
            "Epoch [13/14] Batch [700/1851] D_loss: 2.1858, G_loss: 2.1544\n",
            "Epoch [13/14] Batch [800/1851] D_loss: 1.9263, G_loss: 2.2688\n",
            "Epoch [13/14] Batch [900/1851] D_loss: 1.7388, G_loss: 2.3033\n",
            "Epoch [13/14] Batch [1000/1851] D_loss: 1.8099, G_loss: 2.0621\n",
            "Epoch [13/14] Batch [1100/1851] D_loss: 1.8532, G_loss: 2.3316\n",
            "Epoch [13/14] Batch [1200/1851] D_loss: 2.1138, G_loss: 2.2887\n",
            "Epoch [13/14] Batch [1300/1851] D_loss: 1.9618, G_loss: 2.2129\n",
            "Epoch [13/14] Batch [1400/1851] D_loss: 1.5853, G_loss: 2.2864\n",
            "Epoch [13/14] Batch [1500/1851] D_loss: 2.3776, G_loss: 1.8233\n",
            "Epoch [13/14] Batch [1600/1851] D_loss: 1.9092, G_loss: 2.1338\n",
            "Epoch [13/14] Batch [1700/1851] D_loss: 2.2919, G_loss: 2.0286\n",
            "Epoch [13/14] Batch [1800/1851] D_loss: 1.9204, G_loss: 2.4289\n",
            "Epoch [14/14] Batch [0/1851] D_loss: 2.2885, G_loss: 2.1529\n",
            "Epoch [14/14] Batch [100/1851] D_loss: 2.0260, G_loss: 2.0966\n",
            "Epoch [14/14] Batch [200/1851] D_loss: 1.7639, G_loss: 1.8626\n",
            "Epoch [14/14] Batch [300/1851] D_loss: 1.8622, G_loss: 2.4126\n",
            "Epoch [14/14] Batch [400/1851] D_loss: 1.7579, G_loss: 2.3201\n",
            "Epoch [14/14] Batch [500/1851] D_loss: 1.5686, G_loss: 2.6227\n",
            "Epoch [14/14] Batch [600/1851] D_loss: 2.0580, G_loss: 2.0182\n",
            "Epoch [14/14] Batch [700/1851] D_loss: 1.9224, G_loss: 2.2250\n",
            "Epoch [14/14] Batch [800/1851] D_loss: 1.8148, G_loss: 2.4619\n",
            "Epoch [14/14] Batch [900/1851] D_loss: 1.9183, G_loss: 2.0518\n",
            "Epoch [14/14] Batch [1000/1851] D_loss: 1.5722, G_loss: 2.5497\n",
            "Epoch [14/14] Batch [1100/1851] D_loss: 1.9547, G_loss: 2.3013\n",
            "Epoch [14/14] Batch [1200/1851] D_loss: 1.9096, G_loss: 2.6663\n",
            "Epoch [14/14] Batch [1300/1851] D_loss: 1.7506, G_loss: 2.7227\n",
            "Epoch [14/14] Batch [1400/1851] D_loss: 2.2353, G_loss: 2.3705\n",
            "Epoch [14/14] Batch [1500/1851] D_loss: 1.7505, G_loss: 2.5016\n",
            "Epoch [14/14] Batch [1600/1851] D_loss: 1.7584, G_loss: 2.5710\n",
            "Epoch [14/14] Batch [1700/1851] D_loss: 1.9399, G_loss: 2.4311\n",
            "Epoch [14/14] Batch [1800/1851] D_loss: 1.8594, G_loss: 2.5055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test"
      ],
      "metadata": {
        "id": "TATTMp5lv2en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Assuming you have already imported necessary libraries and defined CustomDataset\n",
        "\n",
        "# Create test dataset\n",
        "test_dataset24o = CustomDataset6(X_test24o, y_test24o)\n",
        "\n",
        "# Create DataLoader\n",
        "test_loader24o = DataLoader(test_dataset24o, batch_size=batch_size24o, shuffle=False)\n",
        "\n",
        "# Set the discriminator to evaluation mode\n",
        "discriminator24o.eval()\n",
        "\n",
        "test_gan(test_loader24o, discriminator24o)"
      ],
      "metadata": {
        "id": "fM0eJNoryi4f",
        "outputId": "37f9b9dc-5579-428c-92fc-88dbeb36dbf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5196\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5905    0.3124    0.4086     11572\n",
            "           1     0.4955    0.4480    0.4705      8954\n",
            "           2     0.2491    0.1375    0.1772      8975\n",
            "           3     0.5470    0.7362    0.6276     29878\n",
            "\n",
            "    accuracy                         0.5196     59379\n",
            "   macro avg     0.4705    0.4085    0.4210     59379\n",
            "weighted avg     0.5027    0.5196    0.4932     59379\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 3615   386   399  7172]\n",
            " [  268  4011   496  4179]\n",
            " [  193   685  1234  6863]\n",
            " [ 2046  3013  2824 21995]]\n",
            "Per-class Recall:\n",
            "Class 0: 0.3124\n",
            "Class 1: 0.4480\n",
            "Class 2: 0.1375\n",
            "Class 3: 0.7362\n",
            "Per-class Accuracy:\n",
            "Class 0: 3.9132\n",
            "Class 1: 4.0282\n",
            "Class 2: 3.8335\n",
            "Class 3: 2.6626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data processing, window size 72 non-overlapping"
      ],
      "metadata": {
        "id": "oJ0_MdxFzyvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store sliding windows and labels for both train and test sets for each activity\n",
        "# This will hold the training and test data after processing each activity.\n",
        "train_test_data72 = {}\n",
        "\n",
        "# Loop through each activity folder and process the data\n",
        "# Note, if you have large amounts of data, this step may take a while\n",
        "for activity, label in activities.items():\n",
        "    # Initialize an empty dictionary for each activity to store train and test windows and labels\n",
        "    train_test_data72[activity] = {}\n",
        "\n",
        "    # Call process_activity() to process the data for the current activity folder\n",
        "    # It loads the data, applies sliding windows, splits it into train and test sets,\n",
        "    # and returns the respective sliding windows and labels for both sets.\n",
        "    (train_test_data72[activity]['train_windows'], train_test_data72[activity]['train_labels'],\n",
        "     train_test_data72[activity]['test_windows'], train_test_data72[activity]['test_labels']) = process_activity(\n",
        "        activity, label, your_dataset_path, window_size=72, step_size=72)\n",
        "\n",
        "# Explanation:\n",
        "    # - 'train_windows' and 'train_labels' store the windows and labels from the training files.\n",
        "    # - 'test_windows' and 'test_labels' store the windows and labels from the test files.\n",
        "    # - `your_dataset_path` should be replaced with the actual path to your dataset.\n",
        "    # - `process_activity` handles all the steps of loading data, splitting it, and applying sliding windows.\n",
        "    # Combine the sliding windows and labels for the training data from all activities\n",
        "# The combine_data() function concatenates the windows and labels across activities\n",
        "X_train72, y_train72 = combine_data(train_test_data72, 'train')\n",
        "\n",
        "# Combine the sliding windows and labels for the test data from all activities\n",
        "X_test72, y_test72 = combine_data(train_test_data72, 'test')\n",
        "\n",
        "# Explanation:\n",
        "# - `combine_data()` takes in the `train_test_data` dictionary and the data type ('train' or 'test') to specify\n",
        "#   whether we are combining training or testing data.\n",
        "# - It retrieves and concatenates the windows and labels from all activities into single arrays\n",
        "#   (`X_train` and `y_train` for training, `X_test` and `y_test` for testing).\n",
        "# - `X_train` and `X_test` are 3D arrays of sliding windows (shape: num_windows, window_size, num_features).\n",
        "# - `y_train` and `y_test` are 1D arrays containing the activity labels corresponding to each window.\n",
        "# Initialize the OneHotEncoder\n",
        "encoder72 = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Reshape y_train to a 2D array to meet the input format requirements of OneHotEncoder\n",
        "# - y_train is originally a 1D array of labels (shape: [num_samples]), but OneHotEncoder expects a 2D array of shape (num_samples, 1).\n",
        "# - reshape(-1, 1): The -1 means 'infer the correct size based on the other dimensions' (i.e., it adapts based on the length of y_train).\n",
        "# OneHotEncoder will then create a binary vector for each label.\n",
        "y_train_one_hot72 = encoder72.fit_transform(y_train72.reshape(-1, 1))\n",
        "\n",
        "# Apply the same transformation to the test labels (y_test)\n",
        "# - Since the encoder is already fitted on the training data, we use transform() for the test set.\n",
        "# - Reshape y_test to (num_samples, 1) for compatibility with the encoder.\n",
        "y_test_one_hot72 = encoder72.transform(y_test72.reshape(-1, 1))\n",
        "\n",
        "# Explanation:\n",
        "# - y_train_one_hot and y_test_one_hot are now 2D arrays where each row is a one-hot encoded binary vector corresponding to a class label.\n",
        "# - The number of columns in the one-hot encoded labels equals the number of unique classes (activities).\n",
        "# For example, if there are 6 unique activities, the encoded vector will have 6 elements, with a '1' indicating the correct class.\n",
        "# Print the shapes of the training and test arrays to verify that everything has been combined correctly\n",
        "print(f\"X_train24 shape: {X_train72.shape}, y_train24 shape: {y_train72.shape}\")\n",
        "print(f\"X_test24 shape: {X_test72.shape}, y_test24 shape: {y_test72.shape}\")\n",
        "# Print the shapes of the one-hot encoded labels to verify that the transformation was successful\n",
        "print(f\"y_train_one_hot24 shape: {y_train_one_hot72.shape}, y_test_one_hot24 shape: {y_test_one_hot72.shape}\")\n",
        "\n",
        "# Explanation of shapes:\n",
        "# - The shape of y_train_one_hot will be (num_samples, num_classes), where:\n",
        "#     - num_samples is the number of training windows.\n",
        "#     - num_classes is the number of unique activities (the length of the one-hot vectors).\n",
        "# - Similarly, y_test_one_hot will have the same number of columns (num_classes) as y_train_one_hot but will have fewer rows (corresponding to the number of test windows).\n",
        "\n",
        "# Determine the input shape for the model\n",
        "input_shape72 = (X_train72.shape[1], X_train72.shape[2])"
      ],
      "metadata": {
        "id": "74xXGuFVz2PK",
        "outputId": "ee9d4495-83b7-4650-b5ea-26bd7363e201",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train24 shape: (38299, 72, 3), y_train24 shape: (38299,)\n",
            "X_test24 shape: (9600, 72, 3), y_test24 shape: (9600,)\n",
            "y_train_one_hot24 shape: (38299, 4), y_test_one_hot24 shape: (9600, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train, window size 72 non-overlapping"
      ],
      "metadata": {
        "id": "zHmUHe0B0pd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator72(nn.Module):\n",
        "    def __init__(self, latent_dim=100, num_classes=4, output_channels=3):\n",
        "        super(Generator72, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Layers for processing noise vector z\n",
        "        self.fc_z = nn.Linear(latent_dim, 1024 * 4)  # Output: (batch_size, 4096)\n",
        "\n",
        "        # Layers for processing class labels c\n",
        "        self.fc_c = nn.Linear(num_classes, 1024 * 4)  # Output: (batch_size, 4096)\n",
        "\n",
        "        self.deconv1 = nn.Sequential(\n",
        "            nn.ConvTranspose1d(2048, 512, kernel_size=3, stride=2, padding=0),  # Output: (batch_size, 512, 9)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.deconv2 = nn.Sequential(\n",
        "            nn.ConvTranspose1d(512, 256, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 256, 18)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.deconv3 = nn.Sequential(\n",
        "            nn.ConvTranspose1d(256, 128, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 128, 36)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.deconv4 = nn.Sequential(\n",
        "            nn.ConvTranspose1d(128, 64, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 64, 72)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.deconv5 = nn.Sequential(\n",
        "            nn.ConvTranspose1d(64, output_channels, kernel_size=1, stride=1, padding=0),  # Output: (batch_size, 3, 72)\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z, c):\n",
        "        # Process noise vector z\n",
        "        x_z = self.fc_z(z)  # Shape: (batch_size, 4096)\n",
        "        x_z = x_z.view(-1, 1024, 4)\n",
        "\n",
        "        # One-hot encode class labels and process\n",
        "        c = F.one_hot(c, num_classes=self.num_classes).float()\n",
        "        x_c = self.fc_c(c)  # Shape: (batch_size, 4096)\n",
        "        x_c = x_c.view(-1, 1024, 4)\n",
        "\n",
        "        # Concatenate feature maps\n",
        "        x = torch.cat([x_z, x_c], dim=1)  # Shape: (batch_size, 2048, 4)\n",
        "\n",
        "        # Pass through deconvolutional layers\n",
        "        x = self.deconv1(x)  # Output: (batch_size, 512, 9)\n",
        "        x = self.deconv2(x)  # Output: (batch_size, 256, 18)\n",
        "        x = self.deconv3(x)  # Output: (batch_size, 128, 36)\n",
        "        x = self.deconv4(x)  # Output: (batch_size, 64, 72)\n",
        "        x = self.deconv5(x)  # Output: (batch_size, 3, 72)\n",
        "        return x  # Output shape: (batch_size, 3, 72)\n",
        "\n",
        "class Discriminator72(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Discriminator72, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv1d(3, 512, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 512, 36)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv1d(512, 1024, kernel_size=4, stride=2, padding=1),  # Output: (batch_size, 1024, 18)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "        self.shared_features = nn.Flatten()  # Flattens to (batch_size, 1024*18)\n",
        "\n",
        "        self.classifier = nn.Linear(1024 * 18, num_classes)\n",
        "        self.discriminator = nn.Sequential(\n",
        "            nn.Linear(1024 * 18, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)  # Output: (batch_size, 512, 36)\n",
        "        x = self.conv2(x)  # Output: (batch_size, 1024, 18)\n",
        "        features = self.shared_features(x)\n",
        "\n",
        "        class_output = self.classifier(features)\n",
        "        real_fake_output = self.discriminator(features)\n",
        "        return class_output, real_fake_output\n"
      ],
      "metadata": {
        "id": "xU6kVlNi1039"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "if __name__ == '__main__':\n",
        "    # Define hyperparameters\n",
        "    latent_dim72 = 100\n",
        "    num_classes72 = 4  # Replace with the actual number of activity classes\n",
        "\n",
        "    #num_epochs6 = 30\n",
        "    batch_size72 = 128\n",
        "\n",
        "    # Initialize models\n",
        "    generator72 = Generator72(latent_dim=latent_dim72, num_classes=num_classes72)\n",
        "    discriminator72 = Discriminator72(num_classes=num_classes72)\n",
        "\n",
        "    # Create DataLoader\n",
        "    train_dataset72 = CustomDataset6(X_train72, y_train72)\n",
        "    sampler72 = RandomSampler(train_dataset72, replacement=True)\n",
        "    train_loader72 = DataLoader(train_dataset72, batch_size=batch_size72, sampler=sampler72)\n",
        "\n",
        "    num_mini_batches_per_epoch = len(train_loader72)\n",
        "    num_epochs72 = (25000 + num_mini_batches_per_epoch - 1) // num_mini_batches_per_epoch  # Ceiling division\n",
        "\n",
        "    # Train the AC-GAN\n",
        "    train_acgan6(generator72, discriminator72, train_loader72, num_classes72, num_epochs72, latent_dim72)\n"
      ],
      "metadata": {
        "id": "q6EOudTO0192",
        "outputId": "443ac883-eab0-4e1d-ef90-0b41fef2ac9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/84] Batch [0/300] D_loss: 4.0881, G_loss: 2.1737\n",
            "Epoch [1/84] Batch [100/300] D_loss: 2.2302, G_loss: 3.3645\n",
            "Epoch [1/84] Batch [200/300] D_loss: 2.1454, G_loss: 3.1217\n",
            "Epoch [2/84] Batch [0/300] D_loss: 2.3067, G_loss: 1.2715\n",
            "Epoch [2/84] Batch [100/300] D_loss: 1.8568, G_loss: 2.5470\n",
            "Epoch [2/84] Batch [200/300] D_loss: 1.9050, G_loss: 2.2484\n",
            "Epoch [3/84] Batch [0/300] D_loss: 2.0873, G_loss: 4.6034\n",
            "Epoch [3/84] Batch [100/300] D_loss: 1.8757, G_loss: 2.6112\n",
            "Epoch [3/84] Batch [200/300] D_loss: 2.0928, G_loss: 1.4585\n",
            "Epoch [4/84] Batch [0/300] D_loss: 1.9792, G_loss: 1.8203\n",
            "Epoch [4/84] Batch [100/300] D_loss: 2.1962, G_loss: 1.4689\n",
            "Epoch [4/84] Batch [200/300] D_loss: 2.2109, G_loss: 1.3459\n",
            "Epoch [5/84] Batch [0/300] D_loss: 1.9818, G_loss: 2.0354\n",
            "Epoch [5/84] Batch [100/300] D_loss: 2.6478, G_loss: 1.6014\n",
            "Epoch [5/84] Batch [200/300] D_loss: 2.1687, G_loss: 2.1877\n",
            "Epoch [6/84] Batch [0/300] D_loss: 2.0938, G_loss: 1.8615\n",
            "Epoch [6/84] Batch [100/300] D_loss: 1.7965, G_loss: 2.5478\n",
            "Epoch [6/84] Batch [200/300] D_loss: 2.0732, G_loss: 1.4616\n",
            "Epoch [7/84] Batch [0/300] D_loss: 2.2312, G_loss: 2.2121\n",
            "Epoch [7/84] Batch [100/300] D_loss: 1.9119, G_loss: 1.8291\n",
            "Epoch [7/84] Batch [200/300] D_loss: 1.7502, G_loss: 1.6142\n",
            "Epoch [8/84] Batch [0/300] D_loss: 2.0496, G_loss: 2.0398\n",
            "Epoch [8/84] Batch [100/300] D_loss: 1.7380, G_loss: 2.2948\n",
            "Epoch [8/84] Batch [200/300] D_loss: 1.8394, G_loss: 3.1730\n",
            "Epoch [9/84] Batch [0/300] D_loss: 1.6897, G_loss: 2.5278\n",
            "Epoch [9/84] Batch [100/300] D_loss: 1.8824, G_loss: 2.0059\n",
            "Epoch [9/84] Batch [200/300] D_loss: 1.9729, G_loss: 1.6146\n",
            "Epoch [10/84] Batch [0/300] D_loss: 1.7517, G_loss: 2.7747\n",
            "Epoch [10/84] Batch [100/300] D_loss: 1.6678, G_loss: 3.2891\n",
            "Epoch [10/84] Batch [200/300] D_loss: 1.6966, G_loss: 3.7083\n",
            "Epoch [11/84] Batch [0/300] D_loss: 1.7499, G_loss: 4.0941\n",
            "Epoch [11/84] Batch [100/300] D_loss: 1.8951, G_loss: 4.0672\n",
            "Epoch [11/84] Batch [200/300] D_loss: 1.5624, G_loss: 3.1691\n",
            "Epoch [12/84] Batch [0/300] D_loss: 1.9520, G_loss: 5.6539\n",
            "Epoch [12/84] Batch [100/300] D_loss: 1.6144, G_loss: 4.9990\n",
            "Epoch [12/84] Batch [200/300] D_loss: 1.6876, G_loss: 3.4522\n",
            "Epoch [13/84] Batch [0/300] D_loss: 2.1547, G_loss: 2.9563\n",
            "Epoch [13/84] Batch [100/300] D_loss: 1.6847, G_loss: 2.3935\n",
            "Epoch [13/84] Batch [200/300] D_loss: 1.6201, G_loss: 2.8613\n",
            "Epoch [14/84] Batch [0/300] D_loss: 1.8099, G_loss: 3.0205\n",
            "Epoch [14/84] Batch [100/300] D_loss: 1.7572, G_loss: 3.8478\n",
            "Epoch [14/84] Batch [200/300] D_loss: 1.7426, G_loss: 3.8040\n",
            "Epoch [15/84] Batch [0/300] D_loss: 1.8771, G_loss: 4.4830\n",
            "Epoch [15/84] Batch [100/300] D_loss: 1.3466, G_loss: 4.9053\n",
            "Epoch [15/84] Batch [200/300] D_loss: 1.6676, G_loss: 5.4990\n",
            "Epoch [16/84] Batch [0/300] D_loss: 1.3009, G_loss: 6.3183\n",
            "Epoch [16/84] Batch [100/300] D_loss: 1.5136, G_loss: 5.7490\n",
            "Epoch [16/84] Batch [200/300] D_loss: 1.5440, G_loss: 5.2829\n",
            "Epoch [17/84] Batch [0/300] D_loss: 1.7245, G_loss: 5.6117\n",
            "Epoch [17/84] Batch [100/300] D_loss: 1.3155, G_loss: 6.9285\n",
            "Epoch [17/84] Batch [200/300] D_loss: 1.6303, G_loss: 2.8641\n",
            "Epoch [18/84] Batch [0/300] D_loss: 1.7217, G_loss: 3.5020\n",
            "Epoch [18/84] Batch [100/300] D_loss: 1.8005, G_loss: 6.0404\n",
            "Epoch [18/84] Batch [200/300] D_loss: 1.4246, G_loss: 6.0519\n",
            "Epoch [19/84] Batch [0/300] D_loss: 1.7291, G_loss: 6.2246\n",
            "Epoch [19/84] Batch [100/300] D_loss: 1.5704, G_loss: 7.5624\n",
            "Epoch [19/84] Batch [200/300] D_loss: 1.5210, G_loss: 6.8074\n",
            "Epoch [20/84] Batch [0/300] D_loss: 1.6877, G_loss: 5.3333\n",
            "Epoch [20/84] Batch [100/300] D_loss: 1.5121, G_loss: 5.6482\n",
            "Epoch [20/84] Batch [200/300] D_loss: 1.6155, G_loss: 5.0888\n",
            "Epoch [21/84] Batch [0/300] D_loss: 1.2618, G_loss: 6.0164\n",
            "Epoch [21/84] Batch [100/300] D_loss: 1.4222, G_loss: 5.6794\n",
            "Epoch [21/84] Batch [200/300] D_loss: 1.4132, G_loss: 7.0359\n",
            "Epoch [22/84] Batch [0/300] D_loss: 1.7524, G_loss: 7.5821\n",
            "Epoch [22/84] Batch [100/300] D_loss: 1.6348, G_loss: 6.1849\n",
            "Epoch [22/84] Batch [200/300] D_loss: 1.4843, G_loss: 8.8339\n",
            "Epoch [23/84] Batch [0/300] D_loss: 1.5510, G_loss: 5.9894\n",
            "Epoch [23/84] Batch [100/300] D_loss: 1.4860, G_loss: 6.3897\n",
            "Epoch [23/84] Batch [200/300] D_loss: 1.4903, G_loss: 8.5805\n",
            "Epoch [24/84] Batch [0/300] D_loss: 1.4739, G_loss: 6.6956\n",
            "Epoch [24/84] Batch [100/300] D_loss: 1.8731, G_loss: 5.1765\n",
            "Epoch [24/84] Batch [200/300] D_loss: 1.7209, G_loss: 4.5792\n",
            "Epoch [25/84] Batch [0/300] D_loss: 2.1503, G_loss: 4.2532\n",
            "Epoch [25/84] Batch [100/300] D_loss: 1.7619, G_loss: 4.8742\n",
            "Epoch [25/84] Batch [200/300] D_loss: 1.3434, G_loss: 5.0275\n",
            "Epoch [26/84] Batch [0/300] D_loss: 1.5873, G_loss: 4.1213\n",
            "Epoch [26/84] Batch [100/300] D_loss: 1.3893, G_loss: 5.9203\n",
            "Epoch [26/84] Batch [200/300] D_loss: 1.3544, G_loss: 5.3046\n",
            "Epoch [27/84] Batch [0/300] D_loss: 1.5329, G_loss: 5.0562\n",
            "Epoch [27/84] Batch [100/300] D_loss: 1.5574, G_loss: 6.1606\n",
            "Epoch [27/84] Batch [200/300] D_loss: 1.3514, G_loss: 8.1938\n",
            "Epoch [28/84] Batch [0/300] D_loss: 2.8972, G_loss: 7.2356\n",
            "Epoch [28/84] Batch [100/300] D_loss: 1.4584, G_loss: 4.0787\n",
            "Epoch [28/84] Batch [200/300] D_loss: 1.5084, G_loss: 4.1865\n",
            "Epoch [29/84] Batch [0/300] D_loss: 1.4692, G_loss: 3.9621\n",
            "Epoch [29/84] Batch [100/300] D_loss: 1.5053, G_loss: 5.7717\n",
            "Epoch [29/84] Batch [200/300] D_loss: 1.5157, G_loss: 5.4143\n",
            "Epoch [30/84] Batch [0/300] D_loss: 1.7786, G_loss: 4.6602\n",
            "Epoch [30/84] Batch [100/300] D_loss: 1.5167, G_loss: 3.9213\n",
            "Epoch [30/84] Batch [200/300] D_loss: 1.4693, G_loss: 3.9488\n",
            "Epoch [31/84] Batch [0/300] D_loss: 1.7908, G_loss: 4.1803\n",
            "Epoch [31/84] Batch [100/300] D_loss: 1.4020, G_loss: 4.1964\n",
            "Epoch [31/84] Batch [200/300] D_loss: 1.4396, G_loss: 4.9739\n",
            "Epoch [32/84] Batch [0/300] D_loss: 1.3811, G_loss: 8.5627\n",
            "Epoch [32/84] Batch [100/300] D_loss: 1.4539, G_loss: 6.3379\n",
            "Epoch [32/84] Batch [200/300] D_loss: 1.4144, G_loss: 5.3954\n",
            "Epoch [33/84] Batch [0/300] D_loss: 1.4778, G_loss: 5.7409\n",
            "Epoch [33/84] Batch [100/300] D_loss: 1.3558, G_loss: 4.3744\n",
            "Epoch [33/84] Batch [200/300] D_loss: 1.3836, G_loss: 7.7645\n",
            "Epoch [34/84] Batch [0/300] D_loss: 1.3309, G_loss: 3.6509\n",
            "Epoch [34/84] Batch [100/300] D_loss: 1.4058, G_loss: 3.9469\n",
            "Epoch [34/84] Batch [200/300] D_loss: 1.4363, G_loss: 6.4460\n",
            "Epoch [35/84] Batch [0/300] D_loss: 1.6091, G_loss: 4.4606\n",
            "Epoch [35/84] Batch [100/300] D_loss: 1.6236, G_loss: 5.9859\n",
            "Epoch [35/84] Batch [200/300] D_loss: 1.1921, G_loss: 10.9162\n",
            "Epoch [36/84] Batch [0/300] D_loss: 1.4465, G_loss: 5.0712\n",
            "Epoch [36/84] Batch [100/300] D_loss: 1.5019, G_loss: 10.0766\n",
            "Epoch [36/84] Batch [200/300] D_loss: 1.4117, G_loss: 8.1303\n",
            "Epoch [37/84] Batch [0/300] D_loss: 1.6172, G_loss: 5.1352\n",
            "Epoch [37/84] Batch [100/300] D_loss: 1.3779, G_loss: 5.9133\n",
            "Epoch [37/84] Batch [200/300] D_loss: 1.7845, G_loss: 7.0437\n",
            "Epoch [38/84] Batch [0/300] D_loss: 1.4752, G_loss: 8.8496\n",
            "Epoch [38/84] Batch [100/300] D_loss: 1.5226, G_loss: 6.0983\n",
            "Epoch [38/84] Batch [200/300] D_loss: 1.7601, G_loss: 9.4176\n",
            "Epoch [39/84] Batch [0/300] D_loss: 1.5440, G_loss: 11.3614\n",
            "Epoch [39/84] Batch [100/300] D_loss: 1.6183, G_loss: 5.5251\n",
            "Epoch [39/84] Batch [200/300] D_loss: 1.4112, G_loss: 4.3053\n",
            "Epoch [40/84] Batch [0/300] D_loss: 1.4433, G_loss: 6.2240\n",
            "Epoch [40/84] Batch [100/300] D_loss: 1.5108, G_loss: 6.6383\n",
            "Epoch [40/84] Batch [200/300] D_loss: 1.3748, G_loss: 22.9671\n",
            "Epoch [41/84] Batch [0/300] D_loss: 1.5042, G_loss: 6.6500\n",
            "Epoch [41/84] Batch [100/300] D_loss: 1.3474, G_loss: 4.6300\n",
            "Epoch [41/84] Batch [200/300] D_loss: 1.3682, G_loss: 4.5208\n",
            "Epoch [42/84] Batch [0/300] D_loss: 1.3389, G_loss: 6.9905\n",
            "Epoch [42/84] Batch [100/300] D_loss: 1.3738, G_loss: 10.0354\n",
            "Epoch [42/84] Batch [200/300] D_loss: 1.4701, G_loss: 6.3544\n",
            "Epoch [43/84] Batch [0/300] D_loss: 1.5921, G_loss: 11.7130\n",
            "Epoch [43/84] Batch [100/300] D_loss: 1.1933, G_loss: 12.0576\n",
            "Epoch [43/84] Batch [200/300] D_loss: 1.4891, G_loss: 11.2488\n",
            "Epoch [44/84] Batch [0/300] D_loss: 1.3831, G_loss: 10.7626\n",
            "Epoch [44/84] Batch [100/300] D_loss: 1.3978, G_loss: 8.2493\n",
            "Epoch [44/84] Batch [200/300] D_loss: 1.5473, G_loss: 5.9677\n",
            "Epoch [45/84] Batch [0/300] D_loss: 1.3703, G_loss: 5.9079\n",
            "Epoch [45/84] Batch [100/300] D_loss: 1.4611, G_loss: 4.9910\n",
            "Epoch [45/84] Batch [200/300] D_loss: 1.5759, G_loss: 4.3644\n",
            "Epoch [46/84] Batch [0/300] D_loss: 1.7566, G_loss: 9.8160\n",
            "Epoch [46/84] Batch [100/300] D_loss: 1.3107, G_loss: 4.9705\n",
            "Epoch [46/84] Batch [200/300] D_loss: 1.7672, G_loss: 5.5724\n",
            "Epoch [47/84] Batch [0/300] D_loss: 1.4410, G_loss: 5.2625\n",
            "Epoch [47/84] Batch [100/300] D_loss: 1.6240, G_loss: 5.1191\n",
            "Epoch [47/84] Batch [200/300] D_loss: 1.5274, G_loss: 5.9085\n",
            "Epoch [48/84] Batch [0/300] D_loss: 1.7403, G_loss: 6.8359\n",
            "Epoch [48/84] Batch [100/300] D_loss: 1.5068, G_loss: 5.6420\n",
            "Epoch [48/84] Batch [200/300] D_loss: 1.4560, G_loss: 10.1517\n",
            "Epoch [49/84] Batch [0/300] D_loss: 1.5780, G_loss: 4.1570\n",
            "Epoch [49/84] Batch [100/300] D_loss: 1.3650, G_loss: 3.9247\n",
            "Epoch [49/84] Batch [200/300] D_loss: 1.7498, G_loss: 3.5549\n",
            "Epoch [50/84] Batch [0/300] D_loss: 1.2750, G_loss: 6.0369\n",
            "Epoch [50/84] Batch [100/300] D_loss: 1.4023, G_loss: 4.4856\n",
            "Epoch [50/84] Batch [200/300] D_loss: 1.7711, G_loss: 4.7001\n",
            "Epoch [51/84] Batch [0/300] D_loss: 1.5665, G_loss: 5.0973\n",
            "Epoch [51/84] Batch [100/300] D_loss: 1.5764, G_loss: 4.0405\n",
            "Epoch [51/84] Batch [200/300] D_loss: 1.3483, G_loss: 3.9571\n",
            "Epoch [52/84] Batch [0/300] D_loss: 1.4544, G_loss: 8.1320\n",
            "Epoch [52/84] Batch [100/300] D_loss: 1.1714, G_loss: 4.8405\n",
            "Epoch [52/84] Batch [200/300] D_loss: 1.1561, G_loss: 4.4955\n",
            "Epoch [53/84] Batch [0/300] D_loss: 1.2742, G_loss: 7.9675\n",
            "Epoch [53/84] Batch [100/300] D_loss: 1.2961, G_loss: 5.3316\n",
            "Epoch [53/84] Batch [200/300] D_loss: 1.4674, G_loss: 4.0562\n",
            "Epoch [54/84] Batch [0/300] D_loss: 1.3108, G_loss: 6.2766\n",
            "Epoch [54/84] Batch [100/300] D_loss: 1.5068, G_loss: 5.6314\n",
            "Epoch [54/84] Batch [200/300] D_loss: 1.1976, G_loss: 6.2228\n",
            "Epoch [55/84] Batch [0/300] D_loss: 1.1704, G_loss: 4.5174\n",
            "Epoch [55/84] Batch [100/300] D_loss: 1.2751, G_loss: 4.8437\n",
            "Epoch [55/84] Batch [200/300] D_loss: 1.1442, G_loss: 9.3676\n",
            "Epoch [56/84] Batch [0/300] D_loss: 1.9322, G_loss: 7.0560\n",
            "Epoch [56/84] Batch [100/300] D_loss: 1.4562, G_loss: 9.1628\n",
            "Epoch [56/84] Batch [200/300] D_loss: 1.6963, G_loss: 3.9371\n",
            "Epoch [57/84] Batch [0/300] D_loss: 1.2855, G_loss: 6.1641\n",
            "Epoch [57/84] Batch [100/300] D_loss: 1.4386, G_loss: 6.5183\n",
            "Epoch [57/84] Batch [200/300] D_loss: 1.5215, G_loss: 4.3352\n",
            "Epoch [58/84] Batch [0/300] D_loss: 1.4614, G_loss: 5.2127\n",
            "Epoch [58/84] Batch [100/300] D_loss: 1.1886, G_loss: 9.5291\n",
            "Epoch [58/84] Batch [200/300] D_loss: 1.2946, G_loss: 20.1972\n",
            "Epoch [59/84] Batch [0/300] D_loss: 1.5082, G_loss: 20.7392\n",
            "Epoch [59/84] Batch [100/300] D_loss: 1.3247, G_loss: 16.9333\n",
            "Epoch [59/84] Batch [200/300] D_loss: 1.4191, G_loss: 13.8344\n",
            "Epoch [60/84] Batch [0/300] D_loss: 1.4556, G_loss: 8.9266\n",
            "Epoch [60/84] Batch [100/300] D_loss: 1.2574, G_loss: 6.7526\n",
            "Epoch [60/84] Batch [200/300] D_loss: 1.3720, G_loss: 7.1318\n",
            "Epoch [61/84] Batch [0/300] D_loss: 1.1346, G_loss: 8.1652\n",
            "Epoch [61/84] Batch [100/300] D_loss: 1.1512, G_loss: 7.1185\n",
            "Epoch [61/84] Batch [200/300] D_loss: 1.2260, G_loss: 5.6381\n",
            "Epoch [62/84] Batch [0/300] D_loss: 1.6525, G_loss: 9.6704\n",
            "Epoch [62/84] Batch [100/300] D_loss: 1.2587, G_loss: 5.9034\n",
            "Epoch [62/84] Batch [200/300] D_loss: 1.2974, G_loss: 7.7707\n",
            "Epoch [63/84] Batch [0/300] D_loss: 1.4935, G_loss: 6.4947\n",
            "Epoch [63/84] Batch [100/300] D_loss: 1.4171, G_loss: 6.5955\n",
            "Epoch [63/84] Batch [200/300] D_loss: 1.2314, G_loss: 6.1472\n",
            "Epoch [64/84] Batch [0/300] D_loss: 1.2897, G_loss: 7.2663\n",
            "Epoch [64/84] Batch [100/300] D_loss: 1.5557, G_loss: 6.6769\n",
            "Epoch [64/84] Batch [200/300] D_loss: 1.2362, G_loss: 6.8342\n",
            "Epoch [65/84] Batch [0/300] D_loss: 1.3318, G_loss: 8.7848\n",
            "Epoch [65/84] Batch [100/300] D_loss: 1.4372, G_loss: 12.4569\n",
            "Epoch [65/84] Batch [200/300] D_loss: 1.3050, G_loss: 9.7696\n",
            "Epoch [66/84] Batch [0/300] D_loss: 1.5637, G_loss: 5.7212\n",
            "Epoch [66/84] Batch [100/300] D_loss: 1.3624, G_loss: 7.7496\n",
            "Epoch [66/84] Batch [200/300] D_loss: 1.2459, G_loss: 4.9334\n",
            "Epoch [67/84] Batch [0/300] D_loss: 1.3362, G_loss: 5.5584\n",
            "Epoch [67/84] Batch [100/300] D_loss: 1.3942, G_loss: 7.7439\n",
            "Epoch [67/84] Batch [200/300] D_loss: 1.3303, G_loss: 4.4862\n",
            "Epoch [68/84] Batch [0/300] D_loss: 1.4254, G_loss: 5.6236\n",
            "Epoch [68/84] Batch [100/300] D_loss: 1.3886, G_loss: 6.6527\n",
            "Epoch [68/84] Batch [200/300] D_loss: 1.2521, G_loss: 5.8853\n",
            "Epoch [69/84] Batch [0/300] D_loss: 1.5669, G_loss: 6.1055\n",
            "Epoch [69/84] Batch [100/300] D_loss: 1.2405, G_loss: 6.8483\n",
            "Epoch [69/84] Batch [200/300] D_loss: 0.9895, G_loss: 5.6576\n",
            "Epoch [70/84] Batch [0/300] D_loss: 1.6760, G_loss: 6.4063\n",
            "Epoch [70/84] Batch [100/300] D_loss: 1.2880, G_loss: 6.7517\n",
            "Epoch [70/84] Batch [200/300] D_loss: 1.7769, G_loss: 6.1258\n",
            "Epoch [71/84] Batch [0/300] D_loss: 1.6195, G_loss: 11.4216\n",
            "Epoch [71/84] Batch [100/300] D_loss: 2.0325, G_loss: 4.1943\n",
            "Epoch [71/84] Batch [200/300] D_loss: 1.2366, G_loss: 12.6608\n",
            "Epoch [72/84] Batch [0/300] D_loss: 1.4470, G_loss: 15.2088\n",
            "Epoch [72/84] Batch [100/300] D_loss: 1.1259, G_loss: 15.1333\n",
            "Epoch [72/84] Batch [200/300] D_loss: 1.2684, G_loss: 9.8393\n",
            "Epoch [73/84] Batch [0/300] D_loss: 1.2207, G_loss: 15.2822\n",
            "Epoch [73/84] Batch [100/300] D_loss: 1.0617, G_loss: 12.7928\n",
            "Epoch [73/84] Batch [200/300] D_loss: 1.2025, G_loss: 24.6361\n",
            "Epoch [74/84] Batch [0/300] D_loss: 1.2855, G_loss: 20.0529\n",
            "Epoch [74/84] Batch [100/300] D_loss: 1.1820, G_loss: 12.9882\n",
            "Epoch [74/84] Batch [200/300] D_loss: 1.3124, G_loss: 20.8245\n",
            "Epoch [75/84] Batch [0/300] D_loss: 1.0568, G_loss: 18.3617\n",
            "Epoch [75/84] Batch [100/300] D_loss: 1.0055, G_loss: 17.9445\n",
            "Epoch [75/84] Batch [200/300] D_loss: 1.1763, G_loss: 10.6428\n",
            "Epoch [76/84] Batch [0/300] D_loss: 1.4369, G_loss: 8.7239\n",
            "Epoch [76/84] Batch [100/300] D_loss: 1.1037, G_loss: 8.8655\n",
            "Epoch [76/84] Batch [200/300] D_loss: 1.5701, G_loss: 11.9842\n",
            "Epoch [77/84] Batch [0/300] D_loss: 1.4493, G_loss: 9.8920\n",
            "Epoch [77/84] Batch [100/300] D_loss: 1.5148, G_loss: 6.3986\n",
            "Epoch [77/84] Batch [200/300] D_loss: 1.3695, G_loss: 7.7688\n",
            "Epoch [78/84] Batch [0/300] D_loss: 1.4449, G_loss: 8.2931\n",
            "Epoch [78/84] Batch [100/300] D_loss: 1.1822, G_loss: 5.9113\n",
            "Epoch [78/84] Batch [200/300] D_loss: 1.4634, G_loss: 9.3569\n",
            "Epoch [79/84] Batch [0/300] D_loss: 1.2711, G_loss: 6.3763\n",
            "Epoch [79/84] Batch [100/300] D_loss: 1.3962, G_loss: 8.4024\n",
            "Epoch [79/84] Batch [200/300] D_loss: 1.4883, G_loss: 7.6246\n",
            "Epoch [80/84] Batch [0/300] D_loss: 1.5173, G_loss: 6.1959\n",
            "Epoch [80/84] Batch [100/300] D_loss: 1.4352, G_loss: 4.9481\n",
            "Epoch [80/84] Batch [200/300] D_loss: 1.3058, G_loss: 13.3063\n",
            "Epoch [81/84] Batch [0/300] D_loss: 1.2743, G_loss: 9.0035\n",
            "Epoch [81/84] Batch [100/300] D_loss: 1.4133, G_loss: 8.6727\n",
            "Epoch [81/84] Batch [200/300] D_loss: 1.4489, G_loss: 10.1256\n",
            "Epoch [82/84] Batch [0/300] D_loss: 1.4897, G_loss: 5.9145\n",
            "Epoch [82/84] Batch [100/300] D_loss: 1.2868, G_loss: 10.4070\n",
            "Epoch [82/84] Batch [200/300] D_loss: 1.5165, G_loss: 7.1255\n",
            "Epoch [83/84] Batch [0/300] D_loss: 1.4281, G_loss: 9.9686\n",
            "Epoch [83/84] Batch [100/300] D_loss: 1.1883, G_loss: 9.7723\n",
            "Epoch [83/84] Batch [200/300] D_loss: 1.1456, G_loss: 8.4716\n",
            "Epoch [84/84] Batch [0/300] D_loss: 1.3964, G_loss: 10.9701\n",
            "Epoch [84/84] Batch [100/300] D_loss: 1.3260, G_loss: 11.1456\n",
            "Epoch [84/84] Batch [200/300] D_loss: 1.2824, G_loss: 9.1419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test"
      ],
      "metadata": {
        "id": "q5ksQONY0r0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Assuming you have already imported necessary libraries and defined CustomDataset\n",
        "\n",
        "# Create test dataset\n",
        "test_dataset72 = CustomDataset6(X_test72, y_test72)\n",
        "\n",
        "# Create DataLoader\n",
        "test_loader72 = DataLoader(test_dataset72, batch_size=batch_size72, shuffle=False)\n",
        "\n",
        "# Set the discriminator to evaluation mode\n",
        "discriminator72.eval()\n",
        "\n",
        "\n",
        "test_gan(test_loader72, discriminator72)\n"
      ],
      "metadata": {
        "id": "TSAI4FOi02g0",
        "outputId": "2b54a04b-73b9-4078-b45b-43751fb5686d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4677\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5418    0.4984    0.5192      1872\n",
            "           1     0.4785    0.3460    0.4016      1445\n",
            "           2     0.2355    0.4415    0.3072      1454\n",
            "           3     0.5880    0.5001    0.5405      4829\n",
            "\n",
            "    accuracy                         0.4677      9600\n",
            "   macro avg     0.4610    0.4465    0.4421      9600\n",
            "weighted avg     0.5091    0.4677    0.4801      9600\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 933   17  264  658]\n",
            " [  15  500  526  404]\n",
            " [ 104   78  642  630]\n",
            " [ 670  450 1294 2415]]\n",
            "Per-class Recall:\n",
            "Class 0: 0.4984\n",
            "Class 1: 0.3460\n",
            "Class 2: 0.4415\n",
            "Class 3: 0.5001\n",
            "Per-class Accuracy:\n",
            "Class 0: 0.6298\n",
            "Class 1: 0.6488\n",
            "Class 2: 0.5363\n",
            "Class 3: 0.4395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data processing, window size 72 overlapping"
      ],
      "metadata": {
        "id": "2Fud107h0SqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store sliding windows and labels for both train and test sets for each activity\n",
        "# This will hold the training and test data after processing each activity.\n",
        "train_test_data72o = {}\n",
        "\n",
        "# Loop through each activity folder and process the data\n",
        "# Note, if you have large amounts of data, this step may take a while\n",
        "for activity, label in activities.items():\n",
        "    # Initialize an empty dictionary for each activity to store train and test windows and labels\n",
        "    train_test_data72o[activity] = {}\n",
        "\n",
        "    # Call process_activity() to process the data for the current activity folder\n",
        "    # It loads the data, applies sliding windows, splits it into train and test sets,\n",
        "    # and returns the respective sliding windows and labels for both sets.\n",
        "    (train_test_data72o[activity]['train_windows'], train_test_data72o[activity]['train_labels'],\n",
        "     train_test_data72o[activity]['test_windows'], train_test_data72o[activity]['test_labels']) = process_activity(\n",
        "        activity, label, your_dataset_path, window_size=72, step_size=36)\n",
        "\n",
        "# Explanation:\n",
        "    # - 'train_windows' and 'train_labels' store the windows and labels from the training files.\n",
        "    # - 'test_windows' and 'test_labels' store the windows and labels from the test files.\n",
        "    # - `your_dataset_path` should be replaced with the actual path to your dataset.\n",
        "    # - `process_activity` handles all the steps of loading data, splitting it, and applying sliding windows.\n",
        "    # Combine the sliding windows and labels for the training data from all activities\n",
        "# The combine_data() function concatenates the windows and labels across activities\n",
        "X_train72o, y_train72o = combine_data(train_test_data72o, 'train')\n",
        "\n",
        "# Combine the sliding windows and labels for the test data from all activities\n",
        "X_test72o, y_test72o = combine_data(train_test_data72o, 'test')\n",
        "\n",
        "# Explanation:\n",
        "# - `combine_data()` takes in the `train_test_data` dictionary and the data type ('train' or 'test') to specify\n",
        "#   whether we are combining training or testing data.\n",
        "# - It retrieves and concatenates the windows and labels from all activities into single arrays\n",
        "#   (`X_train` and `y_train` for training, `X_test` and `y_test` for testing).\n",
        "# - `X_train` and `X_test` are 3D arrays of sliding windows (shape: num_windows, window_size, num_features).\n",
        "# - `y_train` and `y_test` are 1D arrays containing the activity labels corresponding to each window.\n",
        "# Initialize the OneHotEncoder\n",
        "encoder72o = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "# Reshape y_train to a 2D array to meet the input format requirements of OneHotEncoder\n",
        "# - y_train is originally a 1D array of labels (shape: [num_samples]), but OneHotEncoder expects a 2D array of shape (num_samples, 1).\n",
        "# - reshape(-1, 1): The -1 means 'infer the correct size based on the other dimensions' (i.e., it adapts based on the length of y_train).\n",
        "# OneHotEncoder will then create a binary vector for each label.\n",
        "y_train_one_hot72o = encoder72o.fit_transform(y_train72o.reshape(-1, 1))\n",
        "\n",
        "# Apply the same transformation to the test labels (y_test)\n",
        "# - Since the encoder is already fitted on the training data, we use transform() for the test set.\n",
        "# - Reshape y_test to (num_samples, 1) for compatibility with the encoder.\n",
        "y_test_one_hot72o = encoder72o.transform(y_test72o.reshape(-1, 1))\n",
        "\n",
        "# Explanation:\n",
        "# - y_train_one_hot and y_test_one_hot are now 2D arrays where each row is a one-hot encoded binary vector corresponding to a class label.\n",
        "# - The number of columns in the one-hot encoded labels equals the number of unique classes (activities).\n",
        "# For example, if there are 6 unique activities, the encoded vector will have 6 elements, with a '1' indicating the correct class.\n",
        "# Print the shapes of the training and test arrays to verify that everything has been combined correctly\n",
        "print(f\"X_train24 shape: {X_train72o.shape}, y_train24 shape: {y_train72o.shape}\")\n",
        "print(f\"X_test24 shape: {X_test72o.shape}, y_test24 shape: {y_test72o.shape}\")\n",
        "# Print the shapes of the one-hot encoded labels to verify that the transformation was successful\n",
        "print(f\"y_train_one_hot24 shape: {y_train_one_hot72o.shape}, y_test_one_hot24 shape: {y_test_one_hot72o.shape}\")\n",
        "\n",
        "# Explanation of shapes:\n",
        "# - The shape of y_train_one_hot will be (num_samples, num_classes), where:\n",
        "#     - num_samples is the number of training windows.\n",
        "#     - num_classes is the number of unique activities (the length of the one-hot vectors).\n",
        "# - Similarly, y_test_one_hot will have the same number of columns (num_classes) as y_train_one_hot but will have fewer rows (corresponding to the number of test windows).\n",
        "\n",
        "# Determine the input shape for the model\n",
        "input_shape72o = (X_train72o.shape[1], X_train72o.shape[2])"
      ],
      "metadata": {
        "id": "CVQMfRXr0Vcc",
        "outputId": "c714bfff-bd34-408d-9bdc-76e8228d4229",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train24 shape: (75892, 72, 3), y_train24 shape: (75892,)\n",
            "X_test24 shape: (18987, 72, 3), y_test24 shape: (18987,)\n",
            "y_train_one_hot24 shape: (75892, 4), y_test_one_hot24 shape: (18987, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train, window size 72 overlapping"
      ],
      "metadata": {
        "id": "cgjK8NdP0ua1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "from torch.utils.data import DataLoader, RandomSampler\n",
        "if __name__ == '__main__':\n",
        "    # Define hyperparameters\n",
        "    latent_dim72o = 100\n",
        "    num_classes72o = 4  # Replace with the actual number of activity classes\n",
        "\n",
        "    #num_epochs6 = 30\n",
        "    batch_size72o = 128\n",
        "\n",
        "    # Initialize models\n",
        "    generator72o = Generator72(latent_dim=latent_dim72o, num_classes=num_classes72o)\n",
        "    discriminator72o = Discriminator72(num_classes=num_classes72o)\n",
        "\n",
        "    # Create DataLoader\n",
        "    train_dataset72o = CustomDataset6(X_train72o, y_train72o)\n",
        "    sampler72o = RandomSampler(train_dataset72o, replacement=True)\n",
        "    train_loader72o = DataLoader(train_dataset72o, batch_size=batch_size72o, sampler=sampler72o)\n",
        "\n",
        "    num_mini_batches_per_epoch = len(train_loader72o)\n",
        "    num_epochs72o = (25000 + num_mini_batches_per_epoch - 1) // num_mini_batches_per_epoch  # Ceiling division\n",
        "\n",
        "    # Train the AC-GAN\n",
        "    train_acgan6(generator72o, discriminator72o, train_loader72o, num_classes72o, num_epochs72o, latent_dim72o)\n"
      ],
      "metadata": {
        "id": "HlN_tE8z00DZ",
        "outputId": "8344a20a-053c-4f69-b93f-0163f7300316",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/43] Batch [0/593] D_loss: 4.1759, G_loss: 2.2217\n",
            "Epoch [1/43] Batch [100/593] D_loss: 1.9182, G_loss: 2.7678\n",
            "Epoch [1/43] Batch [200/593] D_loss: 2.0331, G_loss: 2.6763\n",
            "Epoch [1/43] Batch [300/593] D_loss: 1.7734, G_loss: 1.6039\n",
            "Epoch [1/43] Batch [400/593] D_loss: 1.8406, G_loss: 2.8029\n",
            "Epoch [1/43] Batch [500/593] D_loss: 1.8020, G_loss: 2.6222\n",
            "Epoch [2/43] Batch [0/593] D_loss: 1.5855, G_loss: 3.4269\n",
            "Epoch [2/43] Batch [100/593] D_loss: 1.7301, G_loss: 2.5392\n",
            "Epoch [2/43] Batch [200/593] D_loss: 1.7701, G_loss: 2.2627\n",
            "Epoch [2/43] Batch [300/593] D_loss: 1.8602, G_loss: 3.0396\n",
            "Epoch [2/43] Batch [400/593] D_loss: 1.8051, G_loss: 2.6668\n",
            "Epoch [2/43] Batch [500/593] D_loss: 1.9748, G_loss: 2.2147\n",
            "Epoch [3/43] Batch [0/593] D_loss: 2.0992, G_loss: 1.8601\n",
            "Epoch [3/43] Batch [100/593] D_loss: 2.2935, G_loss: 2.4408\n",
            "Epoch [3/43] Batch [200/593] D_loss: 3.0887, G_loss: 2.0907\n",
            "Epoch [3/43] Batch [300/593] D_loss: 2.0157, G_loss: 2.0255\n",
            "Epoch [3/43] Batch [400/593] D_loss: 2.3830, G_loss: 2.6659\n",
            "Epoch [3/43] Batch [500/593] D_loss: 2.0088, G_loss: 2.7852\n",
            "Epoch [4/43] Batch [0/593] D_loss: 1.8484, G_loss: 2.8701\n",
            "Epoch [4/43] Batch [100/593] D_loss: 1.8280, G_loss: 3.4142\n",
            "Epoch [4/43] Batch [200/593] D_loss: 1.9396, G_loss: 2.5154\n",
            "Epoch [4/43] Batch [300/593] D_loss: 1.9476, G_loss: 3.3701\n",
            "Epoch [4/43] Batch [400/593] D_loss: 1.9532, G_loss: 3.2424\n",
            "Epoch [4/43] Batch [500/593] D_loss: 1.7431, G_loss: 3.2836\n",
            "Epoch [5/43] Batch [0/593] D_loss: 2.2984, G_loss: 3.0076\n",
            "Epoch [5/43] Batch [100/593] D_loss: 1.6806, G_loss: 3.2057\n",
            "Epoch [5/43] Batch [200/593] D_loss: 1.8307, G_loss: 4.2528\n",
            "Epoch [5/43] Batch [300/593] D_loss: 1.4994, G_loss: 3.7152\n",
            "Epoch [5/43] Batch [400/593] D_loss: 1.4652, G_loss: 4.0441\n",
            "Epoch [5/43] Batch [500/593] D_loss: 2.1871, G_loss: 6.2831\n",
            "Epoch [6/43] Batch [0/593] D_loss: 1.6108, G_loss: 5.1422\n",
            "Epoch [6/43] Batch [100/593] D_loss: 1.4911, G_loss: 4.5574\n",
            "Epoch [6/43] Batch [200/593] D_loss: 1.6011, G_loss: 6.6840\n",
            "Epoch [6/43] Batch [300/593] D_loss: 1.4254, G_loss: 4.1210\n",
            "Epoch [6/43] Batch [400/593] D_loss: 1.7035, G_loss: 6.6708\n",
            "Epoch [6/43] Batch [500/593] D_loss: 1.5485, G_loss: 4.5515\n",
            "Epoch [7/43] Batch [0/593] D_loss: 1.8071, G_loss: 4.2037\n",
            "Epoch [7/43] Batch [100/593] D_loss: 1.7540, G_loss: 3.9490\n",
            "Epoch [7/43] Batch [200/593] D_loss: 1.9642, G_loss: 2.0675\n",
            "Epoch [7/43] Batch [300/593] D_loss: 2.0131, G_loss: 3.5085\n",
            "Epoch [7/43] Batch [400/593] D_loss: 1.8151, G_loss: 4.6266\n",
            "Epoch [7/43] Batch [500/593] D_loss: 2.1679, G_loss: 6.5232\n",
            "Epoch [8/43] Batch [0/593] D_loss: 1.6224, G_loss: 5.4018\n",
            "Epoch [8/43] Batch [100/593] D_loss: 2.2876, G_loss: 4.1823\n",
            "Epoch [8/43] Batch [200/593] D_loss: 1.7808, G_loss: 4.6861\n",
            "Epoch [8/43] Batch [300/593] D_loss: 1.4475, G_loss: 6.3432\n",
            "Epoch [8/43] Batch [400/593] D_loss: 1.8677, G_loss: 3.4111\n",
            "Epoch [8/43] Batch [500/593] D_loss: 1.5408, G_loss: 3.4153\n",
            "Epoch [9/43] Batch [0/593] D_loss: 1.9774, G_loss: 4.3313\n",
            "Epoch [9/43] Batch [100/593] D_loss: 2.1421, G_loss: 3.9953\n",
            "Epoch [9/43] Batch [200/593] D_loss: 1.9110, G_loss: 3.0103\n",
            "Epoch [9/43] Batch [300/593] D_loss: 2.2853, G_loss: 2.5031\n",
            "Epoch [9/43] Batch [400/593] D_loss: 1.5509, G_loss: 4.8440\n",
            "Epoch [9/43] Batch [500/593] D_loss: 1.4211, G_loss: 4.9859\n",
            "Epoch [10/43] Batch [0/593] D_loss: 1.7305, G_loss: 15.1865\n",
            "Epoch [10/43] Batch [100/593] D_loss: 1.4182, G_loss: 5.0033\n",
            "Epoch [10/43] Batch [200/593] D_loss: 1.3034, G_loss: 6.1991\n",
            "Epoch [10/43] Batch [300/593] D_loss: 1.5630, G_loss: 7.1816\n",
            "Epoch [10/43] Batch [400/593] D_loss: 1.4537, G_loss: 4.8517\n",
            "Epoch [10/43] Batch [500/593] D_loss: 1.4090, G_loss: 7.5423\n",
            "Epoch [11/43] Batch [0/593] D_loss: 1.5135, G_loss: 8.9941\n",
            "Epoch [11/43] Batch [100/593] D_loss: 1.3901, G_loss: 7.1734\n",
            "Epoch [11/43] Batch [200/593] D_loss: 1.5828, G_loss: 4.7762\n",
            "Epoch [11/43] Batch [300/593] D_loss: 1.3689, G_loss: 3.2947\n",
            "Epoch [11/43] Batch [400/593] D_loss: 1.4514, G_loss: 7.2588\n",
            "Epoch [11/43] Batch [500/593] D_loss: 1.5172, G_loss: 6.3324\n",
            "Epoch [12/43] Batch [0/593] D_loss: 1.2240, G_loss: 6.2924\n",
            "Epoch [12/43] Batch [100/593] D_loss: 1.2485, G_loss: 4.6870\n",
            "Epoch [12/43] Batch [200/593] D_loss: 1.3935, G_loss: 6.3629\n",
            "Epoch [12/43] Batch [300/593] D_loss: 1.4454, G_loss: 6.1145\n",
            "Epoch [12/43] Batch [400/593] D_loss: 1.6030, G_loss: 6.1584\n",
            "Epoch [12/43] Batch [500/593] D_loss: 1.4127, G_loss: 9.5093\n",
            "Epoch [13/43] Batch [0/593] D_loss: 1.4957, G_loss: 4.7318\n",
            "Epoch [13/43] Batch [100/593] D_loss: 1.4383, G_loss: 6.7935\n",
            "Epoch [13/43] Batch [200/593] D_loss: 1.1934, G_loss: 5.3883\n",
            "Epoch [13/43] Batch [300/593] D_loss: 1.4752, G_loss: 8.7903\n",
            "Epoch [13/43] Batch [400/593] D_loss: 1.4146, G_loss: 6.8862\n",
            "Epoch [13/43] Batch [500/593] D_loss: 1.3517, G_loss: 5.5289\n",
            "Epoch [14/43] Batch [0/593] D_loss: 1.4300, G_loss: 6.8164\n",
            "Epoch [14/43] Batch [100/593] D_loss: 1.5394, G_loss: 14.4447\n",
            "Epoch [14/43] Batch [200/593] D_loss: 1.3599, G_loss: 9.9465\n",
            "Epoch [14/43] Batch [300/593] D_loss: 1.5629, G_loss: 9.5273\n",
            "Epoch [14/43] Batch [400/593] D_loss: 1.3014, G_loss: 10.0322\n",
            "Epoch [14/43] Batch [500/593] D_loss: 1.3829, G_loss: 8.3510\n",
            "Epoch [15/43] Batch [0/593] D_loss: 1.4306, G_loss: 5.6848\n",
            "Epoch [15/43] Batch [100/593] D_loss: 1.6749, G_loss: 11.0804\n",
            "Epoch [15/43] Batch [200/593] D_loss: 1.3088, G_loss: 5.0710\n",
            "Epoch [15/43] Batch [300/593] D_loss: 1.3750, G_loss: 6.8868\n",
            "Epoch [15/43] Batch [400/593] D_loss: 1.2060, G_loss: 8.3944\n",
            "Epoch [15/43] Batch [500/593] D_loss: 1.2112, G_loss: 8.6266\n",
            "Epoch [16/43] Batch [0/593] D_loss: 1.6269, G_loss: 7.5272\n",
            "Epoch [16/43] Batch [100/593] D_loss: 1.3328, G_loss: 7.5696\n",
            "Epoch [16/43] Batch [200/593] D_loss: 1.2153, G_loss: 5.6977\n",
            "Epoch [16/43] Batch [300/593] D_loss: 1.3492, G_loss: 6.9549\n",
            "Epoch [16/43] Batch [400/593] D_loss: 1.5959, G_loss: 6.4728\n",
            "Epoch [16/43] Batch [500/593] D_loss: 1.3116, G_loss: 8.1363\n",
            "Epoch [17/43] Batch [0/593] D_loss: 1.3828, G_loss: 9.8152\n",
            "Epoch [17/43] Batch [100/593] D_loss: 1.2526, G_loss: 7.2851\n",
            "Epoch [17/43] Batch [200/593] D_loss: 1.2516, G_loss: 6.3335\n",
            "Epoch [17/43] Batch [300/593] D_loss: 1.5072, G_loss: 9.0576\n",
            "Epoch [17/43] Batch [400/593] D_loss: 1.6323, G_loss: 7.5334\n",
            "Epoch [17/43] Batch [500/593] D_loss: 1.6926, G_loss: 5.0692\n",
            "Epoch [18/43] Batch [0/593] D_loss: 1.4176, G_loss: 4.3294\n",
            "Epoch [18/43] Batch [100/593] D_loss: 1.4283, G_loss: 5.6768\n",
            "Epoch [18/43] Batch [200/593] D_loss: 1.7084, G_loss: 7.5777\n",
            "Epoch [18/43] Batch [300/593] D_loss: 1.3175, G_loss: 5.9410\n",
            "Epoch [18/43] Batch [400/593] D_loss: 1.2918, G_loss: 7.9680\n",
            "Epoch [18/43] Batch [500/593] D_loss: 1.3232, G_loss: 9.5307\n",
            "Epoch [19/43] Batch [0/593] D_loss: 2.5457, G_loss: 15.8811\n",
            "Epoch [19/43] Batch [100/593] D_loss: 1.3022, G_loss: 7.1372\n",
            "Epoch [19/43] Batch [200/593] D_loss: 1.9556, G_loss: 5.2403\n",
            "Epoch [19/43] Batch [300/593] D_loss: 1.4752, G_loss: 3.9601\n",
            "Epoch [19/43] Batch [400/593] D_loss: 1.4437, G_loss: 7.0703\n",
            "Epoch [19/43] Batch [500/593] D_loss: 1.3816, G_loss: 5.8163\n",
            "Epoch [20/43] Batch [0/593] D_loss: 1.7327, G_loss: 7.7300\n",
            "Epoch [20/43] Batch [100/593] D_loss: 1.3222, G_loss: 7.1579\n",
            "Epoch [20/43] Batch [200/593] D_loss: 1.4989, G_loss: 6.3780\n",
            "Epoch [20/43] Batch [300/593] D_loss: 1.4785, G_loss: 5.0461\n",
            "Epoch [20/43] Batch [400/593] D_loss: 1.4922, G_loss: 6.2399\n",
            "Epoch [20/43] Batch [500/593] D_loss: 1.6663, G_loss: 4.3233\n",
            "Epoch [21/43] Batch [0/593] D_loss: 1.6322, G_loss: 5.2984\n",
            "Epoch [21/43] Batch [100/593] D_loss: 1.5697, G_loss: 5.4374\n",
            "Epoch [21/43] Batch [200/593] D_loss: 1.3224, G_loss: 5.8089\n",
            "Epoch [21/43] Batch [300/593] D_loss: 1.4314, G_loss: 6.0978\n",
            "Epoch [21/43] Batch [400/593] D_loss: 1.6046, G_loss: 7.1186\n",
            "Epoch [21/43] Batch [500/593] D_loss: 1.3928, G_loss: 7.3634\n",
            "Epoch [22/43] Batch [0/593] D_loss: 1.2650, G_loss: 8.2288\n",
            "Epoch [22/43] Batch [100/593] D_loss: 1.0429, G_loss: 6.7863\n",
            "Epoch [22/43] Batch [200/593] D_loss: 1.1995, G_loss: 10.1808\n",
            "Epoch [22/43] Batch [300/593] D_loss: 1.4774, G_loss: 7.2555\n",
            "Epoch [22/43] Batch [400/593] D_loss: 1.5043, G_loss: 4.8329\n",
            "Epoch [22/43] Batch [500/593] D_loss: 1.4121, G_loss: 6.5349\n",
            "Epoch [23/43] Batch [0/593] D_loss: 1.2941, G_loss: 4.1517\n",
            "Epoch [23/43] Batch [100/593] D_loss: 1.3223, G_loss: 4.2119\n",
            "Epoch [23/43] Batch [200/593] D_loss: 1.3041, G_loss: 5.8752\n",
            "Epoch [23/43] Batch [300/593] D_loss: 1.6492, G_loss: 10.6499\n",
            "Epoch [23/43] Batch [400/593] D_loss: 1.3625, G_loss: 4.2701\n",
            "Epoch [23/43] Batch [500/593] D_loss: 1.4424, G_loss: 5.5673\n",
            "Epoch [24/43] Batch [0/593] D_loss: 1.2665, G_loss: 6.0358\n",
            "Epoch [24/43] Batch [100/593] D_loss: 1.4789, G_loss: 8.3710\n",
            "Epoch [24/43] Batch [200/593] D_loss: 1.5067, G_loss: 8.0176\n",
            "Epoch [24/43] Batch [300/593] D_loss: 1.5671, G_loss: 9.1682\n",
            "Epoch [24/43] Batch [400/593] D_loss: 1.4139, G_loss: 6.3215\n",
            "Epoch [24/43] Batch [500/593] D_loss: 1.3736, G_loss: 8.0649\n",
            "Epoch [25/43] Batch [0/593] D_loss: 1.3145, G_loss: 6.9856\n",
            "Epoch [25/43] Batch [100/593] D_loss: 1.4926, G_loss: 5.5962\n",
            "Epoch [25/43] Batch [200/593] D_loss: 1.5557, G_loss: 16.6368\n",
            "Epoch [25/43] Batch [300/593] D_loss: 1.3082, G_loss: 14.3736\n",
            "Epoch [25/43] Batch [400/593] D_loss: 1.7270, G_loss: 14.8877\n",
            "Epoch [25/43] Batch [500/593] D_loss: 1.6657, G_loss: 5.0816\n",
            "Epoch [26/43] Batch [0/593] D_loss: 1.5207, G_loss: 3.9094\n",
            "Epoch [26/43] Batch [100/593] D_loss: 1.3768, G_loss: 4.1689\n",
            "Epoch [26/43] Batch [200/593] D_loss: 1.4257, G_loss: 5.8784\n",
            "Epoch [26/43] Batch [300/593] D_loss: 1.7288, G_loss: 3.4176\n",
            "Epoch [26/43] Batch [400/593] D_loss: 1.2643, G_loss: 5.4061\n",
            "Epoch [26/43] Batch [500/593] D_loss: 1.2421, G_loss: 6.1129\n",
            "Epoch [27/43] Batch [0/593] D_loss: 1.5537, G_loss: 4.8552\n",
            "Epoch [27/43] Batch [100/593] D_loss: 1.4241, G_loss: 5.0347\n",
            "Epoch [27/43] Batch [200/593] D_loss: 1.3026, G_loss: 6.1095\n",
            "Epoch [27/43] Batch [300/593] D_loss: 1.2895, G_loss: 6.4582\n",
            "Epoch [27/43] Batch [400/593] D_loss: 1.6443, G_loss: 10.3045\n",
            "Epoch [27/43] Batch [500/593] D_loss: 1.6284, G_loss: 14.2120\n",
            "Epoch [28/43] Batch [0/593] D_loss: 1.3736, G_loss: 10.0687\n",
            "Epoch [28/43] Batch [100/593] D_loss: 1.3311, G_loss: 8.0347\n",
            "Epoch [28/43] Batch [200/593] D_loss: 1.3897, G_loss: 6.8329\n",
            "Epoch [28/43] Batch [300/593] D_loss: 1.3807, G_loss: 6.0757\n",
            "Epoch [28/43] Batch [400/593] D_loss: 1.1209, G_loss: 4.4259\n",
            "Epoch [28/43] Batch [500/593] D_loss: 1.3651, G_loss: 5.7544\n",
            "Epoch [29/43] Batch [0/593] D_loss: 1.2037, G_loss: 8.1356\n",
            "Epoch [29/43] Batch [100/593] D_loss: 1.5623, G_loss: 8.3263\n",
            "Epoch [29/43] Batch [200/593] D_loss: 1.4121, G_loss: 11.5587\n",
            "Epoch [29/43] Batch [300/593] D_loss: 1.5065, G_loss: 6.6569\n",
            "Epoch [29/43] Batch [400/593] D_loss: 1.2537, G_loss: 8.2268\n",
            "Epoch [29/43] Batch [500/593] D_loss: 1.4970, G_loss: 7.1200\n",
            "Epoch [30/43] Batch [0/593] D_loss: 1.5066, G_loss: 7.4463\n",
            "Epoch [30/43] Batch [100/593] D_loss: 1.0748, G_loss: 5.7894\n",
            "Epoch [30/43] Batch [200/593] D_loss: 1.3709, G_loss: 16.9076\n",
            "Epoch [30/43] Batch [300/593] D_loss: 1.0838, G_loss: 5.7166\n",
            "Epoch [30/43] Batch [400/593] D_loss: 1.2881, G_loss: 5.1788\n",
            "Epoch [30/43] Batch [500/593] D_loss: 1.5953, G_loss: 6.3692\n",
            "Epoch [31/43] Batch [0/593] D_loss: 1.5916, G_loss: 13.4901\n",
            "Epoch [31/43] Batch [100/593] D_loss: 1.3977, G_loss: 5.6230\n",
            "Epoch [31/43] Batch [200/593] D_loss: 1.2178, G_loss: 5.8780\n",
            "Epoch [31/43] Batch [300/593] D_loss: 1.5345, G_loss: 7.0783\n",
            "Epoch [31/43] Batch [400/593] D_loss: 1.4304, G_loss: 10.1535\n",
            "Epoch [31/43] Batch [500/593] D_loss: 1.4754, G_loss: 4.8380\n",
            "Epoch [32/43] Batch [0/593] D_loss: 1.5987, G_loss: 6.4936\n",
            "Epoch [32/43] Batch [100/593] D_loss: 1.6452, G_loss: 3.4864\n",
            "Epoch [32/43] Batch [200/593] D_loss: 1.1503, G_loss: 3.6154\n",
            "Epoch [32/43] Batch [300/593] D_loss: 1.3460, G_loss: 5.5785\n",
            "Epoch [32/43] Batch [400/593] D_loss: 1.4973, G_loss: 4.0036\n",
            "Epoch [32/43] Batch [500/593] D_loss: 1.4119, G_loss: 3.4148\n",
            "Epoch [33/43] Batch [0/593] D_loss: 1.7607, G_loss: 2.0506\n",
            "Epoch [33/43] Batch [100/593] D_loss: 1.4461, G_loss: 2.9977\n",
            "Epoch [33/43] Batch [200/593] D_loss: 1.4342, G_loss: 2.3813\n",
            "Epoch [33/43] Batch [300/593] D_loss: 1.3143, G_loss: 3.1788\n",
            "Epoch [33/43] Batch [400/593] D_loss: 1.4105, G_loss: 3.1835\n",
            "Epoch [33/43] Batch [500/593] D_loss: 1.4215, G_loss: 2.0340\n",
            "Epoch [34/43] Batch [0/593] D_loss: 1.2971, G_loss: 2.2121\n",
            "Epoch [34/43] Batch [100/593] D_loss: 1.5279, G_loss: 3.1478\n",
            "Epoch [34/43] Batch [200/593] D_loss: 1.6263, G_loss: 2.8041\n",
            "Epoch [34/43] Batch [300/593] D_loss: 1.6371, G_loss: 2.5334\n",
            "Epoch [34/43] Batch [400/593] D_loss: 1.3234, G_loss: 2.5702\n",
            "Epoch [34/43] Batch [500/593] D_loss: 1.5169, G_loss: 1.8490\n",
            "Epoch [35/43] Batch [0/593] D_loss: 1.3641, G_loss: 3.0621\n",
            "Epoch [35/43] Batch [100/593] D_loss: 1.5617, G_loss: 2.9235\n",
            "Epoch [35/43] Batch [200/593] D_loss: 1.2271, G_loss: 2.4002\n",
            "Epoch [35/43] Batch [300/593] D_loss: 1.2615, G_loss: 3.0406\n",
            "Epoch [35/43] Batch [400/593] D_loss: 1.3154, G_loss: 3.0368\n",
            "Epoch [35/43] Batch [500/593] D_loss: 1.3791, G_loss: 2.0889\n",
            "Epoch [36/43] Batch [0/593] D_loss: 1.7427, G_loss: 3.3756\n",
            "Epoch [36/43] Batch [100/593] D_loss: 1.4907, G_loss: 2.9428\n",
            "Epoch [36/43] Batch [200/593] D_loss: 1.6703, G_loss: 2.8552\n",
            "Epoch [36/43] Batch [300/593] D_loss: 1.4666, G_loss: 2.4637\n",
            "Epoch [36/43] Batch [400/593] D_loss: 1.1855, G_loss: 3.2741\n",
            "Epoch [36/43] Batch [500/593] D_loss: 1.6067, G_loss: 1.9657\n",
            "Epoch [37/43] Batch [0/593] D_loss: 1.3277, G_loss: 3.3269\n",
            "Epoch [37/43] Batch [100/593] D_loss: 1.4901, G_loss: 1.9196\n",
            "Epoch [37/43] Batch [200/593] D_loss: 1.3641, G_loss: 3.1374\n",
            "Epoch [37/43] Batch [300/593] D_loss: 1.4454, G_loss: 2.8236\n",
            "Epoch [37/43] Batch [400/593] D_loss: 1.2898, G_loss: 2.8621\n",
            "Epoch [37/43] Batch [500/593] D_loss: 1.3996, G_loss: 2.2856\n",
            "Epoch [38/43] Batch [0/593] D_loss: 1.6184, G_loss: 4.4078\n",
            "Epoch [38/43] Batch [100/593] D_loss: 1.3451, G_loss: 2.9263\n",
            "Epoch [38/43] Batch [200/593] D_loss: 1.5060, G_loss: 2.7440\n",
            "Epoch [38/43] Batch [300/593] D_loss: 1.3556, G_loss: 3.2645\n",
            "Epoch [38/43] Batch [400/593] D_loss: 1.2635, G_loss: 3.3984\n",
            "Epoch [38/43] Batch [500/593] D_loss: 1.4282, G_loss: 2.4427\n",
            "Epoch [39/43] Batch [0/593] D_loss: 1.2052, G_loss: 2.2722\n",
            "Epoch [39/43] Batch [100/593] D_loss: 1.3954, G_loss: 2.5131\n",
            "Epoch [39/43] Batch [200/593] D_loss: 1.6318, G_loss: 2.2893\n",
            "Epoch [39/43] Batch [300/593] D_loss: 1.2513, G_loss: 2.8219\n",
            "Epoch [39/43] Batch [400/593] D_loss: 1.3421, G_loss: 3.2599\n",
            "Epoch [39/43] Batch [500/593] D_loss: 1.3735, G_loss: 5.1051\n",
            "Epoch [40/43] Batch [0/593] D_loss: 1.3896, G_loss: 2.7470\n",
            "Epoch [40/43] Batch [100/593] D_loss: 1.3125, G_loss: 2.1576\n",
            "Epoch [40/43] Batch [200/593] D_loss: 1.2650, G_loss: 2.7295\n",
            "Epoch [40/43] Batch [300/593] D_loss: 1.2583, G_loss: 2.6361\n",
            "Epoch [40/43] Batch [400/593] D_loss: 1.6181, G_loss: 3.0020\n",
            "Epoch [40/43] Batch [500/593] D_loss: 1.3714, G_loss: 3.0058\n",
            "Epoch [41/43] Batch [0/593] D_loss: 1.4133, G_loss: 2.7353\n",
            "Epoch [41/43] Batch [100/593] D_loss: 1.5616, G_loss: 2.6260\n",
            "Epoch [41/43] Batch [200/593] D_loss: 1.3133, G_loss: 3.0933\n",
            "Epoch [41/43] Batch [300/593] D_loss: 1.1464, G_loss: 3.5908\n",
            "Epoch [41/43] Batch [400/593] D_loss: 1.4140, G_loss: 3.0354\n",
            "Epoch [41/43] Batch [500/593] D_loss: 1.3689, G_loss: 3.5205\n",
            "Epoch [42/43] Batch [0/593] D_loss: 1.1151, G_loss: 2.8163\n",
            "Epoch [42/43] Batch [100/593] D_loss: 1.6384, G_loss: 3.1631\n",
            "Epoch [42/43] Batch [200/593] D_loss: 1.1798, G_loss: 2.6503\n",
            "Epoch [42/43] Batch [300/593] D_loss: 1.6081, G_loss: 2.2506\n",
            "Epoch [42/43] Batch [400/593] D_loss: 1.2649, G_loss: 3.0089\n",
            "Epoch [42/43] Batch [500/593] D_loss: 1.2686, G_loss: 2.6073\n",
            "Epoch [43/43] Batch [0/593] D_loss: 1.1910, G_loss: 3.3734\n",
            "Epoch [43/43] Batch [100/593] D_loss: 1.2287, G_loss: 2.9458\n",
            "Epoch [43/43] Batch [200/593] D_loss: 1.2150, G_loss: 3.2532\n",
            "Epoch [43/43] Batch [300/593] D_loss: 1.3052, G_loss: 3.1096\n",
            "Epoch [43/43] Batch [400/593] D_loss: 1.5643, G_loss: 4.8479\n",
            "Epoch [43/43] Batch [500/593] D_loss: 1.4246, G_loss: 2.5654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test"
      ],
      "metadata": {
        "id": "90fDeuSK0y8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Assuming you have already imported necessary libraries and defined CustomDataset\n",
        "\n",
        "# Create test dataset\n",
        "test_dataset72o = CustomDataset6(X_test72o, y_test72o)\n",
        "\n",
        "# Create DataLoader\n",
        "test_loader72o = DataLoader(test_dataset72o, batch_size=batch_size72o, shuffle=False)\n",
        "\n",
        "# Set the discriminator to evaluation mode\n",
        "discriminator72o.eval()\n",
        "\n",
        "test_gan(test_loader72o, discriminator72o)"
      ],
      "metadata": {
        "id": "L0lFu8ax0z1O",
        "outputId": "f0455ab9-c221-4549-aee3-f301cec3829a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5542\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.5489    0.5935    0.5704      3695\n",
            "           1     0.4964    0.6474    0.5619      2870\n",
            "           2     0.4359    0.1971    0.2714      2862\n",
            "           3     0.5935    0.6180    0.6055      9560\n",
            "\n",
            "    accuracy                         0.5542     18987\n",
            "   macro avg     0.5187    0.5140    0.5023     18987\n",
            "weighted avg     0.5464    0.5542    0.5417     18987\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2193   98    5 1399]\n",
            " [  29 1858  167  816]\n",
            " [  93  373  564 1832]\n",
            " [1680 1414  558 5908]]\n",
            "Per-class Recall:\n",
            "Class 0: 0.5935\n",
            "Class 1: 0.6474\n",
            "Class 2: 0.1971\n",
            "Class 3: 0.6180\n",
            "Per-class Accuracy:\n",
            "Class 0: 1.2546\n",
            "Class 1: 1.2872\n",
            "Class 2: 1.2767\n",
            "Class 3: 0.9030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet\n",
        "\n",
        "https://project-archive.inf.ed.ac.uk/ug4/20212442/ug4_proj.pdf#page=26.16"
      ],
      "metadata": {
        "id": "WvfCQj5q-P-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ReLU, Dropout, GlobalMaxPooling2D, Add, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "sd8Bkdqj-TGo"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input shape and number of classes\n",
        "input_shape7 = (64, 64, 3)  # Example input shape\n",
        "num_classes7 = 4  # Number of activities\n",
        "\n",
        "# Input layer\n",
        "inputs7 = Input(shape=input_shape7)\n",
        "\n",
        "# Branch 1: Downsample Conv (128 filters)\n",
        "downsample7 = Conv2D(128, kernel_size=(1,1), strides=(1,1), padding='same')(inputs7)\n",
        "\n",
        "# Branch 2: Convolutional Block\n",
        "# Conv1 (128 filters) + BatchNorm + ReLU\n",
        "x = Conv2D(128, kernel_size=(3,3), padding='same')(inputs7)\n",
        "x = BatchNormalization()(x)\n",
        "x = ReLU()(x)\n",
        "\n",
        "# Conv2 (128 filters) + BatchNorm + ReLU\n",
        "x = Conv2D(128, kernel_size=(3,3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = ReLU()(x)\n",
        "\n",
        "# Conv3 (128 filters) + Dropout + BatchNorm\n",
        "x = Conv2D(128, kernel_size=(3,3), padding='same')(x)\n",
        "x = Dropout(0.5)(x)  # 0.5 probability of keeping each neuron\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "# Residual Connection\n",
        "x = Add()([downsample7, x])\n",
        "\n",
        "# Activation and Dropout after addition\n",
        "x = ReLU()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Global Max Pooling\n",
        "x = GlobalMaxPooling2D()(x)\n",
        "\n",
        "# Output layer with 'n' units and softmax activation\n",
        "outputs7 = Dense(num_classes7, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model7 = Model(inputs=inputs7, outputs=outputs7)\n",
        "\n",
        "# Compile the model with categorical cross-entropy loss and Adam optimizer\n",
        "model7.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define EarlyStopping callback with patience of 25 epochs\n",
        "early_stopping7 = EarlyStopping(patience=25, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "1nO8V_X3-bi4"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming train_data, train_labels, val_data, val_labels are predefined datasets\n",
        "# Train the model for 50 epochs with batch size of 128\n",
        "history = model.fit(\n",
        "    train_data, train_labels,\n",
        "    validation_data=(val_data, val_labels),\n",
        "    epochs=50,\n",
        "    batch_size=128,\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ],
      "metadata": {
        "id": "e2CmHogC-xdl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}